{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9cac5cff",
      "metadata": {
        "id": "9cac5cff"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4a11a8",
      "metadata": {
        "id": "6c4a11a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# (Optional) If you're working inside Jupyter\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e80aa0ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff202c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_processor_v2 import DataProcessorUpdated\n",
        "\n",
        "processor = DataProcessorUpdated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caae40c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.load_and_clean_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35901f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.combine_all_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5cff35",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73e0d9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_dap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9b0f63",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5902795",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.split_data(feature_columns=['DAP_SystemLambda', 'SCED_system_lambda','Fuel_solar','Fuel_wind','Load_load'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857623c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.standardize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89475b19",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aff786e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df, x_train_lstm, y_train_lstm, x_val_lstm, y_val_lstm, x_test_lstm, y_test_lstm = processor.get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c965398",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e02c1f06",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_lstm = y_val_lstm.squeeze(-1)\n",
        "y_test_lstm = y_test_lstm.squeeze(-1)\n",
        "y_train_lstm = y_train_lstm.squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed635d10",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"x_train:\", x_train_lstm.shape)   # 期望 (N, 32, 2) 或 (N, 24, 2)\n",
        "print(\"y_train:\", y_train_lstm.shape)   # 期望 (N, 32)   或 (N, 24)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebb85c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test_lstm.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaeebb4",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "8c92454d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from CNN_MLP import CNN2D_MLP_Model   # 根据你的文件结构保持不变\n",
        "\n",
        "# 1. 选择设备\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. 实例化模型（符合新签名）\n",
        "cnn_mlp = CNN2D_MLP_Model(\n",
        "    n_features=5,            # 输入特征数\n",
        "    horizon=24,              # 预测步长\n",
        "    cnn_channels=64,         # 卷积通道\n",
        "    hidden_dims=[256,512,256]  # MLP 隐层\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "fa2ed5df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MAE: 0.1508\n",
            "Test RMSE: 0.8769\n"
          ]
        }
      ],
      "source": [
        "cnn_mlp.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = cnn_mlp(torch.tensor(x_test_lstm, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_lstm  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "c0fde9ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 1.0320, Eval Loss = 0.2533\n",
            "Epoch 2: Train Loss = 0.9872, Eval Loss = 0.2544\n",
            "Epoch 3: Train Loss = 0.9711, Eval Loss = 0.2535\n",
            "Epoch 4: Train Loss = 0.9780, Eval Loss = 0.2492\n",
            "Epoch 5: Train Loss = 0.9455, Eval Loss = 0.2526\n",
            "Epoch 6: Train Loss = 0.9336, Eval Loss = 0.2524\n",
            "Epoch 7: Train Loss = 0.9229, Eval Loss = 0.2608\n",
            "Epoch 8: Train Loss = 0.9103, Eval Loss = 0.2593\n",
            "Epoch 9: Train Loss = 0.8996, Eval Loss = 0.2576\n",
            "Epoch 10: Train Loss = 0.8893, Eval Loss = 0.2631\n",
            "Epoch 11: Train Loss = 0.8776, Eval Loss = 0.2639\n",
            "Epoch 12: Train Loss = 0.8692, Eval Loss = 0.2695\n",
            "Epoch 13: Train Loss = 0.8610, Eval Loss = 0.2695\n",
            "Epoch 14: Train Loss = 0.8547, Eval Loss = 0.2754\n",
            "Epoch 15: Train Loss = 0.8443, Eval Loss = 0.2845\n",
            "Epoch 16: Train Loss = 0.8379, Eval Loss = 0.2956\n",
            "Epoch 17: Train Loss = 0.8291, Eval Loss = 0.2937\n",
            "Epoch 18: Train Loss = 0.8256, Eval Loss = 0.2930\n",
            "Epoch 19: Train Loss = 0.8201, Eval Loss = 0.2904\n",
            "Epoch 20: Train Loss = 0.8188, Eval Loss = 0.3144\n",
            "Epoch 21: Train Loss = 0.8140, Eval Loss = 0.3237\n",
            "Epoch 22: Train Loss = 0.8063, Eval Loss = 0.2986\n",
            "Epoch 23: Train Loss = 0.8095, Eval Loss = 0.3054\n",
            "Epoch 24: Train Loss = 0.8024, Eval Loss = 0.3142\n",
            "Epoch 25: Train Loss = 0.7994, Eval Loss = 0.2999\n",
            "Epoch 26: Train Loss = 0.7966, Eval Loss = 0.3366\n",
            "Epoch 27: Train Loss = 0.7951, Eval Loss = 0.3402\n",
            "Epoch 28: Train Loss = 0.7886, Eval Loss = 0.3122\n",
            "Epoch 29: Train Loss = 0.7897, Eval Loss = 0.3627\n",
            "Epoch 30: Train Loss = 0.7899, Eval Loss = 0.3461\n",
            "Epoch 31: Train Loss = 0.7859, Eval Loss = 0.3520\n",
            "Epoch 32: Train Loss = 0.7822, Eval Loss = 0.3485\n",
            "Epoch 33: Train Loss = 0.7799, Eval Loss = 0.3742\n",
            "Epoch 34: Train Loss = 0.7766, Eval Loss = 0.3420\n",
            "Epoch 35: Train Loss = 0.7727, Eval Loss = 0.3798\n",
            "Epoch 36: Train Loss = 0.7734, Eval Loss = 0.3710\n",
            "Epoch 37: Train Loss = 0.7715, Eval Loss = 0.4340\n",
            "Epoch 38: Train Loss = 0.7704, Eval Loss = 0.3873\n",
            "Epoch 39: Train Loss = 0.7651, Eval Loss = 0.3744\n",
            "Epoch 40: Train Loss = 0.7753, Eval Loss = 0.3525\n",
            "Epoch 41: Train Loss = 0.7626, Eval Loss = 0.5338\n",
            "Epoch 42: Train Loss = 0.7636, Eval Loss = 0.3811\n",
            "Epoch 43: Train Loss = 0.7587, Eval Loss = 0.4761\n",
            "Epoch 44: Train Loss = 0.7616, Eval Loss = 0.3744\n",
            "Epoch 45: Train Loss = 0.7596, Eval Loss = 0.3715\n",
            "Epoch 46: Train Loss = 0.7585, Eval Loss = 0.3742\n",
            "Epoch 47: Train Loss = 0.7562, Eval Loss = 0.4288\n",
            "Epoch 48: Train Loss = 0.7552, Eval Loss = 0.3521\n",
            "Epoch 49: Train Loss = 0.7561, Eval Loss = 0.3923\n",
            "Epoch 50: Train Loss = 0.7519, Eval Loss = 0.3849\n",
            "Epoch 51: Train Loss = 0.7552, Eval Loss = 0.4513\n",
            "Epoch 52: Train Loss = 0.7484, Eval Loss = 0.3794\n",
            "Epoch 53: Train Loss = 0.7578, Eval Loss = 0.3899\n",
            "Epoch 54: Train Loss = 0.7500, Eval Loss = 0.3989\n",
            "Early stopping triggered at epoch 54\n"
          ]
        }
      ],
      "source": [
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss  # or define it above in your notebook\n",
        "\n",
        "trainer = ModelTrainer(\n",
        "    model=cnn_mlp,\n",
        "    features_training_data=x_train_lstm,\n",
        "    target_training_data=y_train_lstm,\n",
        "    features_eval_data=x_val_lstm,\n",
        "    target_eval_data=y_val_lstm,\n",
        "    device=device,\n",
        "    loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=0.11866313536860208)\n",
        ")\n",
        "\n",
        "trainer.train(epochs=100, batch_size=32, patience=50, learning_rate=1.0199709447160282e-05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "951a69d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 44.5838, SMSE: 1.0093\n"
          ]
        }
      ],
      "source": [
        "cnn_mlp.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = cnn_mlp(torch.tensor(x_test_lstm, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_lstm  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "# 1. Flatten both (remove batch and window dimensions if needed)\n",
        "y_pred_flat = y_pred.reshape(-1)\n",
        "y_test_flat = y_test_lstm.reshape(-1)\n",
        "\n",
        "# 2. Denormalize both using your processor's function\n",
        "y_pred_real = processor.denormalization(y_pred_flat)\n",
        "y_test_real = processor.denormalization(y_test_flat)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
        "mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
        "variance = np.var(y_test_real)\n",
        "smse = mse / variance\n",
        "\n",
        "print(f\"MAE: {mae:.4f}, SMSE: {smse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a4e5ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss = trainer.history\n",
        "with open('CNN_MLP_Best.csv', 'w') as f:\n",
        "    pd.DataFrame(loss).to_csv(f, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c690761",
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from CNN_MLP import CNN2D_MLP_Model\n",
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss\n",
        "\n",
        "\n",
        "\n",
        "# ------------- 设备 -------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ------------- Optuna 目标函数 -------------------\n",
        "def objective(trial):\n",
        "    # ---- 超参数搜索空间 ----\n",
        "    cnn_channels = trial.suggest_categorical(\"cnn_channels\", [32, 64, 128])\n",
        "    hidden_dim   = trial.suggest_categorical(\"mlp_hidden_dim\", [128, 256, 512])\n",
        "    n_layers     = trial.suggest_int(\"n_layers\", 2, 4)\n",
        "    lr           = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    alpha        = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n",
        "\n",
        "    hidden_dims = [hidden_dim] * n_layers   # MLP 隐层列表\n",
        "\n",
        "    # ---- 构建模型 ----\n",
        "    model = CNN2D_MLP_Model(\n",
        "        n_features=5,        # 输入特征数\n",
        "        horizon=24,          # 预测步长\n",
        "        cnn_channels=cnn_channels,\n",
        "        hidden_dims=hidden_dims\n",
        "    ).to(device)\n",
        "\n",
        "    # ---- 训练器 ----\n",
        "    trainer = ModelTrainer(\n",
        "        model=model,\n",
        "        features_training_data=x_train_lstm,\n",
        "        target_training_data=y_train_lstm,\n",
        "        features_eval_data=x_val_lstm,\n",
        "        target_eval_data=y_val_lstm,\n",
        "        device=device,\n",
        "        loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=alpha)\n",
        "    )\n",
        "\n",
        "    # ---- 训练，控制轮数别太大避免单次 trial 过慢 ----\n",
        "    trainer.train(epochs=50, batch_size=32, patience=10, learning_rate=lr)\n",
        "\n",
        "    # ---- 返回验证集最后一次 (或最优) 损失 ----\n",
        "    return trainer.history['eval_loss'][-1]\n",
        "\n",
        "# ------------- 创建并运行 Optuna Study -------------------\n",
        "study = optuna.create_study(direction=\"minimize\",\n",
        "                            pruner=optuna.pruners.HyperbandPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"最佳 trial:\", study.best_trial.params)\n",
        "print(\"最佳 eval_loss:\", study.best_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d4194c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "study.optimize(objective, n_trials=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4e3bb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90832a27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict\n",
        "\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = mlp_model(torch.tensor(x_test_mlp, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_mlp  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HAyut1x8xchV",
      "metadata": {
        "id": "HAyut1x8xchV"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "eng",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
