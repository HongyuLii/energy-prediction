{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9cac5cff",
      "metadata": {
        "id": "9cac5cff"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6c4a11a8",
      "metadata": {
        "id": "6c4a11a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# (Optional) If you're working inside Jupyter\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e80aa0ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2ff202c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_processor_v2 import DataProcessorUpdated\n",
        "\n",
        "processor = DataProcessorUpdated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "caae40c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-12-31 23:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/data_processor_v2.py:41: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[time_col] = pd.to_datetime(df[time_col])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-01 23:00:00\n",
            "2023-12-31 23:00:00\n",
            "2023-12-31 23:00:00\n"
          ]
        }
      ],
      "source": [
        "processor.load_and_clean_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "35901f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.combine_all_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8c5cff35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "DAP_SystemLambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SCED_system_lambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_coal_and_lignite",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_hydro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_nuclear",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_power_storage",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_solar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_wind",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_natural_gas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_other",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Load_load",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "delta_price",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "4dae04e1-ed08-4ca1-8232-2986070fafe6",
              "rows": [
                [
                  "2019-01-01 00:00:00",
                  null,
                  "13.8375616073608",
                  "6116.41904",
                  "185.465296",
                  "3895.95194",
                  "0.0",
                  "0.0",
                  "14311.36445",
                  "12512.80815",
                  "2.534772",
                  "36951.0",
                  null
                ],
                [
                  "2019-01-01 01:00:00",
                  null,
                  "15.4648694992065",
                  "6423.24236",
                  "186.667008",
                  "3894.973176",
                  "0.0",
                  "0.0",
                  "14298.52586",
                  "12434.13638",
                  "2.947464",
                  "37112.0",
                  null
                ],
                [
                  "2019-01-01 02:00:00",
                  null,
                  "15.4877195358276",
                  "6309.280752",
                  "187.408832",
                  "3894.733152",
                  "0.0",
                  "0.0",
                  "14030.82875",
                  "12797.25831",
                  "-1.954544",
                  "37154.0",
                  null
                ],
                [
                  "2019-01-01 03:00:00",
                  null,
                  "15.770092010498",
                  "6416.671292",
                  "187.817564",
                  "3894.714576",
                  "0.0",
                  "0.0",
                  "13610.13937",
                  "13279.01803",
                  "1.887324",
                  "37283.0",
                  null
                ],
                [
                  "2019-01-01 04:00:00",
                  null,
                  "16.0360851287842",
                  "6569.580884",
                  "186.990116",
                  "3892.748912",
                  "0.0",
                  "0.0",
                  "13414.14969",
                  "13585.26799",
                  "-0.2011",
                  "37817.0",
                  null
                ],
                [
                  "2019-01-01 05:00:00",
                  null,
                  "16.7470397949219",
                  "6806.102292",
                  "222.169372",
                  "3893.877024",
                  "0.0",
                  "0.0",
                  "12743.16529",
                  "14786.60827",
                  "2.955692",
                  "38763.0",
                  null
                ],
                [
                  "2019-01-01 06:00:00",
                  null,
                  "17.5206718444824",
                  "7356.916872",
                  "223.598596",
                  "3894.202416",
                  "0.0",
                  "0.0",
                  "11695.73501",
                  "16435.8807",
                  "4.032436",
                  "39849.0",
                  null
                ],
                [
                  "2019-01-01 07:00:00",
                  null,
                  "17.7318916320801",
                  "7627.659176",
                  "223.522816",
                  "3891.496004",
                  "0.0",
                  "0.0",
                  "10769.46719",
                  "17849.76048",
                  "2.988096",
                  "40410.0",
                  null
                ],
                [
                  "2019-01-01 08:00:00",
                  null,
                  "18.4140319824219",
                  "8034.6643",
                  "222.1581",
                  "3892.873952",
                  "0.0",
                  "15.504816",
                  "9749.372156",
                  "18761.96472",
                  "3.074772",
                  "40892.0",
                  null
                ],
                [
                  "2019-01-01 09:00:00",
                  null,
                  "19.588623046875",
                  "8861.727808",
                  "223.473352",
                  "3894.109608",
                  "0.0",
                  "73.208772",
                  "8688.958132",
                  "19735.37034",
                  "3.040152",
                  "41671.0",
                  null
                ],
                [
                  "2019-01-01 10:00:00",
                  null,
                  "20.7471313476563",
                  "9938.088416",
                  "223.699976",
                  "3890.997248",
                  "0.0",
                  "165.856592",
                  "7236.261324",
                  "20776.384",
                  "3.8969",
                  "42146.0",
                  null
                ],
                [
                  "2019-01-01 11:00:00",
                  null,
                  "21.3603363037109",
                  "10401.91125",
                  "200.562196",
                  "3892.734124",
                  "0.0",
                  "233.450596",
                  "6421.903592",
                  "21216.38172",
                  "3.608564",
                  "42206.0",
                  null
                ],
                [
                  "2019-01-01 12:00:00",
                  null,
                  "21.6746959686279",
                  "10843.79388",
                  "186.330668",
                  "3892.944372",
                  "0.0",
                  "311.36348",
                  "5665.944092",
                  "21339.63762",
                  "-0.050588",
                  "41807.0",
                  null
                ],
                [
                  "2019-01-01 13:00:00",
                  null,
                  "21.7823867797852",
                  "11049.00355",
                  "186.441272",
                  "3892.50776",
                  "0.0",
                  "259.819596",
                  "5217.935984",
                  "21018.28545",
                  "3.15518",
                  "41320.0",
                  null
                ],
                [
                  "2019-01-01 14:00:00",
                  null,
                  "21.9466972351074",
                  "11187.95622",
                  "186.049876",
                  "3891.574964",
                  "0.0",
                  "203.82868",
                  "4859.254484",
                  "20871.27624",
                  "1.594112",
                  "40949.0",
                  null
                ],
                [
                  "2019-01-01 15:00:00",
                  null,
                  "26.3067970275879",
                  "11535.01104",
                  "211.481304",
                  "3892.253344",
                  "0.0",
                  "110.826784",
                  "4233.964036",
                  "21118.54924",
                  "2.546792",
                  "40975.0",
                  null
                ],
                [
                  "2019-01-01 16:00:00",
                  null,
                  "26.8361930847168",
                  "11924.04599",
                  "249.026864",
                  "3892.451464",
                  "0.0",
                  "66.500996",
                  "3554.642004",
                  "21802.12896",
                  "3.056364",
                  "41783.0",
                  null
                ],
                [
                  "2019-01-01 17:00:00",
                  null,
                  "27.5510845184326",
                  "12276.57683",
                  "248.96194",
                  "3892.762276",
                  "0.0",
                  "15.013288",
                  "3354.061648",
                  "23212.87701",
                  "2.998796",
                  "43966.0",
                  null
                ],
                [
                  "2019-01-01 18:00:00",
                  null,
                  "33.4604682922363",
                  "12373.18407",
                  "221.384096",
                  "3892.680796",
                  "0.0",
                  "0.0",
                  "2992.843944",
                  "25837.25857",
                  "3.79044",
                  "45406.0",
                  null
                ],
                [
                  "2019-01-01 19:00:00",
                  null,
                  "34.9075584411621",
                  "12439.40505",
                  "221.815728",
                  "3892.293888",
                  "0.0",
                  "0.0",
                  "2857.59244",
                  "25935.07676",
                  "1.267524",
                  "45261.0",
                  null
                ],
                [
                  "2019-01-01 20:00:00",
                  null,
                  "34.0498199462891",
                  "12438.36693",
                  "195.830184",
                  "3892.080304",
                  "0.0",
                  "0.0",
                  "2759.597352",
                  "25786.21502",
                  "-1.325144",
                  "44875.0",
                  null
                ],
                [
                  "2019-01-01 21:00:00",
                  null,
                  "31.0697078704834",
                  "12465.79535",
                  "196.451852",
                  "3891.513288",
                  "0.0",
                  "0.0",
                  "2724.787952",
                  "24951.17857",
                  "-0.377196",
                  "43945.0",
                  null
                ],
                [
                  "2019-01-01 22:00:00",
                  null,
                  "31.1546306610107",
                  "12436.69127",
                  "158.890524",
                  "3890.599492",
                  "0.0",
                  "0.0",
                  "2434.006624",
                  "23910.70212",
                  "0.041472",
                  "42277.0",
                  null
                ],
                [
                  "2019-01-01 23:00:00",
                  null,
                  "26.8461532592773",
                  "11874.96931",
                  "159.464984",
                  "3891.757256",
                  "0.0",
                  "0.0",
                  "2510.4403",
                  "22597.71201",
                  "2.822164",
                  "40543.0",
                  null
                ],
                [
                  "2019-01-02 00:00:00",
                  "23.925",
                  "26.1592845916748",
                  "11019.0404",
                  "211.80336",
                  "3891.427324",
                  "0.0",
                  "0.0",
                  "2556.493476",
                  "21857.30259",
                  "0.776324",
                  "39277.0",
                  "2.2342845916748004"
                ],
                [
                  "2019-01-02 01:00:00",
                  "23.314",
                  "25.9841365814209",
                  "10388.7317",
                  "188.16956",
                  "3891.118712",
                  "0.0",
                  "0.0",
                  "2417.738312",
                  "21725.04409",
                  "1.218988",
                  "38589.0",
                  "2.6701365814208984"
                ],
                [
                  "2019-01-02 02:00:00",
                  "23.3475",
                  "25.3712673187256",
                  "10148.57656",
                  "187.471732",
                  "3890.877504",
                  "0.0",
                  "0.0",
                  "2693.351584",
                  "21409.53292",
                  "-2.470856",
                  "38431.0",
                  "2.0237673187256"
                ],
                [
                  "2019-01-02 03:00:00",
                  "23.0595",
                  "25.2762241363525",
                  "9846.024556",
                  "187.525788",
                  "3891.413216",
                  "0.0",
                  "0.0",
                  "3128.780528",
                  "21428.29015",
                  "-1.432144",
                  "38828.0",
                  "2.2167241363525"
                ],
                [
                  "2019-01-02 04:00:00",
                  "25.2672",
                  "24.5719661712646",
                  "9829.751588",
                  "188.180748",
                  "3892.101792",
                  "0.0",
                  "0.0",
                  "3289.184004",
                  "22151.42388",
                  "-3.166144",
                  "40043.0",
                  "-0.6952338287354003"
                ],
                [
                  "2019-01-02 05:00:00",
                  "28.8611",
                  "25.0743083953857",
                  "10341.36317",
                  "225.203888",
                  "3891.783612",
                  "0.0",
                  "0.0",
                  "3539.563424",
                  "23384.49495",
                  "-0.08526",
                  "42402.0",
                  "-3.786791604614301"
                ],
                [
                  "2019-01-02 06:00:00",
                  "39.4101",
                  "25.9785709381104",
                  "11733.04428",
                  "250.607476",
                  "3890.602976",
                  "0.0",
                  "0.0",
                  "2871.80052",
                  "25467.92225",
                  "0.570452",
                  "45219.0",
                  "-13.431529061889599"
                ],
                [
                  "2019-01-02 07:00:00",
                  "39.1896",
                  "29.2044925689697",
                  "12243.0151",
                  "247.146256",
                  "3889.973712",
                  "0.0",
                  "0.0",
                  "2553.030404",
                  "27772.4965",
                  "2.102536",
                  "47432.0",
                  "-9.985107431030297"
                ],
                [
                  "2019-01-02 08:00:00",
                  "36.3108",
                  "36.638427734375",
                  "12250.63438",
                  "248.447572",
                  "3890.307104",
                  "0.0",
                  "0.005384",
                  "2011.634756",
                  "29664.07621",
                  "2.383692",
                  "48598.0",
                  "0.3276277343749996"
                ],
                [
                  "2019-01-02 09:00:00",
                  "39.6983",
                  "40.1176872253418",
                  "12207.58335",
                  "263.57132",
                  "3895.736976",
                  "0.0",
                  "35.411584",
                  "2025.567152",
                  "30648.5328",
                  "-1.2047",
                  "49657.0",
                  "0.4193872253417936"
                ],
                [
                  "2019-01-02 10:00:00",
                  "40.2148",
                  "59.4540328979492",
                  "12269.39236",
                  "273.484616",
                  "3893.812596",
                  "0.0",
                  "107.043332",
                  "1867.155328",
                  "31570.85504",
                  "0.898424",
                  "50661.0",
                  "19.2392328979492"
                ],
                [
                  "2019-01-02 11:00:00",
                  "37.2478",
                  "62.8075675964355",
                  "12340.60632",
                  "230.893108",
                  "3894.783856",
                  "0.0",
                  "131.75698",
                  "1195.121152",
                  "33235.95221",
                  "1.521576",
                  "51295.0",
                  "25.5597675964355"
                ],
                [
                  "2019-01-02 12:00:00",
                  "34.5007",
                  "38.1134338378906",
                  "12180.95975",
                  "230.128864",
                  "3894.444364",
                  "0.0",
                  "147.411984",
                  "1308.978972",
                  "33378.0454",
                  "0.758804",
                  "51412.0",
                  "3.6127338378905947"
                ],
                [
                  "2019-01-02 13:00:00",
                  "34.7428",
                  "43.5680694580078",
                  "12255.0393",
                  "231.139796",
                  "3894.801384",
                  "0.0",
                  "212.907912",
                  "1337.093948",
                  "33392.38348",
                  "1.925832",
                  "51492.0",
                  "8.825269458007796"
                ],
                [
                  "2019-01-02 14:00:00",
                  "34.6144",
                  "36.8626899719238",
                  "12046.10978",
                  "230.807104",
                  "3893.390536",
                  "0.0",
                  "189.23948",
                  "1407.03348",
                  "33137.96618",
                  "2.24628",
                  "51264.0",
                  "2.2482899719237963"
                ],
                [
                  "2019-01-02 15:00:00",
                  "34.4056",
                  "32.3479118347168",
                  "11908.7674",
                  "267.818492",
                  "3894.09848",
                  "0.0",
                  "137.89176",
                  "2095.40284",
                  "32660.76262",
                  "1.693052",
                  "51152.0",
                  "-2.057688165283203"
                ],
                [
                  "2019-01-02 16:00:00",
                  "36.2957",
                  "38.1546897888184",
                  "11771.16732",
                  "304.06906",
                  "3893.31228",
                  "0.0",
                  "71.420348",
                  "1784.647496",
                  "33119.553",
                  "1.7932",
                  "51384.0",
                  "1.8589897888184055"
                ],
                [
                  "2019-01-02 17:00:00",
                  "64.5798",
                  "37.7884407043457",
                  "11733.58142",
                  "276.826592",
                  "3892.46698",
                  "0.0",
                  "20.599708",
                  "1647.287948",
                  "33945.36833",
                  "1.68566",
                  "52665.0",
                  "-26.791359295654303"
                ],
                [
                  "2019-01-02 18:00:00",
                  "66.9318",
                  "52.0153732299805",
                  "11649.02181",
                  "247.01132",
                  "3893.367304",
                  "0.0",
                  "0.0",
                  "1341.622648",
                  "35414.46146",
                  "-2.14424",
                  "53313.0",
                  "-14.916426770019498"
                ],
                [
                  "2019-01-02 19:00:00",
                  "41.2162",
                  "49.0191993713379",
                  "11712.16229",
                  "246.696932",
                  "3894.021436",
                  "0.0",
                  "0.0",
                  "892.246312",
                  "35377.1919",
                  "2.401672",
                  "52396.0",
                  "7.802999371337897"
                ],
                [
                  "2019-01-02 20:00:00",
                  "40.3369",
                  "49.094799041748",
                  "11802.12156",
                  "275.703976",
                  "3895.365856",
                  "0.0",
                  "0.0",
                  "544.153644",
                  "34717.37072",
                  "2.39128",
                  "51125.0",
                  "8.757899041747997"
                ],
                [
                  "2019-01-02 21:00:00",
                  "35.5165",
                  "38.3151359558105",
                  "11684.58332",
                  "277.337932",
                  "3895.42118",
                  "0.0",
                  "0.0",
                  "847.33536",
                  "32946.87372",
                  "1.697152",
                  "49288.0",
                  "2.7986359558104965"
                ],
                [
                  "2019-01-02 22:00:00",
                  "31.5755",
                  "36.8169250488281",
                  "11558.77353",
                  "275.119676",
                  "3893.64908",
                  "0.0",
                  "0.0",
                  "985.165264",
                  "30704.09202",
                  "-1.911472",
                  "46749.0",
                  "5.241425048828095"
                ],
                [
                  "2019-01-02 23:00:00",
                  "26.4935",
                  "30.2865982055664",
                  "11808.90794",
                  "276.018164",
                  "3892.330012",
                  "0.0",
                  "0.0",
                  "644.977968",
                  "28252.50481",
                  "1.073252",
                  "44381.0",
                  "3.793098205566398"
                ],
                [
                  "2019-01-03 00:00:00",
                  "26.6577",
                  "28.0744132995605",
                  "11447.44826",
                  "326.796432",
                  "3893.92314",
                  "0.0",
                  "0.0",
                  "1051.607656",
                  "26255.36574",
                  "-0.792896",
                  "42547.0",
                  "1.4167132995605023"
                ],
                [
                  "2019-01-03 01:00:00",
                  "24.3462",
                  "25.5825328826904",
                  "10882.30282",
                  "301.526784",
                  "3893.651784",
                  "0.0",
                  "0.0",
                  "1576.489276",
                  "24983.27008",
                  "0.819768",
                  "41478.0",
                  "1.2363328826904016"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 43848
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>23.1651</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>23.2113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>21.3244</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>20.3351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>19.2456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00               NaN           13.837562   \n",
              "2019-01-01 01:00:00               NaN           15.464869   \n",
              "2019-01-01 02:00:00               NaN           15.487720   \n",
              "2019-01-01 03:00:00               NaN           15.770092   \n",
              "2019-01-01 04:00:00               NaN           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00           23.1651                 NaN   \n",
              "2024-01-01 20:00:00           23.2113                 NaN   \n",
              "2024-01-01 21:00:00           21.3244                 NaN   \n",
              "2024-01-01 22:00:00           20.3351                 NaN   \n",
              "2024-01-01 23:00:00           19.2456                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "73e0d9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_dap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1a9b0f63",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "DAP_SystemLambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SCED_system_lambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_coal_and_lignite",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_hydro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_nuclear",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_power_storage",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_solar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_wind",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_natural_gas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_other",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Load_load",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "delta_price",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "cd37922e-2a40-4d95-a337-6958d9c4a5e0",
              "rows": [
                [
                  "2019-01-01 00:00:00",
                  "23.925",
                  "13.8375616073608",
                  "6116.41904",
                  "185.465296",
                  "3895.95194",
                  "0.0",
                  "0.0",
                  "14311.36445",
                  "12512.80815",
                  "2.534772",
                  "36951.0",
                  null
                ],
                [
                  "2019-01-01 01:00:00",
                  "23.314",
                  "15.4648694992065",
                  "6423.24236",
                  "186.667008",
                  "3894.973176",
                  "0.0",
                  "0.0",
                  "14298.52586",
                  "12434.13638",
                  "2.947464",
                  "37112.0",
                  null
                ],
                [
                  "2019-01-01 02:00:00",
                  "23.3475",
                  "15.4877195358276",
                  "6309.280752",
                  "187.408832",
                  "3894.733152",
                  "0.0",
                  "0.0",
                  "14030.82875",
                  "12797.25831",
                  "-1.954544",
                  "37154.0",
                  null
                ],
                [
                  "2019-01-01 03:00:00",
                  "23.0595",
                  "15.770092010498",
                  "6416.671292",
                  "187.817564",
                  "3894.714576",
                  "0.0",
                  "0.0",
                  "13610.13937",
                  "13279.01803",
                  "1.887324",
                  "37283.0",
                  null
                ],
                [
                  "2019-01-01 04:00:00",
                  "25.2672",
                  "16.0360851287842",
                  "6569.580884",
                  "186.990116",
                  "3892.748912",
                  "0.0",
                  "0.0",
                  "13414.14969",
                  "13585.26799",
                  "-0.2011",
                  "37817.0",
                  null
                ],
                [
                  "2019-01-01 05:00:00",
                  "28.8611",
                  "16.7470397949219",
                  "6806.102292",
                  "222.169372",
                  "3893.877024",
                  "0.0",
                  "0.0",
                  "12743.16529",
                  "14786.60827",
                  "2.955692",
                  "38763.0",
                  null
                ],
                [
                  "2019-01-01 06:00:00",
                  "39.4101",
                  "17.5206718444824",
                  "7356.916872",
                  "223.598596",
                  "3894.202416",
                  "0.0",
                  "0.0",
                  "11695.73501",
                  "16435.8807",
                  "4.032436",
                  "39849.0",
                  null
                ],
                [
                  "2019-01-01 07:00:00",
                  "39.1896",
                  "17.7318916320801",
                  "7627.659176",
                  "223.522816",
                  "3891.496004",
                  "0.0",
                  "0.0",
                  "10769.46719",
                  "17849.76048",
                  "2.988096",
                  "40410.0",
                  null
                ],
                [
                  "2019-01-01 08:00:00",
                  "36.3108",
                  "18.4140319824219",
                  "8034.6643",
                  "222.1581",
                  "3892.873952",
                  "0.0",
                  "15.504816",
                  "9749.372156",
                  "18761.96472",
                  "3.074772",
                  "40892.0",
                  null
                ],
                [
                  "2019-01-01 09:00:00",
                  "39.6983",
                  "19.588623046875",
                  "8861.727808",
                  "223.473352",
                  "3894.109608",
                  "0.0",
                  "73.208772",
                  "8688.958132",
                  "19735.37034",
                  "3.040152",
                  "41671.0",
                  null
                ],
                [
                  "2019-01-01 10:00:00",
                  "40.2148",
                  "20.7471313476563",
                  "9938.088416",
                  "223.699976",
                  "3890.997248",
                  "0.0",
                  "165.856592",
                  "7236.261324",
                  "20776.384",
                  "3.8969",
                  "42146.0",
                  null
                ],
                [
                  "2019-01-01 11:00:00",
                  "37.2478",
                  "21.3603363037109",
                  "10401.91125",
                  "200.562196",
                  "3892.734124",
                  "0.0",
                  "233.450596",
                  "6421.903592",
                  "21216.38172",
                  "3.608564",
                  "42206.0",
                  null
                ],
                [
                  "2019-01-01 12:00:00",
                  "34.5007",
                  "21.6746959686279",
                  "10843.79388",
                  "186.330668",
                  "3892.944372",
                  "0.0",
                  "311.36348",
                  "5665.944092",
                  "21339.63762",
                  "-0.050588",
                  "41807.0",
                  null
                ],
                [
                  "2019-01-01 13:00:00",
                  "34.7428",
                  "21.7823867797852",
                  "11049.00355",
                  "186.441272",
                  "3892.50776",
                  "0.0",
                  "259.819596",
                  "5217.935984",
                  "21018.28545",
                  "3.15518",
                  "41320.0",
                  null
                ],
                [
                  "2019-01-01 14:00:00",
                  "34.6144",
                  "21.9466972351074",
                  "11187.95622",
                  "186.049876",
                  "3891.574964",
                  "0.0",
                  "203.82868",
                  "4859.254484",
                  "20871.27624",
                  "1.594112",
                  "40949.0",
                  null
                ],
                [
                  "2019-01-01 15:00:00",
                  "34.4056",
                  "26.3067970275879",
                  "11535.01104",
                  "211.481304",
                  "3892.253344",
                  "0.0",
                  "110.826784",
                  "4233.964036",
                  "21118.54924",
                  "2.546792",
                  "40975.0",
                  null
                ],
                [
                  "2019-01-01 16:00:00",
                  "36.2957",
                  "26.8361930847168",
                  "11924.04599",
                  "249.026864",
                  "3892.451464",
                  "0.0",
                  "66.500996",
                  "3554.642004",
                  "21802.12896",
                  "3.056364",
                  "41783.0",
                  null
                ],
                [
                  "2019-01-01 17:00:00",
                  "64.5798",
                  "27.5510845184326",
                  "12276.57683",
                  "248.96194",
                  "3892.762276",
                  "0.0",
                  "15.013288",
                  "3354.061648",
                  "23212.87701",
                  "2.998796",
                  "43966.0",
                  null
                ],
                [
                  "2019-01-01 18:00:00",
                  "66.9318",
                  "33.4604682922363",
                  "12373.18407",
                  "221.384096",
                  "3892.680796",
                  "0.0",
                  "0.0",
                  "2992.843944",
                  "25837.25857",
                  "3.79044",
                  "45406.0",
                  null
                ],
                [
                  "2019-01-01 19:00:00",
                  "41.2162",
                  "34.9075584411621",
                  "12439.40505",
                  "221.815728",
                  "3892.293888",
                  "0.0",
                  "0.0",
                  "2857.59244",
                  "25935.07676",
                  "1.267524",
                  "45261.0",
                  null
                ],
                [
                  "2019-01-01 20:00:00",
                  "40.3369",
                  "34.0498199462891",
                  "12438.36693",
                  "195.830184",
                  "3892.080304",
                  "0.0",
                  "0.0",
                  "2759.597352",
                  "25786.21502",
                  "-1.325144",
                  "44875.0",
                  null
                ],
                [
                  "2019-01-01 21:00:00",
                  "35.5165",
                  "31.0697078704834",
                  "12465.79535",
                  "196.451852",
                  "3891.513288",
                  "0.0",
                  "0.0",
                  "2724.787952",
                  "24951.17857",
                  "-0.377196",
                  "43945.0",
                  null
                ],
                [
                  "2019-01-01 22:00:00",
                  "31.5755",
                  "31.1546306610107",
                  "12436.69127",
                  "158.890524",
                  "3890.599492",
                  "0.0",
                  "0.0",
                  "2434.006624",
                  "23910.70212",
                  "0.041472",
                  "42277.0",
                  null
                ],
                [
                  "2019-01-01 23:00:00",
                  "26.4935",
                  "26.8461532592773",
                  "11874.96931",
                  "159.464984",
                  "3891.757256",
                  "0.0",
                  "0.0",
                  "2510.4403",
                  "22597.71201",
                  "2.822164",
                  "40543.0",
                  null
                ],
                [
                  "2019-01-02 00:00:00",
                  "26.6577",
                  "26.1592845916748",
                  "11019.0404",
                  "211.80336",
                  "3891.427324",
                  "0.0",
                  "0.0",
                  "2556.493476",
                  "21857.30259",
                  "0.776324",
                  "39277.0",
                  "2.2342845916748004"
                ],
                [
                  "2019-01-02 01:00:00",
                  "24.3462",
                  "25.9841365814209",
                  "10388.7317",
                  "188.16956",
                  "3891.118712",
                  "0.0",
                  "0.0",
                  "2417.738312",
                  "21725.04409",
                  "1.218988",
                  "38589.0",
                  "2.6701365814208984"
                ],
                [
                  "2019-01-02 02:00:00",
                  "24.9133",
                  "25.3712673187256",
                  "10148.57656",
                  "187.471732",
                  "3890.877504",
                  "0.0",
                  "0.0",
                  "2693.351584",
                  "21409.53292",
                  "-2.470856",
                  "38431.0",
                  "2.0237673187256"
                ],
                [
                  "2019-01-02 03:00:00",
                  "24.4683",
                  "25.2762241363525",
                  "9846.024556",
                  "187.525788",
                  "3891.413216",
                  "0.0",
                  "0.0",
                  "3128.780528",
                  "21428.29015",
                  "-1.432144",
                  "38828.0",
                  "2.2167241363525"
                ],
                [
                  "2019-01-02 04:00:00",
                  "25.1232",
                  "24.5719661712646",
                  "9829.751588",
                  "188.180748",
                  "3892.101792",
                  "0.0",
                  "0.0",
                  "3289.184004",
                  "22151.42388",
                  "-3.166144",
                  "40043.0",
                  "-0.6952338287354003"
                ],
                [
                  "2019-01-02 05:00:00",
                  "30.1396",
                  "25.0743083953857",
                  "10341.36317",
                  "225.203888",
                  "3891.783612",
                  "0.0",
                  "0.0",
                  "3539.563424",
                  "23384.49495",
                  "-0.08526",
                  "42402.0",
                  "-3.786791604614301"
                ],
                [
                  "2019-01-02 06:00:00",
                  "55.3082",
                  "25.9785709381104",
                  "11733.04428",
                  "250.607476",
                  "3890.602976",
                  "0.0",
                  "0.0",
                  "2871.80052",
                  "25467.92225",
                  "0.570452",
                  "45219.0",
                  "-13.431529061889599"
                ],
                [
                  "2019-01-02 07:00:00",
                  "40.4756",
                  "29.2044925689697",
                  "12243.0151",
                  "247.146256",
                  "3889.973712",
                  "0.0",
                  "0.0",
                  "2553.030404",
                  "27772.4965",
                  "2.102536",
                  "47432.0",
                  "-9.985107431030297"
                ],
                [
                  "2019-01-02 08:00:00",
                  "36.2088",
                  "36.638427734375",
                  "12250.63438",
                  "248.447572",
                  "3890.307104",
                  "0.0",
                  "0.005384",
                  "2011.634756",
                  "29664.07621",
                  "2.383692",
                  "48598.0",
                  "0.3276277343749996"
                ],
                [
                  "2019-01-02 09:00:00",
                  "37.3772",
                  "40.1176872253418",
                  "12207.58335",
                  "263.57132",
                  "3895.736976",
                  "0.0",
                  "35.411584",
                  "2025.567152",
                  "30648.5328",
                  "-1.2047",
                  "49657.0",
                  "0.4193872253417936"
                ],
                [
                  "2019-01-02 10:00:00",
                  "33.4478",
                  "59.4540328979492",
                  "12269.39236",
                  "273.484616",
                  "3893.812596",
                  "0.0",
                  "107.043332",
                  "1867.155328",
                  "31570.85504",
                  "0.898424",
                  "50661.0",
                  "19.2392328979492"
                ],
                [
                  "2019-01-02 11:00:00",
                  "30.6697",
                  "62.8075675964355",
                  "12340.60632",
                  "230.893108",
                  "3894.783856",
                  "0.0",
                  "131.75698",
                  "1195.121152",
                  "33235.95221",
                  "1.521576",
                  "51295.0",
                  "25.5597675964355"
                ],
                [
                  "2019-01-02 12:00:00",
                  "27.9434",
                  "38.1134338378906",
                  "12180.95975",
                  "230.128864",
                  "3894.444364",
                  "0.0",
                  "147.411984",
                  "1308.978972",
                  "33378.0454",
                  "0.758804",
                  "51412.0",
                  "3.6127338378905947"
                ],
                [
                  "2019-01-02 13:00:00",
                  "27.0113",
                  "43.5680694580078",
                  "12255.0393",
                  "231.139796",
                  "3894.801384",
                  "0.0",
                  "212.907912",
                  "1337.093948",
                  "33392.38348",
                  "1.925832",
                  "51492.0",
                  "8.825269458007796"
                ],
                [
                  "2019-01-02 14:00:00",
                  "24.1565",
                  "36.8626899719238",
                  "12046.10978",
                  "230.807104",
                  "3893.390536",
                  "0.0",
                  "189.23948",
                  "1407.03348",
                  "33137.96618",
                  "2.24628",
                  "51264.0",
                  "2.2482899719237963"
                ],
                [
                  "2019-01-02 15:00:00",
                  "24.7873",
                  "32.3479118347168",
                  "11908.7674",
                  "267.818492",
                  "3894.09848",
                  "0.0",
                  "137.89176",
                  "2095.40284",
                  "32660.76262",
                  "1.693052",
                  "51152.0",
                  "-2.057688165283203"
                ],
                [
                  "2019-01-02 16:00:00",
                  "27.272",
                  "38.1546897888184",
                  "11771.16732",
                  "304.06906",
                  "3893.31228",
                  "0.0",
                  "71.420348",
                  "1784.647496",
                  "33119.553",
                  "1.7932",
                  "51384.0",
                  "1.8589897888184055"
                ],
                [
                  "2019-01-02 17:00:00",
                  "41.3426",
                  "37.7884407043457",
                  "11733.58142",
                  "276.826592",
                  "3892.46698",
                  "0.0",
                  "20.599708",
                  "1647.287948",
                  "33945.36833",
                  "1.68566",
                  "52665.0",
                  "-26.791359295654303"
                ],
                [
                  "2019-01-02 18:00:00",
                  "44.7316",
                  "52.0153732299805",
                  "11649.02181",
                  "247.01132",
                  "3893.367304",
                  "0.0",
                  "0.0",
                  "1341.622648",
                  "35414.46146",
                  "-2.14424",
                  "53313.0",
                  "-14.916426770019498"
                ],
                [
                  "2019-01-02 19:00:00",
                  "34.7473",
                  "49.0191993713379",
                  "11712.16229",
                  "246.696932",
                  "3894.021436",
                  "0.0",
                  "0.0",
                  "892.246312",
                  "35377.1919",
                  "2.401672",
                  "52396.0",
                  "7.802999371337897"
                ],
                [
                  "2019-01-02 20:00:00",
                  "33.7482",
                  "49.094799041748",
                  "11802.12156",
                  "275.703976",
                  "3895.365856",
                  "0.0",
                  "0.0",
                  "544.153644",
                  "34717.37072",
                  "2.39128",
                  "51125.0",
                  "8.757899041747997"
                ],
                [
                  "2019-01-02 21:00:00",
                  "30.1116",
                  "38.3151359558105",
                  "11684.58332",
                  "277.337932",
                  "3895.42118",
                  "0.0",
                  "0.0",
                  "847.33536",
                  "32946.87372",
                  "1.697152",
                  "49288.0",
                  "2.7986359558104965"
                ],
                [
                  "2019-01-02 22:00:00",
                  "27.0621",
                  "36.8169250488281",
                  "11558.77353",
                  "275.119676",
                  "3893.64908",
                  "0.0",
                  "0.0",
                  "985.165264",
                  "30704.09202",
                  "-1.911472",
                  "46749.0",
                  "5.241425048828095"
                ],
                [
                  "2019-01-02 23:00:00",
                  "23.5828",
                  "30.2865982055664",
                  "11808.90794",
                  "276.018164",
                  "3892.330012",
                  "0.0",
                  "0.0",
                  "644.977968",
                  "28252.50481",
                  "1.073252",
                  "44381.0",
                  "3.793098205566398"
                ],
                [
                  "2019-01-03 00:00:00",
                  "22.1953",
                  "28.0744132995605",
                  "11447.44826",
                  "326.796432",
                  "3893.92314",
                  "0.0",
                  "0.0",
                  "1051.607656",
                  "26255.36574",
                  "-0.792896",
                  "42547.0",
                  "1.4167132995605023"
                ],
                [
                  "2019-01-03 01:00:00",
                  "22.1915",
                  "25.5825328826904",
                  "10882.30282",
                  "301.526784",
                  "3893.651784",
                  "0.0",
                  "0.0",
                  "1576.489276",
                  "24983.27008",
                  "0.819768",
                  "41478.0",
                  "1.2363328826904016"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 43848
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>23.9250</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>23.3140</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>23.3475</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>23.0595</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>25.2672</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00           23.9250           13.837562   \n",
              "2019-01-01 01:00:00           23.3140           15.464869   \n",
              "2019-01-01 02:00:00           23.3475           15.487720   \n",
              "2019-01-01 03:00:00           23.0595           15.770092   \n",
              "2019-01-01 04:00:00           25.2672           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00               NaN                 NaN   \n",
              "2024-01-01 20:00:00               NaN                 NaN   \n",
              "2024-01-01 21:00:00               NaN                 NaN   \n",
              "2024-01-01 22:00:00               NaN                 NaN   \n",
              "2024-01-01 23:00:00               NaN                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e5902795",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.split_data(feature_columns=['DAP_SystemLambda', 'SCED_system_lambda','Fuel_solar','Fuel_wind','Load_load'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "857623c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.standardize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "89475b19",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9aff786e",
      "metadata": {},
      "outputs": [],
      "source": [
        "df, x_train_lstm, y_train_lstm, x_val_lstm, y_val_lstm, x_test_lstm, y_test_lstm = processor.get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8c965398",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26089, 168, 5)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_lstm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e02c1f06",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_val_lstm = y_val_lstm.squeeze(-1)\n",
        "y_test_lstm = y_test_lstm.squeeze(-1)\n",
        "y_train_lstm = y_train_lstm.squeeze(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ed635d10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train: (26089, 168, 5)\n",
            "y_train: (26089, 24)\n"
          ]
        }
      ],
      "source": [
        "print(\"x_train:\", x_train_lstm.shape)   # æœŸæœ› (N, 32, 2) æˆ– (N, 24, 2)\n",
        "print(\"y_train:\", y_train_lstm.shape)   # æœŸæœ› (N, 32)   æˆ– (N, 24)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaeebb4",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c0fde9ac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 1.0738, Eval Loss = 0.2642\n",
            "Epoch 2: Train Loss = 1.0457, Eval Loss = 0.2659\n",
            "Epoch 3: Train Loss = 1.0325, Eval Loss = 0.2647\n",
            "Epoch 4: Train Loss = 1.0243, Eval Loss = 0.2653\n",
            "Epoch 5: Train Loss = 1.0186, Eval Loss = 0.2647\n",
            "Epoch 6: Train Loss = 1.0141, Eval Loss = 0.2646\n",
            "Epoch 7: Train Loss = 1.0107, Eval Loss = 0.2662\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 27\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fluctuation_loss  \u001b[38;5;66;03m# or define it above in your notebook\u001b[39;00m\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mcnn_mlp,\n\u001b[1;32m     19\u001b[0m     features_training_data\u001b[38;5;241m=\u001b[39mx_train_lstm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pred, target: fluctuation_loss(pred, target, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5193139573153885e-05\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/ModelTrainer.py:44\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, epochs, batch_size, patience, learning_rate)\u001b[0m\n\u001b[1;32m     41\u001b[0m batch_x, batch_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train[indices], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train[indices]\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, batch_y)\n\u001b[1;32m     46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/CNN.py:38\u001b[0m, in \u001b[0;36mCNN2D_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)                      \u001b[38;5;66;03m# (B, C, 168)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_pool(x)                 \u001b[38;5;66;03m# (B, C, 24)\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                      \u001b[38;5;66;03m# (B, 1, 24)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from CNN import CNN2D_Model   # æ ¹æ®ä½ çš„æ–‡ä»¶ç»“æž„ä¿æŒä¸å˜\n",
        "\n",
        "# 1. é€‰æ‹©è®¾å¤‡\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. å®žä¾‹åŒ–æ¨¡åž‹ï¼ˆç¬¦åˆæ–°ç­¾åï¼‰\n",
        "cnn_mlp = CNN2D_Model(\n",
        "    n_features=5,            # è¾“å…¥ç‰¹å¾æ•°\n",
        "    horizon=24,              # é¢„æµ‹æ­¥é•¿\n",
        "    cnn_channels=32,         # å·ç§¯é€šé“\n",
        ").to(device)\n",
        "\n",
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss  # or define it above in your notebook\n",
        "\n",
        "trainer = ModelTrainer(\n",
        "    model=cnn_mlp,\n",
        "    features_training_data=x_train_lstm,\n",
        "    target_training_data=y_train_lstm,\n",
        "    features_eval_data=x_val_lstm,\n",
        "    target_eval_data=y_val_lstm,\n",
        "    device=device,\n",
        "    loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=0.2)\n",
        ")\n",
        "\n",
        "trainer.train(epochs=100, batch_size=32, patience=50, learning_rate=1.5193139573153885e-05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e68dccd2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6c690761",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 20:15:05,215] A new study created in memory with name: no-name-390fd262-b461-4723-8c64-1158ec0f9eb1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_3976733/3306160659.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr           = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_3976733/3306160659.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  alpha        = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 1.0691, Eval Loss = 0.2769\n",
            "Epoch 2: Train Loss = 1.0304, Eval Loss = 0.2775\n",
            "Epoch 3: Train Loss = 1.0214, Eval Loss = 0.2763\n",
            "Epoch 4: Train Loss = 1.0152, Eval Loss = 0.2763\n",
            "Epoch 5: Train Loss = 1.0103, Eval Loss = 0.2730\n",
            "Epoch 6: Train Loss = 1.0061, Eval Loss = 0.2726\n",
            "Epoch 7: Train Loss = 1.0018, Eval Loss = 0.2710\n",
            "Epoch 8: Train Loss = 0.9982, Eval Loss = 0.2745\n",
            "Epoch 9: Train Loss = 0.9946, Eval Loss = 0.2715\n",
            "Epoch 10: Train Loss = 0.9904, Eval Loss = 0.2721\n",
            "Epoch 11: Train Loss = 0.9869, Eval Loss = 0.2726\n",
            "Epoch 12: Train Loss = 0.9839, Eval Loss = 0.2727\n",
            "Epoch 13: Train Loss = 0.9804, Eval Loss = 0.2729\n",
            "Epoch 14: Train Loss = 0.9777, Eval Loss = 0.2746\n",
            "Epoch 15: Train Loss = 0.9742, Eval Loss = 0.2751\n",
            "Epoch 16: Train Loss = 0.9710, Eval Loss = 0.2749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 20:15:27,552] Trial 0 finished with value: 0.2752312123775482 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 1.3625826647597739e-05, 'alpha': 0.2461291652516053}. Best is trial 0 with value: 0.2752312123775482.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9674, Eval Loss = 0.2752\n",
            "Early stopping triggered at epoch 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W 2025-05-10 20:15:28,940] Trial 1 failed with parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 256, 'n_layers': 3, 'lr': 1.527014030402518e-05, 'alpha': 0.21688984645277587} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 139.72 GiB of which 341.69 MiB is free. Process 4118226 has 132.95 GiB memory in use. Process 3956204 has 4.80 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 920.66 MiB is allocated by PyTorch, and 109.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)').\n",
            "Traceback (most recent call last):\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/ephnvme/weiliang/cache/tmpdir/ipykernel_3976733/3306160659.py\", line 43, in objective\n",
            "    trainer.train(epochs=50, batch_size=32, patience=10, learning_rate=lr)\n",
            "  File \"/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/ModelTrainer.py\", line 58, in train\n",
            "    outputs = self.model(self.x_eval)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/CNN.py\", line 34, in forward\n",
            "    x = self.conv_block(x)                # (B, C, 1, 168)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 240, in forward\n",
            "    input = module(input)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
            "    return F.conv2d(\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 139.72 GiB of which 341.69 MiB is free. Process 4118226 has 132.95 GiB memory in use. Process 3956204 has 4.80 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 920.66 MiB is allocated by PyTorch, and 109.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "[W 2025-05-10 20:15:28,941] Trial 1 failed with value None.\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 139.72 GiB of which 341.69 MiB is free. Process 4118226 has 132.95 GiB memory in use. Process 3956204 has 4.80 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 920.66 MiB is allocated by PyTorch, and 109.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# ------------- åˆ›å»ºå¹¶è¿è¡Œ Optuna Study -------------------\u001b[39;00m\n\u001b[1;32m     49\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m                             pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mHyperbandPruner())\n\u001b[0;32m---> 51\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæœ€ä½³ trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæœ€ä½³ eval_loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[21], line 43\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     32\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer(\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     34\u001b[0m     features_training_data\u001b[38;5;241m=\u001b[39mx_train_lstm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     loss_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m pred, target: fluctuation_loss(pred, target, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# ---- è®­ç»ƒï¼ŒæŽ§åˆ¶è½®æ•°åˆ«å¤ªå¤§é¿å…å•æ¬¡ trial è¿‡æ…¢ ----\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# ---- è¿”å›žéªŒè¯é›†æœ€åŽä¸€æ¬¡ (æˆ–æœ€ä¼˜) æŸå¤± ----\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/ModelTrainer.py:58\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, epochs, batch_size, patience, learning_rate)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 58\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     eval_loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_eval)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(eval_loss)\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/CNN.py:34\u001b[0m, in \u001b[0;36mCNN2D_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):                \u001b[38;5;66;03m# x: (B, 168, 2)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)   \u001b[38;5;66;03m# (B, 1, 2, 168)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                \u001b[38;5;66;03m# (B, C, 1, 168)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)                      \u001b[38;5;66;03m# (B, C, 168)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_pool(x)                 \u001b[38;5;66;03m# (B, C, 24)\u001b[39;00m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/ephnvme/weiliang/miniforge/envs/eng/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 690.00 MiB. GPU 0 has a total capacity of 139.72 GiB of which 341.69 MiB is free. Process 4118226 has 132.95 GiB memory in use. Process 3956204 has 4.80 GiB memory in use. Including non-PyTorch memory, this process has 1.62 GiB memory in use. Of the allocated memory 920.66 MiB is allocated by PyTorch, and 109.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "import torch\n",
        "from CNN import CNN2D_Model\n",
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss\n",
        "\n",
        "\n",
        "\n",
        "# ------------- è®¾å¤‡ -------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ------------- Optuna ç›®æ ‡å‡½æ•° -------------------\n",
        "def objective(trial):\n",
        "    # ---- è¶…å‚æ•°æœç´¢ç©ºé—´ ----\n",
        "    cnn_channels = trial.suggest_categorical(\"cnn_channels\", [32, 64, 128])\n",
        "    hidden_dim   = trial.suggest_categorical(\"mlp_hidden_dim\", [128, 256, 512])\n",
        "    n_layers     = trial.suggest_int(\"n_layers\", 2, 4)\n",
        "    lr           = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    alpha        = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n",
        "\n",
        "    hidden_dims = [hidden_dim] * n_layers   # MLP éšå±‚åˆ—è¡¨\n",
        "\n",
        "    # ---- æž„å»ºæ¨¡åž‹ ----\n",
        "    model = CNN2D_Model(\n",
        "        n_features=5,        # è¾“å…¥ç‰¹å¾æ•°\n",
        "        horizon=24,          # é¢„æµ‹æ­¥é•¿\n",
        "        cnn_channels=cnn_channels,\n",
        "        # hidden_dims=hidden_dims\n",
        "    ).to(device)\n",
        "\n",
        "    # ---- è®­ç»ƒå™¨ ----\n",
        "    trainer = ModelTrainer(\n",
        "        model=model,\n",
        "        features_training_data=x_train_lstm,\n",
        "        target_training_data=y_train_lstm,\n",
        "        features_eval_data=x_val_lstm,\n",
        "        target_eval_data=y_val_lstm,\n",
        "        device=device,\n",
        "        loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=alpha)\n",
        "    )\n",
        "\n",
        "    # ---- è®­ç»ƒï¼ŒæŽ§åˆ¶è½®æ•°åˆ«å¤ªå¤§é¿å…å•æ¬¡ trial è¿‡æ…¢ ----\n",
        "    trainer.train(epochs=50, batch_size=32, patience=10, learning_rate=lr)\n",
        "\n",
        "    # ---- è¿”å›žéªŒè¯é›†æœ€åŽä¸€æ¬¡ (æˆ–æœ€ä¼˜) æŸå¤± ----\n",
        "    return trainer.history['eval_loss'][-1]\n",
        "\n",
        "# ------------- åˆ›å»ºå¹¶è¿è¡Œ Optuna Study -------------------\n",
        "study = optuna.create_study(direction=\"minimize\",\n",
        "                            pruner=optuna.pruners.HyperbandPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"æœ€ä½³ trial:\", study.best_trial.params)\n",
        "print(\"æœ€ä½³ eval_loss:\", study.best_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "43d4194c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:22:28,049] A new study created in memory with name: no-name-4cf8ccbe-9a92-4da1-8967-304230d80faf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_3214566/1296943527.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr           = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_3214566/1296943527.py:19: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  alpha        = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 1.0401, Eval Loss = 0.2596\n",
            "Epoch 2: Train Loss = 1.0031, Eval Loss = 0.2573\n",
            "Epoch 3: Train Loss = 0.9958, Eval Loss = 0.2546\n",
            "Epoch 4: Train Loss = 0.9976, Eval Loss = 0.2549\n",
            "Epoch 5: Train Loss = 0.9886, Eval Loss = 0.2543\n",
            "Epoch 6: Train Loss = 0.9863, Eval Loss = 0.2543\n",
            "Epoch 7: Train Loss = 0.9831, Eval Loss = 0.2549\n",
            "Epoch 8: Train Loss = 0.9809, Eval Loss = 0.2568\n",
            "Epoch 9: Train Loss = 0.9799, Eval Loss = 0.2580\n",
            "Epoch 10: Train Loss = 1.0064, Eval Loss = 0.2585\n",
            "Epoch 11: Train Loss = 0.9758, Eval Loss = 0.2622\n",
            "Epoch 12: Train Loss = 0.9729, Eval Loss = 0.2638\n",
            "Epoch 13: Train Loss = 0.9700, Eval Loss = 0.2644\n",
            "Epoch 14: Train Loss = 0.9672, Eval Loss = 0.2700\n",
            "Epoch 15: Train Loss = 0.9648, Eval Loss = 0.2698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:22:55,674] Trial 0 finished with value: 0.2738994359970093 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.6762006154950508e-05, 'alpha': 0.16003437788590633}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.9614, Eval Loss = 0.2739\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 1.1736, Eval Loss = 0.3127\n",
            "Epoch 2: Train Loss = 1.1410, Eval Loss = 0.3133\n",
            "Epoch 3: Train Loss = 1.1315, Eval Loss = 0.3186\n",
            "Epoch 4: Train Loss = 1.1269, Eval Loss = 0.3226\n",
            "Epoch 5: Train Loss = 1.1223, Eval Loss = 0.3312\n",
            "Epoch 6: Train Loss = 1.1158, Eval Loss = 0.3442\n",
            "Epoch 7: Train Loss = 1.1075, Eval Loss = 0.3790\n",
            "Epoch 8: Train Loss = 1.1000, Eval Loss = 0.4209\n",
            "Epoch 9: Train Loss = 1.0845, Eval Loss = 0.4322\n",
            "Epoch 10: Train Loss = 1.0725, Eval Loss = 0.5102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:23:17,180] Trial 1 finished with value: 0.6552785038948059 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 3.774761179305267e-05, 'alpha': 0.4976820489482745}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 1.0580, Eval Loss = 0.6553\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0900, Eval Loss = 0.2904\n",
            "Epoch 2: Train Loss = 1.0629, Eval Loss = 0.3600\n",
            "Epoch 3: Train Loss = 1.0162, Eval Loss = 0.7473\n",
            "Epoch 4: Train Loss = 0.9804, Eval Loss = 1.2394\n",
            "Epoch 5: Train Loss = 0.9599, Eval Loss = 1.4431\n",
            "Epoch 6: Train Loss = 0.9369, Eval Loss = 3.3610\n",
            "Epoch 7: Train Loss = 0.9281, Eval Loss = 5.8393\n",
            "Epoch 8: Train Loss = 0.9222, Eval Loss = 3.7979\n",
            "Epoch 9: Train Loss = 0.9164, Eval Loss = 5.5244\n",
            "Epoch 10: Train Loss = 0.9095, Eval Loss = 3.0783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:23:38,969] Trial 2 finished with value: 5.323314666748047 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 256, 'n_layers': 3, 'lr': 8.328138787792279e-05, 'alpha': 0.35678627164814514}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.9075, Eval Loss = 5.3233\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.1752, Eval Loss = 0.3077\n",
            "Epoch 2: Train Loss = 1.1410, Eval Loss = 0.3058\n",
            "Epoch 3: Train Loss = 1.1311, Eval Loss = 0.3076\n",
            "Epoch 4: Train Loss = 1.1263, Eval Loss = 0.3092\n",
            "Epoch 5: Train Loss = 1.1218, Eval Loss = 0.3105\n",
            "Epoch 6: Train Loss = 1.1181, Eval Loss = 0.3109\n",
            "Epoch 7: Train Loss = 1.1163, Eval Loss = 0.3162\n",
            "Epoch 8: Train Loss = 1.1115, Eval Loss = 0.3218\n",
            "Epoch 9: Train Loss = 1.1086, Eval Loss = 0.3288\n",
            "Epoch 10: Train Loss = 1.1038, Eval Loss = 0.3279\n",
            "Epoch 11: Train Loss = 1.1011, Eval Loss = 0.3423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:24:05,176] Trial 3 finished with value: 0.36020201444625854 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 4, 'lr': 2.243074448120802e-05, 'alpha': 0.47293332571801117}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 1.0953, Eval Loss = 0.3602\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0880, Eval Loss = 0.3236\n",
            "Epoch 2: Train Loss = 0.9967, Eval Loss = 1.7780\n",
            "Epoch 3: Train Loss = 0.9324, Eval Loss = 3.7947\n",
            "Epoch 4: Train Loss = 0.9090, Eval Loss = 4.0085\n",
            "Epoch 5: Train Loss = 0.9080, Eval Loss = 2.8146\n",
            "Epoch 6: Train Loss = 0.8991, Eval Loss = 2.2502\n",
            "Epoch 7: Train Loss = 0.8903, Eval Loss = 2.9950\n",
            "Epoch 8: Train Loss = 0.8864, Eval Loss = 3.7222\n",
            "Epoch 9: Train Loss = 0.8855, Eval Loss = 2.5776\n",
            "Epoch 10: Train Loss = 0.8838, Eval Loss = 1.2630\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:24:23,733] Trial 4 finished with value: 1.8486249446868896 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 0.0009389849331872621, 'alpha': 0.3114460248023588}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.8828, Eval Loss = 1.8486\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0497, Eval Loss = 0.2780\n",
            "Epoch 2: Train Loss = 0.8710, Eval Loss = 2.3446\n",
            "Epoch 3: Train Loss = 0.8344, Eval Loss = 2.3367\n",
            "Epoch 4: Train Loss = 0.8244, Eval Loss = 1.3790\n",
            "Epoch 5: Train Loss = 0.8066, Eval Loss = 1.0408\n",
            "Epoch 6: Train Loss = 0.8013, Eval Loss = 2.0789\n",
            "Epoch 7: Train Loss = 0.7916, Eval Loss = 1.5370\n",
            "Epoch 8: Train Loss = 0.7815, Eval Loss = 0.9965\n",
            "Epoch 9: Train Loss = 0.7814, Eval Loss = 0.5327\n",
            "Epoch 10: Train Loss = 0.7764, Eval Loss = 1.6482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:24:45,743] Trial 5 finished with value: 0.45797789096832275 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 512, 'n_layers': 3, 'lr': 0.0009877535799774706, 'alpha': 0.10370899111345988}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.7790, Eval Loss = 0.4580\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0285, Eval Loss = 0.2868\n",
            "Epoch 2: Train Loss = 0.9586, Eval Loss = 0.9602\n",
            "Epoch 3: Train Loss = 0.8987, Eval Loss = 1.6639\n",
            "Epoch 4: Train Loss = 0.8758, Eval Loss = 1.9377\n",
            "Epoch 5: Train Loss = 0.8626, Eval Loss = 3.6878\n",
            "Epoch 6: Train Loss = 0.8550, Eval Loss = 2.8572\n",
            "Epoch 7: Train Loss = 0.8501, Eval Loss = 4.2173\n",
            "Epoch 8: Train Loss = 0.8429, Eval Loss = 2.4840\n",
            "Epoch 9: Train Loss = 0.8439, Eval Loss = 1.9436\n",
            "Epoch 10: Train Loss = 0.8390, Eval Loss = 4.2260\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:25:04,869] Trial 6 finished with value: 3.0724120140075684 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 0.00032460776745863725, 'alpha': 0.2135471698426691}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.8347, Eval Loss = 3.0724\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0634, Eval Loss = 0.2792\n",
            "Epoch 2: Train Loss = 1.0169, Eval Loss = 0.6528\n",
            "Epoch 3: Train Loss = 0.9422, Eval Loss = 2.5689\n",
            "Epoch 4: Train Loss = 0.9114, Eval Loss = 2.9116\n",
            "Epoch 5: Train Loss = 0.8858, Eval Loss = 3.2715\n",
            "Epoch 6: Train Loss = 0.8906, Eval Loss = 3.9184\n",
            "Epoch 7: Train Loss = 0.8876, Eval Loss = 2.9558\n",
            "Epoch 8: Train Loss = 0.8814, Eval Loss = 4.1064\n",
            "Epoch 9: Train Loss = 0.8823, Eval Loss = 6.1658\n",
            "Epoch 10: Train Loss = 0.8720, Eval Loss = 2.8486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:25:29,956] Trial 7 finished with value: 2.6094090938568115 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 256, 'n_layers': 4, 'lr': 0.000156440888972571, 'alpha': 0.28373447894176496}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.8688, Eval Loss = 2.6094\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0967, Eval Loss = 0.2800\n",
            "Epoch 2: Train Loss = 1.0627, Eval Loss = 0.2793\n",
            "Epoch 3: Train Loss = 1.0576, Eval Loss = 0.2818\n",
            "Epoch 4: Train Loss = 1.0474, Eval Loss = 0.2851\n",
            "Epoch 5: Train Loss = 1.0431, Eval Loss = 0.3014\n",
            "Epoch 6: Train Loss = 1.0338, Eval Loss = 0.3035\n",
            "Epoch 7: Train Loss = 1.0152, Eval Loss = 0.3425\n",
            "Epoch 8: Train Loss = 0.9941, Eval Loss = 0.4293\n",
            "Epoch 9: Train Loss = 0.9763, Eval Loss = 0.6442\n",
            "Epoch 10: Train Loss = 0.9557, Eval Loss = 0.5496\n",
            "Epoch 11: Train Loss = 0.9512, Eval Loss = 0.9528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:25:57,622] Trial 8 finished with value: 0.9972115159034729 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 512, 'n_layers': 4, 'lr': 1.2312050220378737e-05, 'alpha': 0.3118332552570817}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9343, Eval Loss = 0.9972\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0934, Eval Loss = 0.3070\n",
            "Epoch 2: Train Loss = 1.0597, Eval Loss = 0.4037\n",
            "Epoch 3: Train Loss = 0.9873, Eval Loss = 0.8607\n",
            "Epoch 4: Train Loss = 0.9582, Eval Loss = 4.6335\n",
            "Epoch 5: Train Loss = 0.9418, Eval Loss = 4.2211\n",
            "Epoch 6: Train Loss = 0.9258, Eval Loss = 1.4237\n",
            "Epoch 7: Train Loss = 0.9209, Eval Loss = 2.3481\n",
            "Epoch 8: Train Loss = 0.9252, Eval Loss = 5.5265\n",
            "Epoch 9: Train Loss = 0.9128, Eval Loss = 1.7031\n",
            "Epoch 10: Train Loss = 0.9077, Eval Loss = 5.0235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:26:19,851] Trial 9 finished with value: 4.124166488647461 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 256, 'n_layers': 3, 'lr': 0.00014315138645761217, 'alpha': 0.36982741411872355}. Best is trial 0 with value: 0.2738994359970093.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.9109, Eval Loss = 4.1242\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0325, Eval Loss = 0.2519\n",
            "Epoch 2: Train Loss = 0.9938, Eval Loss = 0.2505\n",
            "Epoch 3: Train Loss = 0.9831, Eval Loss = 0.2489\n",
            "Epoch 4: Train Loss = 0.9792, Eval Loss = 0.2490\n",
            "Epoch 5: Train Loss = 0.9758, Eval Loss = 0.2498\n",
            "Epoch 6: Train Loss = 0.9738, Eval Loss = 0.2494\n",
            "Epoch 7: Train Loss = 0.9716, Eval Loss = 0.2499\n",
            "Epoch 8: Train Loss = 0.9693, Eval Loss = 0.2507\n",
            "Epoch 9: Train Loss = 0.9675, Eval Loss = 0.2513\n",
            "Epoch 10: Train Loss = 0.9667, Eval Loss = 0.2516\n",
            "Epoch 11: Train Loss = 0.9637, Eval Loss = 0.2540\n",
            "Epoch 12: Train Loss = 0.9618, Eval Loss = 0.2562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:26:42,347] Trial 10 finished with value: 0.2556920051574707 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.1523163231932351e-05, 'alpha': 0.1302652523073275}. Best is trial 10 with value: 0.2556920051574707.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.9598, Eval Loss = 0.2557\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 1.0325, Eval Loss = 0.2501\n",
            "Epoch 2: Train Loss = 0.9943, Eval Loss = 0.2487\n",
            "Epoch 3: Train Loss = 0.9811, Eval Loss = 0.2472\n",
            "Epoch 4: Train Loss = 0.9758, Eval Loss = 0.2453\n",
            "Epoch 5: Train Loss = 0.9707, Eval Loss = 0.2445\n",
            "Epoch 6: Train Loss = 0.9682, Eval Loss = 0.2446\n",
            "Epoch 7: Train Loss = 0.9653, Eval Loss = 0.2450\n",
            "Epoch 8: Train Loss = 0.9631, Eval Loss = 0.2454\n",
            "Epoch 9: Train Loss = 0.9735, Eval Loss = 0.2461\n",
            "Epoch 10: Train Loss = 0.9599, Eval Loss = 0.2468\n",
            "Epoch 11: Train Loss = 0.9584, Eval Loss = 0.2478\n",
            "Epoch 12: Train Loss = 0.9572, Eval Loss = 0.2498\n",
            "Epoch 13: Train Loss = 0.9560, Eval Loss = 0.2492\n",
            "Epoch 14: Train Loss = 0.9542, Eval Loss = 0.2494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:27:08,236] Trial 11 finished with value: 0.2520657777786255 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.0087005075559585e-05, 'alpha': 0.10213791182385862}. Best is trial 11 with value: 0.2520657777786255.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss = 0.9535, Eval Loss = 0.2521\n",
            "Early stopping triggered at epoch 15\n",
            "Epoch 1: Train Loss = 1.0175, Eval Loss = 0.2502\n",
            "Epoch 2: Train Loss = 0.9868, Eval Loss = 0.2493\n",
            "Epoch 3: Train Loss = 0.9777, Eval Loss = 0.2486\n",
            "Epoch 4: Train Loss = 0.9726, Eval Loss = 0.2469\n",
            "Epoch 5: Train Loss = 0.9693, Eval Loss = 0.2471\n",
            "Epoch 6: Train Loss = 0.9670, Eval Loss = 0.2462\n",
            "Epoch 7: Train Loss = 0.9649, Eval Loss = 0.2460\n",
            "Epoch 8: Train Loss = 0.9633, Eval Loss = 0.2464\n",
            "Epoch 9: Train Loss = 0.9616, Eval Loss = 0.2468\n",
            "Epoch 10: Train Loss = 0.9603, Eval Loss = 0.2472\n",
            "Epoch 11: Train Loss = 0.9595, Eval Loss = 0.2474\n",
            "Epoch 12: Train Loss = 0.9579, Eval Loss = 0.2484\n",
            "Epoch 13: Train Loss = 0.9559, Eval Loss = 0.2492\n",
            "Epoch 14: Train Loss = 0.9555, Eval Loss = 0.2490\n",
            "Epoch 15: Train Loss = 0.9531, Eval Loss = 0.2502\n",
            "Epoch 16: Train Loss = 0.9529, Eval Loss = 0.2502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:27:37,603] Trial 12 finished with value: 0.25116702914237976 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.0143567282057281e-05, 'alpha': 0.11162229615146242}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9508, Eval Loss = 0.2512\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 1.0366, Eval Loss = 0.2618\n",
            "Epoch 2: Train Loss = 1.0076, Eval Loss = 0.2605\n",
            "Epoch 3: Train Loss = 0.9991, Eval Loss = 0.2646\n",
            "Epoch 4: Train Loss = 0.9887, Eval Loss = 0.2652\n",
            "Epoch 5: Train Loss = 0.9814, Eval Loss = 0.2719\n",
            "Epoch 6: Train Loss = 0.9715, Eval Loss = 0.3081\n",
            "Epoch 7: Train Loss = 0.9615, Eval Loss = 0.3048\n",
            "Epoch 8: Train Loss = 0.9590, Eval Loss = 0.3216\n",
            "Epoch 9: Train Loss = 0.9409, Eval Loss = 0.3236\n",
            "Epoch 10: Train Loss = 0.9302, Eval Loss = 0.4368\n",
            "Epoch 11: Train Loss = 0.9217, Eval Loss = 0.4080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:27:58,526] Trial 13 finished with value: 0.5060582756996155 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 4.240373909393719e-05, 'alpha': 0.19695620419920262}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9128, Eval Loss = 0.5061\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0581, Eval Loss = 0.2690\n",
            "Epoch 2: Train Loss = 1.0269, Eval Loss = 0.2666\n",
            "Epoch 3: Train Loss = 1.0183, Eval Loss = 0.2668\n",
            "Epoch 4: Train Loss = 1.0134, Eval Loss = 0.2692\n",
            "Epoch 5: Train Loss = 1.0102, Eval Loss = 0.2718\n",
            "Epoch 6: Train Loss = 1.0042, Eval Loss = 0.2740\n",
            "Epoch 7: Train Loss = 1.0004, Eval Loss = 0.2832\n",
            "Epoch 8: Train Loss = 0.9957, Eval Loss = 0.2832\n",
            "Epoch 9: Train Loss = 0.9923, Eval Loss = 0.3011\n",
            "Epoch 10: Train Loss = 0.9858, Eval Loss = 0.3032\n",
            "Epoch 11: Train Loss = 0.9805, Eval Loss = 0.3218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:28:19,496] Trial 14 finished with value: 0.3330986201763153 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 3.1953039916194004e-05, 'alpha': 0.2286221403165182}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9732, Eval Loss = 0.3331\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0442, Eval Loss = 0.2582\n",
            "Epoch 2: Train Loss = 1.0087, Eval Loss = 0.2574\n",
            "Epoch 3: Train Loss = 1.0011, Eval Loss = 0.2566\n",
            "Epoch 4: Train Loss = 0.9971, Eval Loss = 0.2560\n",
            "Epoch 5: Train Loss = 0.9967, Eval Loss = 0.2553\n",
            "Epoch 6: Train Loss = 0.9910, Eval Loss = 0.2544\n",
            "Epoch 7: Train Loss = 0.9887, Eval Loss = 0.2543\n",
            "Epoch 8: Train Loss = 0.9943, Eval Loss = 0.2540\n",
            "Epoch 9: Train Loss = 0.9852, Eval Loss = 0.2542\n",
            "Epoch 10: Train Loss = 0.9831, Eval Loss = 0.2551\n",
            "Epoch 11: Train Loss = 0.9828, Eval Loss = 0.2550\n",
            "Epoch 12: Train Loss = 0.9818, Eval Loss = 0.2556\n",
            "Epoch 13: Train Loss = 0.9803, Eval Loss = 0.2571\n",
            "Epoch 14: Train Loss = 0.9794, Eval Loss = 0.2568\n",
            "Epoch 15: Train Loss = 0.9778, Eval Loss = 0.2579\n",
            "Epoch 16: Train Loss = 0.9766, Eval Loss = 0.2577\n",
            "Epoch 17: Train Loss = 0.9766, Eval Loss = 0.2581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:28:50,555] Trial 15 finished with value: 0.2595260441303253 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.0036313148608122e-05, 'alpha': 0.16043247549075626}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss = 0.9746, Eval Loss = 0.2595\n",
            "Early stopping triggered at epoch 18\n",
            "Epoch 1: Train Loss = 0.9843, Eval Loss = 0.2516\n",
            "Epoch 2: Train Loss = 0.9605, Eval Loss = 0.2509\n",
            "Epoch 3: Train Loss = 0.9335, Eval Loss = 0.3192\n",
            "Epoch 4: Train Loss = 0.8872, Eval Loss = 0.3353\n",
            "Epoch 5: Train Loss = 0.8529, Eval Loss = 0.6318\n",
            "Epoch 6: Train Loss = 0.8421, Eval Loss = 0.9173\n",
            "Epoch 7: Train Loss = 0.8285, Eval Loss = 1.4468\n",
            "Epoch 8: Train Loss = 0.8191, Eval Loss = 1.2997\n",
            "Epoch 9: Train Loss = 0.8073, Eval Loss = 1.3263\n",
            "Epoch 10: Train Loss = 0.8044, Eval Loss = 3.5172\n",
            "Epoch 11: Train Loss = 0.8002, Eval Loss = 2.7868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:29:14,556] Trial 16 finished with value: 2.2914137840270996 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 512, 'n_layers': 3, 'lr': 6.346153007139529e-05, 'alpha': 0.10305413371856059}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.7963, Eval Loss = 2.2914\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0207, Eval Loss = 0.2572\n",
            "Epoch 2: Train Loss = 0.9968, Eval Loss = 0.2536\n",
            "Epoch 3: Train Loss = 0.9901, Eval Loss = 0.2536\n",
            "Epoch 4: Train Loss = 0.9860, Eval Loss = 0.2548\n",
            "Epoch 5: Train Loss = 0.9829, Eval Loss = 0.2557\n",
            "Epoch 6: Train Loss = 0.9805, Eval Loss = 0.2588\n",
            "Epoch 7: Train Loss = 0.9767, Eval Loss = 0.2587\n",
            "Epoch 8: Train Loss = 0.9762, Eval Loss = 0.2630\n",
            "Epoch 9: Train Loss = 0.9728, Eval Loss = 0.2728\n",
            "Epoch 10: Train Loss = 0.9700, Eval Loss = 0.2728\n",
            "Epoch 11: Train Loss = 0.9665, Eval Loss = 0.2742\n",
            "Epoch 12: Train Loss = 0.9631, Eval Loss = 0.2770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:29:37,131] Trial 17 finished with value: 0.30055129528045654 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 2.099807762811611e-05, 'alpha': 0.15767786670845874}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.9583, Eval Loss = 0.3006\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 1.0612, Eval Loss = 0.2696\n",
            "Epoch 2: Train Loss = 1.0320, Eval Loss = 0.2711\n",
            "Epoch 3: Train Loss = 1.0244, Eval Loss = 0.2730\n",
            "Epoch 4: Train Loss = 1.0171, Eval Loss = 0.2776\n",
            "Epoch 5: Train Loss = 1.0303, Eval Loss = 0.2940\n",
            "Epoch 6: Train Loss = 0.9899, Eval Loss = 0.3269\n",
            "Epoch 7: Train Loss = 0.9717, Eval Loss = 0.3584\n",
            "Epoch 8: Train Loss = 0.9505, Eval Loss = 0.4669\n",
            "Epoch 9: Train Loss = 0.9304, Eval Loss = 0.6274\n",
            "Epoch 10: Train Loss = 0.9254, Eval Loss = 0.5732\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:29:59,224] Trial 18 finished with value: 0.8044040203094482 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 256, 'n_layers': 3, 'lr': 2.424115356579275e-05, 'alpha': 0.2527898638244849}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.9122, Eval Loss = 0.8044\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0084, Eval Loss = 0.5711\n",
            "Epoch 2: Train Loss = 0.9074, Eval Loss = 3.0247\n",
            "Epoch 3: Train Loss = 0.8860, Eval Loss = 2.0021\n",
            "Epoch 4: Train Loss = 0.8587, Eval Loss = 5.3229\n",
            "Epoch 5: Train Loss = 0.8574, Eval Loss = 1.2510\n",
            "Epoch 6: Train Loss = 0.8478, Eval Loss = 3.0964\n",
            "Epoch 7: Train Loss = 0.8458, Eval Loss = 2.1409\n",
            "Epoch 8: Train Loss = 0.8449, Eval Loss = 2.7704\n",
            "Epoch 9: Train Loss = 0.8362, Eval Loss = 4.3586\n",
            "Epoch 10: Train Loss = 0.8395, Eval Loss = 2.4807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:30:18,211] Trial 19 finished with value: 2.194502592086792 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 512, 'n_layers': 2, 'lr': 0.0004394209326736343, 'alpha': 0.18771317202890522}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.8318, Eval Loss = 2.1945\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.1361, Eval Loss = 0.2999\n",
            "Epoch 2: Train Loss = 1.1048, Eval Loss = 0.2982\n",
            "Epoch 3: Train Loss = 1.0974, Eval Loss = 0.3006\n",
            "Epoch 4: Train Loss = 1.0922, Eval Loss = 0.3060\n",
            "Epoch 5: Train Loss = 1.0843, Eval Loss = 0.3175\n",
            "Epoch 6: Train Loss = 1.0730, Eval Loss = 0.3324\n",
            "Epoch 7: Train Loss = 1.0659, Eval Loss = 0.3446\n",
            "Epoch 8: Train Loss = 1.0544, Eval Loss = 0.3782\n",
            "Epoch 9: Train Loss = 1.0434, Eval Loss = 0.3902\n",
            "Epoch 10: Train Loss = 1.0330, Eval Loss = 0.4839\n",
            "Epoch 11: Train Loss = 1.0316, Eval Loss = 0.5343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:30:39,345] Trial 20 finished with value: 0.5596268773078918 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 4.7664191563740304e-05, 'alpha': 0.41766477217477344}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 1.0133, Eval Loss = 0.5596\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0380, Eval Loss = 0.2549\n",
            "Epoch 2: Train Loss = 0.9946, Eval Loss = 0.2513\n",
            "Epoch 3: Train Loss = 0.9835, Eval Loss = 0.2510\n",
            "Epoch 4: Train Loss = 0.9787, Eval Loss = 0.2500\n",
            "Epoch 5: Train Loss = 0.9754, Eval Loss = 0.2498\n",
            "Epoch 6: Train Loss = 0.9733, Eval Loss = 0.2504\n",
            "Epoch 7: Train Loss = 0.9716, Eval Loss = 0.2513\n",
            "Epoch 8: Train Loss = 0.9690, Eval Loss = 0.2520\n",
            "Epoch 9: Train Loss = 0.9789, Eval Loss = 0.2533\n",
            "Epoch 10: Train Loss = 0.9651, Eval Loss = 0.2569\n",
            "Epoch 11: Train Loss = 0.9633, Eval Loss = 0.2588\n",
            "Epoch 12: Train Loss = 0.9616, Eval Loss = 0.2579\n",
            "Epoch 13: Train Loss = 0.9593, Eval Loss = 0.2586\n",
            "Epoch 14: Train Loss = 0.9563, Eval Loss = 0.2598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:31:05,405] Trial 21 finished with value: 0.2667071223258972 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.3885885935059846e-05, 'alpha': 0.13295010050903114}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss = 0.9530, Eval Loss = 0.2667\n",
            "Early stopping triggered at epoch 15\n",
            "Epoch 1: Train Loss = 1.0458, Eval Loss = 0.2545\n",
            "Epoch 2: Train Loss = 0.9997, Eval Loss = 0.2532\n",
            "Epoch 3: Train Loss = 0.9846, Eval Loss = 0.2506\n",
            "Epoch 4: Train Loss = 0.9795, Eval Loss = 0.2493\n",
            "Epoch 5: Train Loss = 0.9759, Eval Loss = 0.2480\n",
            "Epoch 6: Train Loss = 0.9732, Eval Loss = 0.2478\n",
            "Epoch 7: Train Loss = 0.9704, Eval Loss = 0.2482\n",
            "Epoch 8: Train Loss = 0.9684, Eval Loss = 0.2487\n",
            "Epoch 9: Train Loss = 0.9663, Eval Loss = 0.2493\n",
            "Epoch 10: Train Loss = 0.9646, Eval Loss = 0.2501\n",
            "Epoch 11: Train Loss = 0.9613, Eval Loss = 0.2539\n",
            "Epoch 12: Train Loss = 0.9609, Eval Loss = 0.2515\n",
            "Epoch 13: Train Loss = 0.9588, Eval Loss = 0.2539\n",
            "Epoch 14: Train Loss = 0.9573, Eval Loss = 0.2552\n",
            "Epoch 15: Train Loss = 0.9561, Eval Loss = 0.2561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:31:33,347] Trial 22 finished with value: 0.2575450837612152 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.02280873134014e-05, 'alpha': 0.1250830106845291}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.9536, Eval Loss = 0.2575\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 1.0317, Eval Loss = 0.2582\n",
            "Epoch 2: Train Loss = 1.0097, Eval Loss = 0.2564\n",
            "Epoch 3: Train Loss = 0.9951, Eval Loss = 0.2527\n",
            "Epoch 4: Train Loss = 0.9855, Eval Loss = 0.2524\n",
            "Epoch 5: Train Loss = 0.9802, Eval Loss = 0.2511\n",
            "Epoch 6: Train Loss = 0.9761, Eval Loss = 0.2507\n",
            "Epoch 7: Train Loss = 0.9735, Eval Loss = 0.2512\n",
            "Epoch 8: Train Loss = 0.9712, Eval Loss = 0.2518\n",
            "Epoch 9: Train Loss = 0.9658, Eval Loss = 0.2530\n",
            "Epoch 10: Train Loss = 0.9643, Eval Loss = 0.2542\n",
            "Epoch 11: Train Loss = 0.9680, Eval Loss = 0.2558\n",
            "Epoch 12: Train Loss = 0.9583, Eval Loss = 0.2562\n",
            "Epoch 13: Train Loss = 0.9564, Eval Loss = 0.2576\n",
            "Epoch 14: Train Loss = 0.9521, Eval Loss = 0.2598\n",
            "Epoch 15: Train Loss = 0.9606, Eval Loss = 0.2631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:32:01,316] Trial 23 finished with value: 0.2644270658493042 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.559729623817571e-05, 'alpha': 0.13957913455788024}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.9454, Eval Loss = 0.2644\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 1.0376, Eval Loss = 0.2593\n",
            "Epoch 2: Train Loss = 1.0106, Eval Loss = 0.2570\n",
            "Epoch 3: Train Loss = 1.0000, Eval Loss = 0.2600\n",
            "Epoch 4: Train Loss = 0.9948, Eval Loss = 0.2623\n",
            "Epoch 5: Train Loss = 0.9906, Eval Loss = 0.2673\n",
            "Epoch 6: Train Loss = 0.9837, Eval Loss = 0.2767\n",
            "Epoch 7: Train Loss = 0.9780, Eval Loss = 0.2766\n",
            "Epoch 8: Train Loss = 0.9729, Eval Loss = 0.2793\n",
            "Epoch 9: Train Loss = 0.9682, Eval Loss = 0.2902\n",
            "Epoch 10: Train Loss = 0.9608, Eval Loss = 0.3006\n",
            "Epoch 11: Train Loss = 0.9551, Eval Loss = 0.3130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:32:22,643] Trial 24 finished with value: 0.3127421438694 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 2.832874211183308e-05, 'alpha': 0.18016252786154394}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9476, Eval Loss = 0.3127\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0035, Eval Loss = 0.2471\n",
            "Epoch 2: Train Loss = 0.9758, Eval Loss = 0.2447\n",
            "Epoch 3: Train Loss = 0.9779, Eval Loss = 0.2457\n",
            "Epoch 4: Train Loss = 0.9581, Eval Loss = 0.2487\n",
            "Epoch 5: Train Loss = 0.9511, Eval Loss = 0.2547\n",
            "Epoch 6: Train Loss = 0.9399, Eval Loss = 0.2927\n",
            "Epoch 7: Train Loss = 0.9265, Eval Loss = 0.3014\n",
            "Epoch 8: Train Loss = 0.9089, Eval Loss = 0.3136\n",
            "Epoch 9: Train Loss = 0.8929, Eval Loss = 0.3550\n",
            "Epoch 10: Train Loss = 0.8765, Eval Loss = 0.4112\n",
            "Epoch 11: Train Loss = 0.8633, Eval Loss = 0.4523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:32:46,723] Trial 25 finished with value: 0.5776929259300232 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 256, 'n_layers': 3, 'lr': 1.8033428292414736e-05, 'alpha': 0.10665250868323811}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.8606, Eval Loss = 0.5777\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0778, Eval Loss = 0.2722\n",
            "Epoch 2: Train Loss = 1.0395, Eval Loss = 0.2704\n",
            "Epoch 3: Train Loss = 1.0304, Eval Loss = 0.2683\n",
            "Epoch 4: Train Loss = 1.0630, Eval Loss = 0.2675\n",
            "Epoch 5: Train Loss = 1.0221, Eval Loss = 0.2665\n",
            "Epoch 6: Train Loss = 1.0191, Eval Loss = 0.2664\n",
            "Epoch 7: Train Loss = 1.0168, Eval Loss = 0.2662\n",
            "Epoch 8: Train Loss = 1.0148, Eval Loss = 0.2669\n",
            "Epoch 9: Train Loss = 1.0121, Eval Loss = 0.2675\n",
            "Epoch 10: Train Loss = 1.0105, Eval Loss = 0.2690\n",
            "Epoch 11: Train Loss = 1.0076, Eval Loss = 0.2698\n",
            "Epoch 12: Train Loss = 1.0054, Eval Loss = 0.2710\n",
            "Epoch 13: Train Loss = 1.0029, Eval Loss = 0.2718\n",
            "Epoch 14: Train Loss = 1.0019, Eval Loss = 0.2737\n",
            "Epoch 15: Train Loss = 1.0388, Eval Loss = 0.2741\n",
            "Epoch 16: Train Loss = 0.9942, Eval Loss = 0.2756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:33:15,914] Trial 26 finished with value: 0.28000181913375854 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.34581704397855e-05, 'alpha': 0.232953697416907}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9918, Eval Loss = 0.2800\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 1.0654, Eval Loss = 0.2715\n",
            "Epoch 2: Train Loss = 1.0378, Eval Loss = 0.2721\n",
            "Epoch 3: Train Loss = 1.0337, Eval Loss = 0.2808\n",
            "Epoch 4: Train Loss = 1.0174, Eval Loss = 0.2924\n",
            "Epoch 5: Train Loss = 1.0082, Eval Loss = 0.3139\n",
            "Epoch 6: Train Loss = 0.9962, Eval Loss = 0.3245\n",
            "Epoch 7: Train Loss = 0.9778, Eval Loss = 0.3597\n",
            "Epoch 8: Train Loss = 0.9679, Eval Loss = 0.4380\n",
            "Epoch 9: Train Loss = 0.9519, Eval Loss = 0.4798\n",
            "Epoch 10: Train Loss = 0.9443, Eval Loss = 0.4661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:33:35,028] Trial 27 finished with value: 0.6463319659233093 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 6.016776729037473e-05, 'alpha': 0.2635946681857624}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.9314, Eval Loss = 0.6463\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0526, Eval Loss = 0.2542\n",
            "Epoch 2: Train Loss = 1.0206, Eval Loss = 0.2535\n",
            "Epoch 3: Train Loss = 1.0021, Eval Loss = 0.2516\n",
            "Epoch 4: Train Loss = 0.9940, Eval Loss = 0.2499\n",
            "Epoch 5: Train Loss = 0.9890, Eval Loss = 0.2497\n",
            "Epoch 6: Train Loss = 0.9859, Eval Loss = 0.2492\n",
            "Epoch 7: Train Loss = 0.9823, Eval Loss = 0.2491\n",
            "Epoch 8: Train Loss = 0.9795, Eval Loss = 0.2495\n",
            "Epoch 9: Train Loss = 0.9780, Eval Loss = 0.2500\n",
            "Epoch 10: Train Loss = 0.9761, Eval Loss = 0.2503\n",
            "Epoch 11: Train Loss = 0.9746, Eval Loss = 0.2510\n",
            "Epoch 12: Train Loss = 0.9735, Eval Loss = 0.2513\n",
            "Epoch 13: Train Loss = 0.9720, Eval Loss = 0.2527\n",
            "Epoch 14: Train Loss = 0.9713, Eval Loss = 0.2526\n",
            "Epoch 15: Train Loss = 0.9707, Eval Loss = 0.2537\n",
            "Epoch 16: Train Loss = 0.9695, Eval Loss = 0.2544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:34:08,017] Trial 28 finished with value: 0.2564733326435089 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 1.061993034281355e-05, 'alpha': 0.13226869534287872}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9681, Eval Loss = 0.2565\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 1.0215, Eval Loss = 0.2571\n",
            "Epoch 2: Train Loss = 0.9967, Eval Loss = 0.2543\n",
            "Epoch 3: Train Loss = 0.9981, Eval Loss = 0.2551\n",
            "Epoch 4: Train Loss = 0.9808, Eval Loss = 0.2571\n",
            "Epoch 5: Train Loss = 0.9769, Eval Loss = 0.2583\n",
            "Epoch 6: Train Loss = 0.9725, Eval Loss = 0.2619\n",
            "Epoch 7: Train Loss = 0.9656, Eval Loss = 0.2621\n",
            "Epoch 8: Train Loss = 0.9584, Eval Loss = 0.2728\n",
            "Epoch 9: Train Loss = 0.9551, Eval Loss = 0.2715\n",
            "Epoch 10: Train Loss = 0.9707, Eval Loss = 0.2773\n",
            "Epoch 11: Train Loss = 0.9451, Eval Loss = 0.2801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:34:28,754] Trial 29 finished with value: 0.2840186655521393 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 512, 'n_layers': 2, 'lr': 1.8451117749347172e-05, 'alpha': 0.16288400892442328}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9385, Eval Loss = 0.2840\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0179, Eval Loss = 0.2535\n",
            "Epoch 2: Train Loss = 0.9916, Eval Loss = 0.2522\n",
            "Epoch 3: Train Loss = 0.9842, Eval Loss = 0.2535\n",
            "Epoch 4: Train Loss = 0.9777, Eval Loss = 0.2553\n",
            "Epoch 5: Train Loss = 0.9719, Eval Loss = 0.2583\n",
            "Epoch 6: Train Loss = 0.9668, Eval Loss = 0.2618\n",
            "Epoch 7: Train Loss = 0.9599, Eval Loss = 0.2745\n",
            "Epoch 8: Train Loss = 0.9536, Eval Loss = 0.2756\n",
            "Epoch 9: Train Loss = 0.9450, Eval Loss = 0.2836\n",
            "Epoch 10: Train Loss = 0.9341, Eval Loss = 0.3034\n",
            "Epoch 11: Train Loss = 0.9278, Eval Loss = 0.3020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:34:50,137] Trial 30 finished with value: 0.35041344165802 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 1.6779168566240874e-05, 'alpha': 0.152439165111748}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9161, Eval Loss = 0.3504\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0573, Eval Loss = 0.2559\n",
            "Epoch 2: Train Loss = 1.0316, Eval Loss = 0.2545\n",
            "Epoch 3: Train Loss = 1.0053, Eval Loss = 0.2535\n",
            "Epoch 4: Train Loss = 0.9993, Eval Loss = 0.2521\n",
            "Epoch 5: Train Loss = 0.9957, Eval Loss = 0.2506\n",
            "Epoch 6: Train Loss = 0.9920, Eval Loss = 0.2487\n",
            "Epoch 7: Train Loss = 0.9991, Eval Loss = 0.2481\n",
            "Epoch 8: Train Loss = 0.9832, Eval Loss = 0.2472\n",
            "Epoch 9: Train Loss = 0.9789, Eval Loss = 0.2472\n",
            "Epoch 10: Train Loss = 0.9751, Eval Loss = 0.2475\n",
            "Epoch 11: Train Loss = 0.9717, Eval Loss = 0.2479\n",
            "Epoch 12: Train Loss = 0.9690, Eval Loss = 0.2488\n",
            "Epoch 13: Train Loss = 0.9669, Eval Loss = 0.2497\n",
            "Epoch 14: Train Loss = 0.9643, Eval Loss = 0.2508\n",
            "Epoch 15: Train Loss = 0.9629, Eval Loss = 0.2519\n",
            "Epoch 16: Train Loss = 0.9618, Eval Loss = 0.2533\n",
            "Epoch 17: Train Loss = 0.9595, Eval Loss = 0.2534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:35:29,378] Trial 31 finished with value: 0.25709235668182373 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 4, 'lr': 1.0771167576237237e-05, 'alpha': 0.12291535699584}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss = 0.9582, Eval Loss = 0.2571\n",
            "Early stopping triggered at epoch 18\n",
            "Epoch 1: Train Loss = 1.0521, Eval Loss = 0.2552\n",
            "Epoch 2: Train Loss = 1.0289, Eval Loss = 0.2558\n",
            "Epoch 3: Train Loss = 1.0021, Eval Loss = 0.2534\n",
            "Epoch 4: Train Loss = 0.9931, Eval Loss = 0.2515\n",
            "Epoch 5: Train Loss = 0.9861, Eval Loss = 0.2505\n",
            "Epoch 6: Train Loss = 1.0183, Eval Loss = 0.2496\n",
            "Epoch 7: Train Loss = 0.9770, Eval Loss = 0.2493\n",
            "Epoch 8: Train Loss = 0.9744, Eval Loss = 0.2497\n",
            "Epoch 9: Train Loss = 0.9712, Eval Loss = 0.2499\n",
            "Epoch 10: Train Loss = 0.9714, Eval Loss = 0.2507\n",
            "Epoch 11: Train Loss = 0.9688, Eval Loss = 0.2518\n",
            "Epoch 12: Train Loss = 0.9661, Eval Loss = 0.2526\n",
            "Epoch 13: Train Loss = 0.9637, Eval Loss = 0.2545\n",
            "Epoch 14: Train Loss = 0.9615, Eval Loss = 0.2567\n",
            "Epoch 15: Train Loss = 0.9592, Eval Loss = 0.2579\n",
            "Epoch 16: Train Loss = 0.9568, Eval Loss = 0.2570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:36:02,113] Trial 32 finished with value: 0.26400646567344666 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 1.496307482827408e-05, 'alpha': 0.13096811697933167}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9548, Eval Loss = 0.2640\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 1.0451, Eval Loss = 0.2583\n",
            "Epoch 2: Train Loss = 1.0023, Eval Loss = 0.2566\n",
            "Epoch 3: Train Loss = 0.9961, Eval Loss = 0.2567\n",
            "Epoch 4: Train Loss = 0.9920, Eval Loss = 0.2575\n",
            "Epoch 5: Train Loss = 0.9923, Eval Loss = 0.2592\n",
            "Epoch 6: Train Loss = 0.9866, Eval Loss = 0.2625\n",
            "Epoch 7: Train Loss = 0.9837, Eval Loss = 0.2636\n",
            "Epoch 8: Train Loss = 0.9904, Eval Loss = 0.2720\n",
            "Epoch 9: Train Loss = 0.9754, Eval Loss = 0.2860\n",
            "Epoch 10: Train Loss = 0.9701, Eval Loss = 0.2811\n",
            "Epoch 11: Train Loss = 0.9658, Eval Loss = 0.3017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:36:25,271] Trial 33 finished with value: 0.3087987005710602 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 2.893098741868543e-05, 'alpha': 0.1751734765192901}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9589, Eval Loss = 0.3088\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0818, Eval Loss = 0.2667\n",
            "Epoch 2: Train Loss = 1.0452, Eval Loss = 0.2665\n",
            "Epoch 3: Train Loss = 1.0281, Eval Loss = 0.2653\n",
            "Epoch 4: Train Loss = 1.0221, Eval Loss = 0.2639\n",
            "Epoch 5: Train Loss = 1.0184, Eval Loss = 0.2633\n",
            "Epoch 6: Train Loss = 1.0139, Eval Loss = 0.2619\n",
            "Epoch 7: Train Loss = 1.0141, Eval Loss = 0.2619\n",
            "Epoch 8: Train Loss = 1.0081, Eval Loss = 0.2623\n",
            "Epoch 9: Train Loss = 1.0063, Eval Loss = 0.2627\n",
            "Epoch 10: Train Loss = 1.0049, Eval Loss = 0.2632\n",
            "Epoch 11: Train Loss = 1.0031, Eval Loss = 0.2639\n",
            "Epoch 12: Train Loss = 1.0023, Eval Loss = 0.2645\n",
            "Epoch 13: Train Loss = 1.0002, Eval Loss = 0.2656\n",
            "Epoch 14: Train Loss = 0.9992, Eval Loss = 0.2667\n",
            "Epoch 15: Train Loss = 0.9976, Eval Loss = 0.2665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:36:56,511] Trial 34 finished with value: 0.26761212944984436 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 1.3472724194554914e-05, 'alpha': 0.20613977689968857}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.9963, Eval Loss = 0.2676\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 1.0358, Eval Loss = 0.2469\n",
            "Epoch 2: Train Loss = 0.9927, Eval Loss = 0.2449\n",
            "Epoch 3: Train Loss = 0.9813, Eval Loss = 0.2449\n",
            "Epoch 4: Train Loss = 0.9711, Eval Loss = 0.2472\n",
            "Epoch 5: Train Loss = 0.9658, Eval Loss = 0.2509\n",
            "Epoch 6: Train Loss = 0.9587, Eval Loss = 0.2516\n",
            "Epoch 7: Train Loss = 0.9553, Eval Loss = 0.2661\n",
            "Epoch 8: Train Loss = 0.9514, Eval Loss = 0.2634\n",
            "Epoch 9: Train Loss = 0.9479, Eval Loss = 0.2770\n",
            "Epoch 10: Train Loss = 0.9452, Eval Loss = 0.2839\n",
            "Epoch 11: Train Loss = 0.9410, Eval Loss = 0.3068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:37:22,733] Trial 35 finished with value: 0.32170090079307556 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 4, 'lr': 2.2504317023321575e-05, 'alpha': 0.10126879481152155}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.9354, Eval Loss = 0.3217\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0750, Eval Loss = 0.2629\n",
            "Epoch 2: Train Loss = 1.0451, Eval Loss = 0.2570\n",
            "Epoch 3: Train Loss = 1.0190, Eval Loss = 0.2550\n",
            "Epoch 4: Train Loss = 1.0059, Eval Loss = 0.2553\n",
            "Epoch 5: Train Loss = 1.0000, Eval Loss = 0.2553\n",
            "Epoch 6: Train Loss = 0.9966, Eval Loss = 0.2539\n",
            "Epoch 7: Train Loss = 0.9938, Eval Loss = 0.2524\n",
            "Epoch 8: Train Loss = 0.9911, Eval Loss = 0.2520\n",
            "Epoch 9: Train Loss = 0.9892, Eval Loss = 0.2522\n",
            "Epoch 10: Train Loss = 0.9876, Eval Loss = 0.2516\n",
            "Epoch 11: Train Loss = 0.9861, Eval Loss = 0.2515\n",
            "Epoch 12: Train Loss = 0.9850, Eval Loss = 0.2519\n",
            "Epoch 13: Train Loss = 0.9836, Eval Loss = 0.2522\n",
            "Epoch 14: Train Loss = 0.9827, Eval Loss = 0.2521\n",
            "Epoch 15: Train Loss = 0.9818, Eval Loss = 0.2524\n",
            "Epoch 16: Train Loss = 0.9808, Eval Loss = 0.2526\n",
            "Epoch 17: Train Loss = 0.9799, Eval Loss = 0.2530\n",
            "Epoch 18: Train Loss = 0.9788, Eval Loss = 0.2535\n",
            "Epoch 19: Train Loss = 0.9777, Eval Loss = 0.2542\n",
            "Epoch 20: Train Loss = 0.9766, Eval Loss = 0.2541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:37:58,570] Trial 36 finished with value: 0.2545967698097229 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.0147762499757695e-05, 'alpha': 0.14629492927746093}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss = 0.9775, Eval Loss = 0.2546\n",
            "Early stopping triggered at epoch 21\n",
            "Epoch 1: Train Loss = 1.0948, Eval Loss = 0.2866\n",
            "Epoch 2: Train Loss = 1.0733, Eval Loss = 0.2865\n",
            "Epoch 3: Train Loss = 1.0672, Eval Loss = 0.2845\n",
            "Epoch 4: Train Loss = 1.0637, Eval Loss = 0.2846\n",
            "Epoch 5: Train Loss = 1.0558, Eval Loss = 0.2860\n",
            "Epoch 6: Train Loss = 1.0545, Eval Loss = 0.2886\n",
            "Epoch 7: Train Loss = 1.0486, Eval Loss = 0.2939\n",
            "Epoch 8: Train Loss = 1.0416, Eval Loss = 0.2995\n",
            "Epoch 9: Train Loss = 1.0356, Eval Loss = 0.3037\n",
            "Epoch 10: Train Loss = 1.0268, Eval Loss = 0.3191\n",
            "Epoch 11: Train Loss = 1.0206, Eval Loss = 0.3149\n",
            "Epoch 12: Train Loss = 1.0133, Eval Loss = 0.3289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:38:21,139] Trial 37 finished with value: 0.3230527937412262 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 3.4068009379768155e-05, 'alpha': 0.34201071563413393}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 1.0053, Eval Loss = 0.3231\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 1.1528, Eval Loss = 0.3120\n",
            "Epoch 2: Train Loss = 1.1328, Eval Loss = 0.3413\n",
            "Epoch 3: Train Loss = 1.1162, Eval Loss = 0.3512\n",
            "Epoch 4: Train Loss = 1.0930, Eval Loss = 0.4131\n",
            "Epoch 5: Train Loss = 1.0739, Eval Loss = 0.5628\n",
            "Epoch 6: Train Loss = 1.0492, Eval Loss = 0.7684\n",
            "Epoch 7: Train Loss = 1.0309, Eval Loss = 0.9526\n",
            "Epoch 8: Train Loss = 1.0164, Eval Loss = 1.0282\n",
            "Epoch 9: Train Loss = 1.0130, Eval Loss = 1.3865\n",
            "Epoch 10: Train Loss = 1.0028, Eval Loss = 1.3699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:38:40,193] Trial 38 finished with value: 1.579217791557312 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 256, 'n_layers': 2, 'lr': 9.08763566018112e-05, 'alpha': 0.4997849784487111}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 1.0001, Eval Loss = 1.5792\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.1361, Eval Loss = 0.3173\n",
            "Epoch 2: Train Loss = 1.0851, Eval Loss = 0.8493\n",
            "Epoch 3: Train Loss = 1.0353, Eval Loss = 2.5370\n",
            "Epoch 4: Train Loss = 0.9994, Eval Loss = 2.9036\n",
            "Epoch 5: Train Loss = 0.9874, Eval Loss = 3.3324\n",
            "Epoch 6: Train Loss = 0.9981, Eval Loss = 4.0166\n",
            "Epoch 7: Train Loss = 0.9746, Eval Loss = 1.7250\n",
            "Epoch 8: Train Loss = 0.9662, Eval Loss = 2.8018\n",
            "Epoch 9: Train Loss = 0.9639, Eval Loss = 3.6494\n",
            "Epoch 10: Train Loss = 0.9630, Eval Loss = 2.4420\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:38:59,366] Trial 39 finished with value: 4.800275802612305 and parameters: {'cnn_channels': 128, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 0.00027277286285503196, 'alpha': 0.4648853458653538}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.9576, Eval Loss = 4.8003\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0037, Eval Loss = 0.2537\n",
            "Epoch 2: Train Loss = 0.9847, Eval Loss = 0.2517\n",
            "Epoch 3: Train Loss = 0.9772, Eval Loss = 0.2582\n",
            "Epoch 4: Train Loss = 0.9659, Eval Loss = 0.2611\n",
            "Epoch 5: Train Loss = 0.9568, Eval Loss = 0.2696\n",
            "Epoch 6: Train Loss = 0.9446, Eval Loss = 0.2963\n",
            "Epoch 7: Train Loss = 0.9361, Eval Loss = 0.3041\n",
            "Epoch 8: Train Loss = 0.9198, Eval Loss = 0.3242\n",
            "Epoch 9: Train Loss = 0.9072, Eval Loss = 0.3553\n",
            "Epoch 10: Train Loss = 0.8998, Eval Loss = 0.4518\n",
            "Epoch 11: Train Loss = 0.8892, Eval Loss = 0.4651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:39:20,289] Trial 40 finished with value: 0.5096547603607178 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 512, 'n_layers': 2, 'lr': 1.9623724694986602e-05, 'alpha': 0.14742327637487515}. Best is trial 12 with value: 0.25116702914237976.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.8828, Eval Loss = 0.5097\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 1.0464, Eval Loss = 0.2514\n",
            "Epoch 2: Train Loss = 1.0141, Eval Loss = 0.2514\n",
            "Epoch 3: Train Loss = 0.9891, Eval Loss = 0.2503\n",
            "Epoch 4: Train Loss = 0.9817, Eval Loss = 0.2500\n",
            "Epoch 5: Train Loss = 0.9788, Eval Loss = 0.2492\n",
            "Epoch 6: Train Loss = 0.9765, Eval Loss = 0.2499\n",
            "Epoch 7: Train Loss = 1.0152, Eval Loss = 0.2474\n",
            "Epoch 8: Train Loss = 0.9728, Eval Loss = 0.2481\n",
            "Epoch 9: Train Loss = 0.9710, Eval Loss = 0.2468\n",
            "Epoch 10: Train Loss = 0.9692, Eval Loss = 0.2474\n",
            "Epoch 11: Train Loss = 0.9688, Eval Loss = 0.2470\n",
            "Epoch 12: Train Loss = 0.9674, Eval Loss = 0.2472\n",
            "Epoch 13: Train Loss = 0.9664, Eval Loss = 0.2463\n",
            "Epoch 14: Train Loss = 0.9654, Eval Loss = 0.2466\n",
            "Epoch 15: Train Loss = 0.9645, Eval Loss = 0.2467\n",
            "Epoch 16: Train Loss = 0.9637, Eval Loss = 0.2467\n",
            "Epoch 17: Train Loss = 0.9626, Eval Loss = 0.2469\n",
            "Epoch 18: Train Loss = 0.9619, Eval Loss = 0.2470\n",
            "Epoch 19: Train Loss = 0.9609, Eval Loss = 0.2474\n",
            "Epoch 20: Train Loss = 0.9595, Eval Loss = 0.2475\n",
            "Epoch 21: Train Loss = 0.9593, Eval Loss = 0.2477\n",
            "Epoch 22: Train Loss = 0.9585, Eval Loss = 0.2482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:40:04,651] Trial 41 finished with value: 0.2487073391675949 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 1.00116030738174e-05, 'alpha': 0.11300372982148608}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Train Loss = 0.9576, Eval Loss = 0.2487\n",
            "Early stopping triggered at epoch 23\n",
            "Epoch 1: Train Loss = 1.0442, Eval Loss = 0.2526\n",
            "Epoch 2: Train Loss = 1.0042, Eval Loss = 0.2512\n",
            "Epoch 3: Train Loss = 0.9842, Eval Loss = 0.2505\n",
            "Epoch 4: Train Loss = 0.9789, Eval Loss = 0.2494\n",
            "Epoch 5: Train Loss = 0.9760, Eval Loss = 0.2483\n",
            "Epoch 6: Train Loss = 0.9737, Eval Loss = 0.2480\n",
            "Epoch 7: Train Loss = 0.9712, Eval Loss = 0.2477\n",
            "Epoch 8: Train Loss = 0.9692, Eval Loss = 0.2479\n",
            "Epoch 9: Train Loss = 0.9678, Eval Loss = 0.2475\n",
            "Epoch 10: Train Loss = 0.9663, Eval Loss = 0.2477\n",
            "Epoch 11: Train Loss = 0.9652, Eval Loss = 0.2480\n",
            "Epoch 12: Train Loss = 0.9639, Eval Loss = 0.2484\n",
            "Epoch 13: Train Loss = 0.9634, Eval Loss = 0.2488\n",
            "Epoch 14: Train Loss = 0.9617, Eval Loss = 0.2494\n",
            "Epoch 15: Train Loss = 0.9611, Eval Loss = 0.2497\n",
            "Epoch 16: Train Loss = 0.9602, Eval Loss = 0.2499\n",
            "Epoch 17: Train Loss = 0.9591, Eval Loss = 0.2507\n",
            "Epoch 18: Train Loss = 0.9583, Eval Loss = 0.2510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:40:36,638] Trial 42 finished with value: 0.25224974751472473 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.2274651203245158e-05, 'alpha': 0.12061589517173268}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss = 0.9568, Eval Loss = 0.2522\n",
            "Early stopping triggered at epoch 19\n",
            "Epoch 1: Train Loss = 1.0495, Eval Loss = 0.2528\n",
            "Epoch 2: Train Loss = 1.0062, Eval Loss = 0.2529\n",
            "Epoch 3: Train Loss = 0.9911, Eval Loss = 0.2518\n",
            "Epoch 4: Train Loss = 0.9849, Eval Loss = 0.2505\n",
            "Epoch 5: Train Loss = 0.9792, Eval Loss = 0.2481\n",
            "Epoch 6: Train Loss = 0.9748, Eval Loss = 0.2480\n",
            "Epoch 7: Train Loss = 0.9714, Eval Loss = 0.2465\n",
            "Epoch 8: Train Loss = 0.9689, Eval Loss = 0.2465\n",
            "Epoch 9: Train Loss = 0.9668, Eval Loss = 0.2483\n",
            "Epoch 10: Train Loss = 0.9645, Eval Loss = 0.2505\n",
            "Epoch 11: Train Loss = 0.9662, Eval Loss = 0.2488\n",
            "Epoch 12: Train Loss = 0.9610, Eval Loss = 0.2492\n",
            "Epoch 13: Train Loss = 0.9588, Eval Loss = 0.2507\n",
            "Epoch 14: Train Loss = 0.9565, Eval Loss = 0.2514\n",
            "Epoch 15: Train Loss = 0.9539, Eval Loss = 0.2536\n",
            "Epoch 16: Train Loss = 0.9516, Eval Loss = 0.2592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:41:13,683] Trial 43 finished with value: 0.25778481364250183 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 4, 'lr': 1.3110342549883978e-05, 'alpha': 0.11600548477182192}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.9544, Eval Loss = 0.2578\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 1.0548, Eval Loss = 0.2627\n",
            "Epoch 2: Train Loss = 1.0247, Eval Loss = 0.2605\n",
            "Epoch 3: Train Loss = 1.0169, Eval Loss = 0.2592\n",
            "Epoch 4: Train Loss = 1.0092, Eval Loss = 0.2576\n",
            "Epoch 5: Train Loss = 1.0035, Eval Loss = 0.2575\n",
            "Epoch 6: Train Loss = 0.9986, Eval Loss = 0.2568\n",
            "Epoch 7: Train Loss = 0.9951, Eval Loss = 0.2572\n",
            "Epoch 8: Train Loss = 0.9930, Eval Loss = 0.2575\n",
            "Epoch 9: Train Loss = 0.9909, Eval Loss = 0.2582\n",
            "Epoch 10: Train Loss = 1.0237, Eval Loss = 0.2592\n",
            "Epoch 11: Train Loss = 0.9867, Eval Loss = 0.2596\n",
            "Epoch 12: Train Loss = 0.9850, Eval Loss = 0.2606\n",
            "Epoch 13: Train Loss = 0.9838, Eval Loss = 0.2626\n",
            "Epoch 14: Train Loss = 0.9810, Eval Loss = 0.2650\n",
            "Epoch 15: Train Loss = 0.9788, Eval Loss = 0.2633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:41:40,849] Trial 44 finished with value: 0.26632606983184814 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.710432857012617e-05, 'alpha': 0.17664014375544548}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.9780, Eval Loss = 0.2663\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 1.0449, Eval Loss = 0.2518\n",
            "Epoch 2: Train Loss = 1.0109, Eval Loss = 0.2505\n",
            "Epoch 3: Train Loss = 0.9904, Eval Loss = 0.2489\n",
            "Epoch 4: Train Loss = 0.9801, Eval Loss = 0.2478\n",
            "Epoch 5: Train Loss = 0.9755, Eval Loss = 0.2469\n",
            "Epoch 6: Train Loss = 0.9745, Eval Loss = 0.2468\n",
            "Epoch 7: Train Loss = 0.9713, Eval Loss = 0.2464\n",
            "Epoch 8: Train Loss = 0.9696, Eval Loss = 0.2462\n",
            "Epoch 9: Train Loss = 0.9684, Eval Loss = 0.2463\n",
            "Epoch 10: Train Loss = 0.9673, Eval Loss = 0.2462\n",
            "Epoch 11: Train Loss = 0.9664, Eval Loss = 0.2463\n",
            "Epoch 12: Train Loss = 0.9653, Eval Loss = 0.2464\n",
            "Epoch 13: Train Loss = 0.9644, Eval Loss = 0.2465\n",
            "Epoch 14: Train Loss = 0.9636, Eval Loss = 0.2467\n",
            "Epoch 15: Train Loss = 0.9630, Eval Loss = 0.2470\n",
            "Epoch 16: Train Loss = 0.9630, Eval Loss = 0.2475\n",
            "Epoch 17: Train Loss = 0.9610, Eval Loss = 0.2478\n",
            "Epoch 18: Train Loss = 0.9603, Eval Loss = 0.2484\n",
            "Epoch 19: Train Loss = 0.9600, Eval Loss = 0.2488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:42:15,022] Trial 45 finished with value: 0.24913595616817474 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.0026911155303846e-05, 'alpha': 0.11209570270410085}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss = 0.9587, Eval Loss = 0.2491\n",
            "Early stopping triggered at epoch 20\n",
            "Epoch 1: Train Loss = 0.9859, Eval Loss = 0.2526\n",
            "Epoch 2: Train Loss = 0.9565, Eval Loss = 0.2823\n",
            "Epoch 3: Train Loss = 0.9244, Eval Loss = 0.3649\n",
            "Epoch 4: Train Loss = 0.8806, Eval Loss = 0.6908\n",
            "Epoch 5: Train Loss = 0.8628, Eval Loss = 1.0545\n",
            "Epoch 6: Train Loss = 0.8530, Eval Loss = 1.8257\n",
            "Epoch 7: Train Loss = 0.8309, Eval Loss = 3.0170\n",
            "Epoch 8: Train Loss = 0.8182, Eval Loss = 4.7580\n",
            "Epoch 9: Train Loss = 0.8258, Eval Loss = 3.4445\n",
            "Epoch 10: Train Loss = 0.8073, Eval Loss = 3.0524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:42:36,704] Trial 46 finished with value: 2.139230728149414 and parameters: {'cnn_channels': 64, 'mlp_hidden_dim': 128, 'n_layers': 3, 'lr': 0.00012914749998095567, 'alpha': 0.11563140672906512}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss = 0.8053, Eval Loss = 2.1392\n",
            "Early stopping triggered at epoch 11\n",
            "Epoch 1: Train Loss = 1.0685, Eval Loss = 0.2602\n",
            "Epoch 2: Train Loss = 1.0322, Eval Loss = 0.2598\n",
            "Epoch 3: Train Loss = 1.0119, Eval Loss = 0.2586\n",
            "Epoch 4: Train Loss = 1.0053, Eval Loss = 0.2577\n",
            "Epoch 5: Train Loss = 1.0049, Eval Loss = 0.2567\n",
            "Epoch 6: Train Loss = 0.9987, Eval Loss = 0.2559\n",
            "Epoch 7: Train Loss = 0.9964, Eval Loss = 0.2552\n",
            "Epoch 8: Train Loss = 0.9945, Eval Loss = 0.2552\n",
            "Epoch 9: Train Loss = 0.9932, Eval Loss = 0.2550\n",
            "Epoch 10: Train Loss = 0.9913, Eval Loss = 0.2550\n",
            "Epoch 11: Train Loss = 0.9903, Eval Loss = 0.2551\n",
            "Epoch 12: Train Loss = 0.9888, Eval Loss = 0.2554\n",
            "Epoch 13: Train Loss = 0.9878, Eval Loss = 0.2557\n",
            "Epoch 14: Train Loss = 0.9867, Eval Loss = 0.2561\n",
            "Epoch 15: Train Loss = 0.9855, Eval Loss = 0.2563\n",
            "Epoch 16: Train Loss = 0.9845, Eval Loss = 0.2569\n",
            "Epoch 17: Train Loss = 0.9833, Eval Loss = 0.2578\n",
            "Epoch 18: Train Loss = 1.0155, Eval Loss = 0.2584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:43:08,988] Trial 47 finished with value: 0.2588275372982025 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.2453243648141978e-05, 'alpha': 0.16839400852822478}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss = 0.9810, Eval Loss = 0.2588\n",
            "Early stopping triggered at epoch 19\n",
            "Epoch 1: Train Loss = 1.0242, Eval Loss = 0.2478\n",
            "Epoch 2: Train Loss = 0.9798, Eval Loss = 0.2452\n",
            "Epoch 3: Train Loss = 0.9718, Eval Loss = 0.2434\n",
            "Epoch 4: Train Loss = 0.9676, Eval Loss = 0.2434\n",
            "Epoch 5: Train Loss = 0.9637, Eval Loss = 0.2439\n",
            "Epoch 6: Train Loss = 0.9605, Eval Loss = 0.2446\n",
            "Epoch 7: Train Loss = 0.9567, Eval Loss = 0.2460\n",
            "Epoch 8: Train Loss = 0.9534, Eval Loss = 0.2481\n",
            "Epoch 9: Train Loss = 0.9502, Eval Loss = 0.2495\n",
            "Epoch 10: Train Loss = 0.9472, Eval Loss = 0.2512\n",
            "Epoch 11: Train Loss = 0.9501, Eval Loss = 0.2545\n",
            "Epoch 12: Train Loss = 0.9393, Eval Loss = 0.2584\n",
            "Epoch 13: Train Loss = 0.9346, Eval Loss = 0.2622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:43:32,763] Trial 48 finished with value: 0.2716767489910126 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 2.5437758763639746e-05, 'alpha': 0.10108882945412737}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.9299, Eval Loss = 0.2717\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 1.0690, Eval Loss = 0.2656\n",
            "Epoch 2: Train Loss = 1.0266, Eval Loss = 0.2650\n",
            "Epoch 3: Train Loss = 1.0180, Eval Loss = 0.2640\n",
            "Epoch 4: Train Loss = 1.0140, Eval Loss = 0.2636\n",
            "Epoch 5: Train Loss = 1.0097, Eval Loss = 0.2615\n",
            "Epoch 6: Train Loss = 1.0063, Eval Loss = 0.2607\n",
            "Epoch 7: Train Loss = 1.0032, Eval Loss = 0.2607\n",
            "Epoch 8: Train Loss = 1.0022, Eval Loss = 0.2603\n",
            "Epoch 9: Train Loss = 1.0017, Eval Loss = 0.2608\n",
            "Epoch 10: Train Loss = 0.9992, Eval Loss = 0.2603\n",
            "Epoch 11: Train Loss = 0.9978, Eval Loss = 0.2602\n",
            "Epoch 12: Train Loss = 0.9967, Eval Loss = 0.2605\n",
            "Epoch 13: Train Loss = 0.9956, Eval Loss = 0.2610\n",
            "Epoch 14: Train Loss = 0.9943, Eval Loss = 0.2612\n",
            "Epoch 15: Train Loss = 0.9931, Eval Loss = 0.2618\n",
            "Epoch 16: Train Loss = 0.9910, Eval Loss = 0.2619\n",
            "Epoch 17: Train Loss = 0.9903, Eval Loss = 0.2626\n",
            "Epoch 18: Train Loss = 0.9887, Eval Loss = 0.2634\n",
            "Epoch 19: Train Loss = 0.9852, Eval Loss = 0.2668\n",
            "Epoch 20: Train Loss = 0.9859, Eval Loss = 0.2657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-10 05:44:08,546] Trial 49 finished with value: 0.2689477503299713 and parameters: {'cnn_channels': 32, 'mlp_hidden_dim': 128, 'n_layers': 2, 'lr': 1.5193139573153885e-05, 'alpha': 0.19377291819592107}. Best is trial 41 with value: 0.2487073391675949.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss = 0.9827, Eval Loss = 0.2689\n",
            "Early stopping triggered at epoch 21\n"
          ]
        }
      ],
      "source": [
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "study.optimize(objective, n_trials=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4e3bb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90832a27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict\n",
        "\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = mlp_model(torch.tensor(x_test_mlp, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_mlp  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HAyut1x8xchV",
      "metadata": {
        "id": "HAyut1x8xchV"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "eng",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
