{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9cac5cff",
      "metadata": {
        "id": "9cac5cff"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6c4a11a8",
      "metadata": {
        "id": "6c4a11a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# (Optional) If you're working inside Jupyter\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "e80aa0ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "2ff202c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_processor_v2 import DataProcessorUpdated\n",
        "\n",
        "processor = DataProcessorUpdated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "caae40c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-12-31 23:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<string>:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-01 23:00:00\n",
            "2023-12-31 23:00:00\n",
            "2023-12-31 23:00:00\n"
          ]
        }
      ],
      "source": [
        "processor.load_and_clean_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "35901f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.combine_all_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "8c5cff35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>23.1651</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>23.2113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>21.3244</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>20.3351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>19.2456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00               NaN           13.837562   \n",
              "2019-01-01 01:00:00               NaN           15.464869   \n",
              "2019-01-01 02:00:00               NaN           15.487720   \n",
              "2019-01-01 03:00:00               NaN           15.770092   \n",
              "2019-01-01 04:00:00               NaN           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00           23.1651                 NaN   \n",
              "2024-01-01 20:00:00           23.2113                 NaN   \n",
              "2024-01-01 21:00:00           21.3244                 NaN   \n",
              "2024-01-01 22:00:00           20.3351                 NaN   \n",
              "2024-01-01 23:00:00           19.2456                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "73e0d9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_dap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "1a9b0f63",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>23.9250</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>23.3140</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>23.3475</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>23.0595</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>25.2672</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00           23.9250           13.837562   \n",
              "2019-01-01 01:00:00           23.3140           15.464869   \n",
              "2019-01-01 02:00:00           23.3475           15.487720   \n",
              "2019-01-01 03:00:00           23.0595           15.770092   \n",
              "2019-01-01 04:00:00           25.2672           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00               NaN                 NaN   \n",
              "2024-01-01 20:00:00               NaN                 NaN   \n",
              "2024-01-01 21:00:00               NaN                 NaN   \n",
              "2024-01-01 22:00:00               NaN                 NaN   \n",
              "2024-01-01 23:00:00               NaN                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "e5902795",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.split_data(feature_columns=['DAP_SystemLambda', 'SCED_system_lambda'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "857623c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.standardize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "89475b19",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "9aff786e",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_mlp, x_val_mlp, x_test_mlp, y_train_mlp, y_val_mlp, y_test_mlp = processor.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "404fc096",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "336"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train_mlp[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaeebb4",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "c0fde9ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLPModel(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=336, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=512, out_features=24, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from MLP import MLPModel\n",
        "\n",
        "new_model = MLPModel(\n",
        "    input_shape=len(x_train_mlp[1]),    # 5 features\n",
        "    output_shape=len(y_train_mlp[1]),   # 1 price per time step\n",
        "    hidden_layers=[512, 512, 512]  # or [256, 256]\n",
        ")\n",
        "\n",
        "mlp_model = new_model.get_model()\n",
        "mlp_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "prD6Bpb9fMdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prD6Bpb9fMdc",
        "outputId": "2b5275e4-590f-4b76-d355-5ae9fd1d9e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 0.7054, Eval Loss = 0.2542\n",
            "Epoch 2: Train Loss = 0.6823, Eval Loss = 0.2532\n",
            "Epoch 3: Train Loss = 0.5815, Eval Loss = 0.2545\n",
            "Epoch 4: Train Loss = 0.5567, Eval Loss = 0.2576\n",
            "Epoch 5: Train Loss = 0.5194, Eval Loss = 0.2557\n",
            "Epoch 6: Train Loss = 0.5382, Eval Loss = 0.2557\n",
            "Epoch 7: Train Loss = 0.4888, Eval Loss = 0.2577\n",
            "Epoch 8: Train Loss = 0.4367, Eval Loss = 0.2566\n",
            "Epoch 9: Train Loss = 0.4262, Eval Loss = 0.2560\n",
            "Epoch 10: Train Loss = 0.3929, Eval Loss = 0.2555\n",
            "Epoch 11: Train Loss = 0.3594, Eval Loss = 0.2533\n",
            "Epoch 12: Train Loss = 0.3572, Eval Loss = 0.2550\n",
            "Epoch 13: Train Loss = 0.3181, Eval Loss = 0.2537\n",
            "Epoch 14: Train Loss = 0.2979, Eval Loss = 0.2601\n",
            "Epoch 15: Train Loss = 0.2957, Eval Loss = 0.2533\n",
            "Epoch 16: Train Loss = 0.2741, Eval Loss = 0.2544\n",
            "Epoch 17: Train Loss = 0.2697, Eval Loss = 0.2525\n",
            "Epoch 18: Train Loss = 0.2597, Eval Loss = 0.2539\n",
            "Epoch 19: Train Loss = 0.2538, Eval Loss = 0.2544\n",
            "Epoch 20: Train Loss = 0.2450, Eval Loss = 0.2589\n",
            "Epoch 21: Train Loss = 0.2314, Eval Loss = 0.2562\n",
            "Epoch 22: Train Loss = 0.2334, Eval Loss = 0.2572\n",
            "Epoch 23: Train Loss = 0.2276, Eval Loss = 0.2540\n",
            "Epoch 24: Train Loss = 0.2260, Eval Loss = 0.2568\n",
            "Epoch 25: Train Loss = 0.2153, Eval Loss = 0.2581\n",
            "Epoch 26: Train Loss = 0.2031, Eval Loss = 0.2564\n",
            "Epoch 27: Train Loss = 0.2051, Eval Loss = 0.2573\n",
            "Epoch 28: Train Loss = 0.2077, Eval Loss = 0.2561\n",
            "Epoch 29: Train Loss = 0.1922, Eval Loss = 0.2572\n",
            "Epoch 30: Train Loss = 0.2005, Eval Loss = 0.2601\n",
            "Epoch 31: Train Loss = 0.1925, Eval Loss = 0.2549\n",
            "Epoch 32: Train Loss = 0.1841, Eval Loss = 0.2557\n",
            "Epoch 33: Train Loss = 0.1848, Eval Loss = 0.2573\n",
            "Epoch 34: Train Loss = 0.1942, Eval Loss = 0.2575\n",
            "Epoch 35: Train Loss = 0.1824, Eval Loss = 0.2596\n",
            "Epoch 36: Train Loss = 0.1753, Eval Loss = 0.2601\n",
            "Epoch 37: Train Loss = 0.1691, Eval Loss = 0.2596\n",
            "Epoch 38: Train Loss = 0.1780, Eval Loss = 0.2567\n",
            "Epoch 39: Train Loss = 0.1694, Eval Loss = 0.2604\n",
            "Epoch 40: Train Loss = 0.1753, Eval Loss = 0.2606\n",
            "Epoch 41: Train Loss = 0.1720, Eval Loss = 0.2581\n",
            "Epoch 42: Train Loss = 0.1698, Eval Loss = 0.2593\n",
            "Epoch 43: Train Loss = 0.1659, Eval Loss = 0.2582\n",
            "Epoch 44: Train Loss = 0.1551, Eval Loss = 0.2594\n",
            "Epoch 45: Train Loss = 0.1617, Eval Loss = 0.2586\n",
            "Epoch 46: Train Loss = 0.1635, Eval Loss = 0.2589\n",
            "Epoch 47: Train Loss = 0.1524, Eval Loss = 0.2593\n",
            "Epoch 48: Train Loss = 0.1546, Eval Loss = 0.2578\n",
            "Epoch 49: Train Loss = 0.1500, Eval Loss = 0.2598\n",
            "Epoch 50: Train Loss = 0.1538, Eval Loss = 0.2619\n",
            "Epoch 51: Train Loss = 0.1544, Eval Loss = 0.2589\n",
            "Epoch 52: Train Loss = 0.1487, Eval Loss = 0.2588\n",
            "Epoch 53: Train Loss = 0.1568, Eval Loss = 0.2620\n",
            "Epoch 54: Train Loss = 0.1459, Eval Loss = 0.2602\n",
            "Epoch 55: Train Loss = 0.1454, Eval Loss = 0.2616\n",
            "Epoch 56: Train Loss = 0.1486, Eval Loss = 0.2594\n",
            "Epoch 57: Train Loss = 0.1387, Eval Loss = 0.2606\n",
            "Epoch 58: Train Loss = 0.1384, Eval Loss = 0.2603\n",
            "Epoch 59: Train Loss = 0.1382, Eval Loss = 0.2614\n",
            "Epoch 60: Train Loss = 0.1335, Eval Loss = 0.2615\n",
            "Epoch 61: Train Loss = 0.1370, Eval Loss = 0.2602\n",
            "Epoch 62: Train Loss = 0.1448, Eval Loss = 0.2585\n",
            "Epoch 63: Train Loss = 0.1382, Eval Loss = 0.2635\n",
            "Epoch 64: Train Loss = 0.1228, Eval Loss = 0.2625\n",
            "Epoch 65: Train Loss = 0.1326, Eval Loss = 0.2627\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[111]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlosses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fluctuation_loss  \u001b[38;5;66;03m# or define it above in your notebook\u001b[39;00m\n\u001b[32m      4\u001b[39m trainer = ModelTrainer(\n\u001b[32m      5\u001b[39m     model=mlp_model,\n\u001b[32m      6\u001b[39m     features_training_data=x_train_mlp,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     loss_fn=\u001b[38;5;28;01mlambda\u001b[39;00m pred, target: fluctuation_loss(pred, target, alpha=\u001b[32m0.2\u001b[39m)\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Classes/Spring2025/NNDL/Projects/repo/energy-prediction/pytorch/ModelTrainer.py:47\u001b[39m, in \u001b[36mModelTrainer.train\u001b[39m\u001b[34m(self, epochs, batch_size, patience, learning_rate)\u001b[39m\n\u001b[32m     45\u001b[39m     loss = loss_fn(outputs, batch_y)\n\u001b[32m     46\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m     train_loss += loss.item()\n\u001b[32m     51\u001b[39m train_loss /= (N // batch_size)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/optimizer.py:485\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    482\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    483\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    488\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/optimizer.py:79\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/adam.py:246\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    234\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    237\u001b[39m         group,\n\u001b[32m    238\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m         state_steps,\n\u001b[32m    244\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/optimizer.py:147\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/adam.py:933\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    931\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/red-river-energy/lib/python3.11/site-packages/torch/optim/adam.py:525\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    523\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m         denom = (\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / bias_correction2_sqrt).add_(eps)\n\u001b[32m    527\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)\n\u001b[32m    529\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss  # or define it above in your notebook\n",
        "\n",
        "trainer = ModelTrainer(\n",
        "    model=mlp_model,\n",
        "    features_training_data=x_train_mlp,\n",
        "    target_training_data=y_train_mlp,\n",
        "    features_eval_data=x_val_mlp,\n",
        "    target_eval_data=y_val_mlp,\n",
        "    device=device,\n",
        "    loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=0.2)\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train(epochs=100, batch_size=32, patience=50, learning_rate=5e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "6c690761",
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from MLP import MLPModel\n",
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [128, 256, 512])\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    alpha = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n",
        "\n",
        "    # Build hidden layers\n",
        "    hidden_layers = [hidden_dim] * n_layers\n",
        "\n",
        "    # Build model\n",
        "    model = MLPModel(input_shape=len(x_train_mlp[1]), output_shape=len(y_train_mlp[1]), hidden_layers=hidden_layers).get_model().to(device)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = ModelTrainer(\n",
        "        model=model,\n",
        "        features_training_data=x_train_mlp,\n",
        "        target_training_data=y_train_mlp,\n",
        "        features_eval_data=x_val_mlp,\n",
        "        target_eval_data=y_val_mlp,\n",
        "        device=device,\n",
        "        loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=alpha)\n",
        "    )\n",
        "\n",
        "    # Train for a few epochs\n",
        "    trainer.train(epochs=50, batch_size=32, patience=10, learning_rate=lr)\n",
        "\n",
        "    # Return final eval loss (or early stopping best)\n",
        "    return trainer.history['eval_loss'][-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43d4194c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:42:11,678] A new study created in memory with name: no-name-a698c28b-2645-47e5-9c4e-20eeea0fe031\n",
            "/var/folders/wd/tgznb8111md97qlw9yqd793m0000gn/T/ipykernel_93659/1319189539.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
            "/var/folders/wd/tgznb8111md97qlw9yqd793m0000gn/T/ipykernel_93659/1319189539.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  alpha = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 0.9701, Eval Loss = 0.2825\n",
            "Epoch 2: Train Loss = 0.6931, Eval Loss = 0.2827\n",
            "Epoch 3: Train Loss = 0.6292, Eval Loss = 0.2827\n",
            "Epoch 4: Train Loss = 0.6035, Eval Loss = 0.2810\n",
            "Epoch 5: Train Loss = 0.5935, Eval Loss = 0.2807\n",
            "Epoch 6: Train Loss = 0.5770, Eval Loss = 0.2806\n",
            "Epoch 7: Train Loss = 0.5642, Eval Loss = 0.2794\n",
            "Epoch 8: Train Loss = 0.5514, Eval Loss = 0.2780\n",
            "Epoch 9: Train Loss = 0.5346, Eval Loss = 0.2767\n",
            "Epoch 10: Train Loss = 0.5215, Eval Loss = 0.2763\n",
            "Epoch 11: Train Loss = 0.5073, Eval Loss = 0.2757\n",
            "Epoch 12: Train Loss = 0.4906, Eval Loss = 0.2751\n",
            "Epoch 13: Train Loss = 0.4776, Eval Loss = 0.2741\n",
            "Epoch 14: Train Loss = 0.4626, Eval Loss = 0.2739\n",
            "Epoch 15: Train Loss = 0.4611, Eval Loss = 0.2732\n",
            "Epoch 16: Train Loss = 0.4435, Eval Loss = 0.2738\n",
            "Epoch 17: Train Loss = 0.4321, Eval Loss = 0.2729\n",
            "Epoch 18: Train Loss = 0.4210, Eval Loss = 0.2731\n",
            "Epoch 19: Train Loss = 0.4135, Eval Loss = 0.2729\n",
            "Epoch 20: Train Loss = 0.4025, Eval Loss = 0.2733\n",
            "Epoch 21: Train Loss = 0.3931, Eval Loss = 0.2725\n",
            "Epoch 22: Train Loss = 0.3867, Eval Loss = 0.2731\n",
            "Epoch 23: Train Loss = 0.3817, Eval Loss = 0.2728\n",
            "Epoch 24: Train Loss = 0.3713, Eval Loss = 0.2727\n",
            "Epoch 25: Train Loss = 0.3659, Eval Loss = 0.2729\n",
            "Epoch 26: Train Loss = 0.3593, Eval Loss = 0.2724\n",
            "Epoch 27: Train Loss = 0.3532, Eval Loss = 0.2727\n",
            "Epoch 28: Train Loss = 0.3495, Eval Loss = 0.2726\n",
            "Epoch 29: Train Loss = 0.3434, Eval Loss = 0.2727\n",
            "Epoch 30: Train Loss = 0.3389, Eval Loss = 0.2725\n",
            "Epoch 31: Train Loss = 0.3341, Eval Loss = 0.2724\n",
            "Epoch 32: Train Loss = 0.3287, Eval Loss = 0.2726\n",
            "Epoch 33: Train Loss = 0.3267, Eval Loss = 0.2723\n",
            "Epoch 34: Train Loss = 0.3225, Eval Loss = 0.2723\n",
            "Epoch 35: Train Loss = 0.3181, Eval Loss = 0.2722\n",
            "Epoch 36: Train Loss = 0.3151, Eval Loss = 0.2721\n",
            "Epoch 37: Train Loss = 0.3122, Eval Loss = 0.2722\n",
            "Epoch 38: Train Loss = 0.3074, Eval Loss = 0.2721\n",
            "Epoch 39: Train Loss = 0.3065, Eval Loss = 0.2721\n",
            "Epoch 40: Train Loss = 0.3032, Eval Loss = 0.2720\n",
            "Epoch 41: Train Loss = 0.2996, Eval Loss = 0.2719\n",
            "Epoch 42: Train Loss = 0.2969, Eval Loss = 0.2720\n",
            "Epoch 43: Train Loss = 0.2944, Eval Loss = 0.2721\n",
            "Epoch 44: Train Loss = 0.2909, Eval Loss = 0.2720\n",
            "Epoch 45: Train Loss = 0.2875, Eval Loss = 0.2721\n",
            "Epoch 46: Train Loss = 0.2859, Eval Loss = 0.2723\n",
            "Epoch 47: Train Loss = 0.2831, Eval Loss = 0.2719\n",
            "Epoch 48: Train Loss = 0.2806, Eval Loss = 0.2720\n",
            "Epoch 49: Train Loss = 0.2770, Eval Loss = 0.2723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:44:23,971] Trial 0 finished with value: 0.27223822474479675 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 1.852800155011604e-05, 'alpha': 0.33719711995218815}. Best is trial 0 with value: 0.27223822474479675.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.2736, Eval Loss = 0.2722\n",
            "Epoch 1: Train Loss = 1.1218, Eval Loss = 0.2850\n",
            "Epoch 2: Train Loss = 0.9999, Eval Loss = 0.2813\n",
            "Epoch 3: Train Loss = 0.8356, Eval Loss = 0.2798\n",
            "Epoch 4: Train Loss = 0.7409, Eval Loss = 0.2799\n",
            "Epoch 5: Train Loss = 0.6869, Eval Loss = 0.2799\n",
            "Epoch 6: Train Loss = 0.6520, Eval Loss = 0.2802\n",
            "Epoch 7: Train Loss = 0.6312, Eval Loss = 0.2803\n",
            "Epoch 8: Train Loss = 0.6182, Eval Loss = 0.2803\n",
            "Epoch 9: Train Loss = 0.6086, Eval Loss = 0.2803\n",
            "Epoch 10: Train Loss = 0.6021, Eval Loss = 0.2803\n",
            "Epoch 11: Train Loss = 0.5959, Eval Loss = 0.2800\n",
            "Epoch 12: Train Loss = 0.5928, Eval Loss = 0.2800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:44:57,167] Trial 1 finished with value: 0.28002551198005676 and parameters: {'hidden_dim': 128, 'n_layers': 4, 'lr': 1.3594728164092837e-05, 'alpha': 0.3120330930570845}. Best is trial 0 with value: 0.27223822474479675.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.5884, Eval Loss = 0.2800\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.9783, Eval Loss = 0.2642\n",
            "Epoch 2: Train Loss = 0.6718, Eval Loss = 0.2643\n",
            "Epoch 3: Train Loss = 0.5928, Eval Loss = 0.2645\n",
            "Epoch 4: Train Loss = 0.5649, Eval Loss = 0.2647\n",
            "Epoch 5: Train Loss = 0.5482, Eval Loss = 0.2639\n",
            "Epoch 6: Train Loss = 0.5368, Eval Loss = 0.2636\n",
            "Epoch 7: Train Loss = 0.5268, Eval Loss = 0.2635\n",
            "Epoch 8: Train Loss = 0.5172, Eval Loss = 0.2628\n",
            "Epoch 9: Train Loss = 0.5072, Eval Loss = 0.2618\n",
            "Epoch 10: Train Loss = 0.4958, Eval Loss = 0.2613\n",
            "Epoch 11: Train Loss = 0.4866, Eval Loss = 0.2604\n",
            "Epoch 12: Train Loss = 0.4745, Eval Loss = 0.2595\n",
            "Epoch 13: Train Loss = 0.4649, Eval Loss = 0.2588\n",
            "Epoch 14: Train Loss = 0.4517, Eval Loss = 0.2582\n",
            "Epoch 15: Train Loss = 0.4421, Eval Loss = 0.2574\n",
            "Epoch 16: Train Loss = 0.4301, Eval Loss = 0.2572\n",
            "Epoch 17: Train Loss = 0.4207, Eval Loss = 0.2570\n",
            "Epoch 18: Train Loss = 0.4101, Eval Loss = 0.2563\n",
            "Epoch 19: Train Loss = 0.4028, Eval Loss = 0.2563\n",
            "Epoch 20: Train Loss = 0.3912, Eval Loss = 0.2562\n",
            "Epoch 21: Train Loss = 0.3847, Eval Loss = 0.2556\n",
            "Epoch 22: Train Loss = 0.3755, Eval Loss = 0.2558\n",
            "Epoch 23: Train Loss = 0.3696, Eval Loss = 0.2555\n",
            "Epoch 24: Train Loss = 0.3625, Eval Loss = 0.2556\n",
            "Epoch 25: Train Loss = 0.3541, Eval Loss = 0.2554\n",
            "Epoch 26: Train Loss = 0.3491, Eval Loss = 0.2556\n",
            "Epoch 27: Train Loss = 0.3428, Eval Loss = 0.2556\n",
            "Epoch 28: Train Loss = 0.3374, Eval Loss = 0.2555\n",
            "Epoch 29: Train Loss = 0.3336, Eval Loss = 0.2556\n",
            "Epoch 30: Train Loss = 0.3266, Eval Loss = 0.2555\n",
            "Epoch 31: Train Loss = 0.3214, Eval Loss = 0.2558\n",
            "Epoch 32: Train Loss = 0.3175, Eval Loss = 0.2553\n",
            "Epoch 33: Train Loss = 0.3135, Eval Loss = 0.2555\n",
            "Epoch 34: Train Loss = 0.3083, Eval Loss = 0.2553\n",
            "Epoch 35: Train Loss = 0.3051, Eval Loss = 0.2551\n",
            "Epoch 36: Train Loss = 0.3026, Eval Loss = 0.2552\n",
            "Epoch 37: Train Loss = 0.2993, Eval Loss = 0.2552\n",
            "Epoch 38: Train Loss = 0.2952, Eval Loss = 0.2553\n",
            "Epoch 39: Train Loss = 0.2943, Eval Loss = 0.2549\n",
            "Epoch 40: Train Loss = 0.2888, Eval Loss = 0.2550\n",
            "Epoch 41: Train Loss = 0.2860, Eval Loss = 0.2548\n",
            "Epoch 42: Train Loss = 0.2841, Eval Loss = 0.2551\n",
            "Epoch 43: Train Loss = 0.2818, Eval Loss = 0.2550\n",
            "Epoch 44: Train Loss = 0.2794, Eval Loss = 0.2549\n",
            "Epoch 45: Train Loss = 0.2773, Eval Loss = 0.2550\n",
            "Epoch 46: Train Loss = 0.2750, Eval Loss = 0.2550\n",
            "Epoch 47: Train Loss = 0.2731, Eval Loss = 0.2550\n",
            "Epoch 48: Train Loss = 0.2707, Eval Loss = 0.2549\n",
            "Epoch 49: Train Loss = 0.2681, Eval Loss = 0.2550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:46:55,219] Trial 2 finished with value: 0.25507283210754395 and parameters: {'hidden_dim': 256, 'n_layers': 3, 'lr': 2.4681893128437116e-05, 'alpha': 0.2167974200541837}. Best is trial 2 with value: 0.25507283210754395.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.2680, Eval Loss = 0.2551\n",
            "Epoch 1: Train Loss = 0.6770, Eval Loss = 0.2568\n",
            "Epoch 2: Train Loss = 0.5513, Eval Loss = 0.2541\n",
            "Epoch 3: Train Loss = 0.5099, Eval Loss = 0.2504\n",
            "Epoch 4: Train Loss = 0.4597, Eval Loss = 0.2482\n",
            "Epoch 5: Train Loss = 0.4164, Eval Loss = 0.2472\n",
            "Epoch 6: Train Loss = 0.3818, Eval Loss = 0.2470\n",
            "Epoch 7: Train Loss = 0.3411, Eval Loss = 0.2456\n",
            "Epoch 8: Train Loss = 0.3161, Eval Loss = 0.2458\n",
            "Epoch 9: Train Loss = 0.3005, Eval Loss = 0.2445\n",
            "Epoch 10: Train Loss = 0.2868, Eval Loss = 0.2460\n",
            "Epoch 11: Train Loss = 0.2829, Eval Loss = 0.2454\n",
            "Epoch 12: Train Loss = 0.2720, Eval Loss = 0.2457\n",
            "Epoch 13: Train Loss = 0.2646, Eval Loss = 0.2466\n",
            "Epoch 14: Train Loss = 0.2583, Eval Loss = 0.2462\n",
            "Epoch 15: Train Loss = 0.2605, Eval Loss = 0.2468\n",
            "Epoch 16: Train Loss = 0.2499, Eval Loss = 0.2463\n",
            "Epoch 17: Train Loss = 0.2467, Eval Loss = 0.2478\n",
            "Epoch 18: Train Loss = 0.2402, Eval Loss = 0.2480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:47:45,108] Trial 3 finished with value: 0.2493184357881546 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 8.509979449576007e-05, 'alpha': 0.18529583966325883}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss = 0.2385, Eval Loss = 0.2493\n",
            "Early stopping triggered at epoch 19\n",
            "Epoch 1: Train Loss = 1.1099, Eval Loss = 0.2836\n",
            "Epoch 2: Train Loss = 0.8757, Eval Loss = 0.2818\n",
            "Epoch 3: Train Loss = 0.7054, Eval Loss = 0.2825\n",
            "Epoch 4: Train Loss = 0.6407, Eval Loss = 0.2817\n",
            "Epoch 5: Train Loss = 0.6165, Eval Loss = 0.2822\n",
            "Epoch 6: Train Loss = 0.6059, Eval Loss = 0.2819\n",
            "Epoch 7: Train Loss = 0.5980, Eval Loss = 0.2818\n",
            "Epoch 8: Train Loss = 0.5918, Eval Loss = 0.2814\n",
            "Epoch 9: Train Loss = 0.5865, Eval Loss = 0.2811\n",
            "Epoch 10: Train Loss = 0.5839, Eval Loss = 0.2817\n",
            "Epoch 11: Train Loss = 0.5798, Eval Loss = 0.2809\n",
            "Epoch 12: Train Loss = 0.5763, Eval Loss = 0.2810\n",
            "Epoch 13: Train Loss = 0.5728, Eval Loss = 0.2807\n",
            "Epoch 14: Train Loss = 0.5684, Eval Loss = 0.2804\n",
            "Epoch 15: Train Loss = 0.5653, Eval Loss = 0.2807\n",
            "Epoch 16: Train Loss = 0.5773, Eval Loss = 0.2804\n",
            "Epoch 17: Train Loss = 0.5582, Eval Loss = 0.2803\n",
            "Epoch 18: Train Loss = 0.5540, Eval Loss = 0.2798\n",
            "Epoch 19: Train Loss = 0.5516, Eval Loss = 0.2798\n",
            "Epoch 20: Train Loss = 0.5474, Eval Loss = 0.2798\n",
            "Epoch 21: Train Loss = 0.5443, Eval Loss = 0.2797\n",
            "Epoch 22: Train Loss = 0.5416, Eval Loss = 0.2795\n",
            "Epoch 23: Train Loss = 0.5371, Eval Loss = 0.2793\n",
            "Epoch 24: Train Loss = 0.5330, Eval Loss = 0.2791\n",
            "Epoch 25: Train Loss = 0.5305, Eval Loss = 0.2788\n",
            "Epoch 26: Train Loss = 0.5259, Eval Loss = 0.2787\n",
            "Epoch 27: Train Loss = 0.5216, Eval Loss = 0.2786\n",
            "Epoch 28: Train Loss = 0.5171, Eval Loss = 0.2783\n",
            "Epoch 29: Train Loss = 0.5124, Eval Loss = 0.2779\n",
            "Epoch 30: Train Loss = 0.5079, Eval Loss = 0.2779\n",
            "Epoch 31: Train Loss = 0.5024, Eval Loss = 0.2773\n",
            "Epoch 32: Train Loss = 0.4973, Eval Loss = 0.2772\n",
            "Epoch 33: Train Loss = 0.4998, Eval Loss = 0.2767\n",
            "Epoch 34: Train Loss = 0.4922, Eval Loss = 0.2765\n",
            "Epoch 35: Train Loss = 0.4791, Eval Loss = 0.2762\n",
            "Epoch 36: Train Loss = 0.4727, Eval Loss = 0.2758\n",
            "Epoch 37: Train Loss = 0.4664, Eval Loss = 0.2755\n",
            "Epoch 38: Train Loss = 0.4597, Eval Loss = 0.2754\n",
            "Epoch 39: Train Loss = 0.4531, Eval Loss = 0.2749\n",
            "Epoch 40: Train Loss = 0.4454, Eval Loss = 0.2748\n",
            "Epoch 41: Train Loss = 0.4407, Eval Loss = 0.2747\n",
            "Epoch 42: Train Loss = 0.4336, Eval Loss = 0.2744\n",
            "Epoch 43: Train Loss = 0.4281, Eval Loss = 0.2741\n",
            "Epoch 44: Train Loss = 0.4223, Eval Loss = 0.2739\n",
            "Epoch 45: Train Loss = 0.4176, Eval Loss = 0.2737\n",
            "Epoch 46: Train Loss = 0.4122, Eval Loss = 0.2737\n",
            "Epoch 47: Train Loss = 0.4075, Eval Loss = 0.2736\n",
            "Epoch 48: Train Loss = 0.4093, Eval Loss = 0.2734\n",
            "Epoch 49: Train Loss = 0.3998, Eval Loss = 0.2737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:49:49,705] Trial 4 finished with value: 0.2733435332775116 and parameters: {'hidden_dim': 128, 'n_layers': 4, 'lr': 2.1864712800755953e-05, 'alpha': 0.3155324332004457}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.3938, Eval Loss = 0.2733\n",
            "Epoch 1: Train Loss = 1.0530, Eval Loss = 0.2623\n",
            "Epoch 2: Train Loss = 0.7122, Eval Loss = 0.2613\n",
            "Epoch 3: Train Loss = 0.6011, Eval Loss = 0.2624\n",
            "Epoch 4: Train Loss = 0.5652, Eval Loss = 0.2630\n",
            "Epoch 5: Train Loss = 0.5482, Eval Loss = 0.2633\n",
            "Epoch 6: Train Loss = 0.5390, Eval Loss = 0.2614\n",
            "Epoch 7: Train Loss = 0.5337, Eval Loss = 0.2617\n",
            "Epoch 8: Train Loss = 0.5278, Eval Loss = 0.2613\n",
            "Epoch 9: Train Loss = 0.5235, Eval Loss = 0.2610\n",
            "Epoch 10: Train Loss = 0.5171, Eval Loss = 0.2614\n",
            "Epoch 11: Train Loss = 0.5136, Eval Loss = 0.2605\n",
            "Epoch 12: Train Loss = 0.5092, Eval Loss = 0.2602\n",
            "Epoch 13: Train Loss = 0.5041, Eval Loss = 0.2595\n",
            "Epoch 14: Train Loss = 0.4999, Eval Loss = 0.2592\n",
            "Epoch 15: Train Loss = 0.4973, Eval Loss = 0.2590\n",
            "Epoch 16: Train Loss = 0.4862, Eval Loss = 0.2585\n",
            "Epoch 17: Train Loss = 0.4811, Eval Loss = 0.2574\n",
            "Epoch 18: Train Loss = 0.4732, Eval Loss = 0.2572\n",
            "Epoch 19: Train Loss = 0.4659, Eval Loss = 0.2565\n",
            "Epoch 20: Train Loss = 0.4572, Eval Loss = 0.2561\n",
            "Epoch 21: Train Loss = 0.4471, Eval Loss = 0.2555\n",
            "Epoch 22: Train Loss = 0.4354, Eval Loss = 0.2551\n",
            "Epoch 23: Train Loss = 0.4292, Eval Loss = 0.2546\n",
            "Epoch 24: Train Loss = 0.4189, Eval Loss = 0.2544\n",
            "Epoch 25: Train Loss = 0.4097, Eval Loss = 0.2539\n",
            "Epoch 26: Train Loss = 0.4017, Eval Loss = 0.2540\n",
            "Epoch 27: Train Loss = 0.3944, Eval Loss = 0.2535\n",
            "Epoch 28: Train Loss = 0.3863, Eval Loss = 0.2535\n",
            "Epoch 29: Train Loss = 0.3794, Eval Loss = 0.2528\n",
            "Epoch 30: Train Loss = 0.3763, Eval Loss = 0.2529\n",
            "Epoch 31: Train Loss = 0.3676, Eval Loss = 0.2525\n",
            "Epoch 32: Train Loss = 0.3609, Eval Loss = 0.2525\n",
            "Epoch 33: Train Loss = 0.3568, Eval Loss = 0.2524\n",
            "Epoch 34: Train Loss = 0.3505, Eval Loss = 0.2520\n",
            "Epoch 35: Train Loss = 0.3469, Eval Loss = 0.2520\n",
            "Epoch 36: Train Loss = 0.3405, Eval Loss = 0.2522\n",
            "Epoch 37: Train Loss = 0.3351, Eval Loss = 0.2521\n",
            "Epoch 38: Train Loss = 0.3321, Eval Loss = 0.2519\n",
            "Epoch 39: Train Loss = 0.3271, Eval Loss = 0.2519\n",
            "Epoch 40: Train Loss = 0.3248, Eval Loss = 0.2520\n",
            "Epoch 41: Train Loss = 0.3202, Eval Loss = 0.2519\n",
            "Epoch 42: Train Loss = 0.3149, Eval Loss = 0.2518\n",
            "Epoch 43: Train Loss = 0.3129, Eval Loss = 0.2516\n",
            "Epoch 44: Train Loss = 0.3086, Eval Loss = 0.2514\n",
            "Epoch 45: Train Loss = 0.3048, Eval Loss = 0.2514\n",
            "Epoch 46: Train Loss = 0.3036, Eval Loss = 0.2515\n",
            "Epoch 47: Train Loss = 0.3005, Eval Loss = 0.2516\n",
            "Epoch 48: Train Loss = 0.2968, Eval Loss = 0.2514\n",
            "Epoch 49: Train Loss = 0.2944, Eval Loss = 0.2513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:52:04,835] Trial 5 finished with value: 0.2511976361274719 and parameters: {'hidden_dim': 256, 'n_layers': 4, 'lr': 1.977413122210332e-05, 'alpha': 0.19625321141587435}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.2924, Eval Loss = 0.2512\n",
            "Epoch 1: Train Loss = 0.8289, Eval Loss = 0.2880\n",
            "Epoch 2: Train Loss = 0.6486, Eval Loss = 0.2858\n",
            "Epoch 3: Train Loss = 0.6021, Eval Loss = 0.2855\n",
            "Epoch 4: Train Loss = 0.5667, Eval Loss = 0.2823\n",
            "Epoch 5: Train Loss = 0.5342, Eval Loss = 0.2818\n",
            "Epoch 6: Train Loss = 0.5014, Eval Loss = 0.2810\n",
            "Epoch 7: Train Loss = 0.4742, Eval Loss = 0.2805\n",
            "Epoch 8: Train Loss = 0.4496, Eval Loss = 0.2817\n",
            "Epoch 9: Train Loss = 0.4273, Eval Loss = 0.2811\n",
            "Epoch 10: Train Loss = 0.4063, Eval Loss = 0.2809\n",
            "Epoch 11: Train Loss = 0.3966, Eval Loss = 0.2808\n",
            "Epoch 12: Train Loss = 0.3798, Eval Loss = 0.2812\n",
            "Epoch 13: Train Loss = 0.3641, Eval Loss = 0.2809\n",
            "Epoch 14: Train Loss = 0.3524, Eval Loss = 0.2811\n",
            "Epoch 15: Train Loss = 0.3386, Eval Loss = 0.2812\n",
            "Epoch 16: Train Loss = 0.3293, Eval Loss = 0.2819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:52:43,281] Trial 6 finished with value: 0.28121981024742126 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 5.927281568613536e-05, 'alpha': 0.3865527492388211}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.3239, Eval Loss = 0.2812\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 0.9345, Eval Loss = 0.2590\n",
            "Epoch 2: Train Loss = 0.6582, Eval Loss = 0.2592\n",
            "Epoch 3: Train Loss = 0.5781, Eval Loss = 0.2599\n",
            "Epoch 4: Train Loss = 0.5512, Eval Loss = 0.2594\n",
            "Epoch 5: Train Loss = 0.5374, Eval Loss = 0.2590\n",
            "Epoch 6: Train Loss = 0.5375, Eval Loss = 0.2588\n",
            "Epoch 7: Train Loss = 0.5202, Eval Loss = 0.2578\n",
            "Epoch 8: Train Loss = 0.5106, Eval Loss = 0.2573\n",
            "Epoch 9: Train Loss = 0.5009, Eval Loss = 0.2573\n",
            "Epoch 10: Train Loss = 0.4960, Eval Loss = 0.2567\n",
            "Epoch 11: Train Loss = 0.4855, Eval Loss = 0.2564\n",
            "Epoch 12: Train Loss = 0.4798, Eval Loss = 0.2551\n",
            "Epoch 13: Train Loss = 0.4670, Eval Loss = 0.2545\n",
            "Epoch 14: Train Loss = 0.4562, Eval Loss = 0.2543\n",
            "Epoch 15: Train Loss = 0.4453, Eval Loss = 0.2530\n",
            "Epoch 16: Train Loss = 0.4330, Eval Loss = 0.2532\n",
            "Epoch 17: Train Loss = 0.4245, Eval Loss = 0.2524\n",
            "Epoch 18: Train Loss = 0.4131, Eval Loss = 0.2518\n",
            "Epoch 19: Train Loss = 0.4009, Eval Loss = 0.2519\n",
            "Epoch 20: Train Loss = 0.3933, Eval Loss = 0.2512\n",
            "Epoch 21: Train Loss = 0.3837, Eval Loss = 0.2512\n",
            "Epoch 22: Train Loss = 0.3742, Eval Loss = 0.2508\n",
            "Epoch 23: Train Loss = 0.3655, Eval Loss = 0.2508\n",
            "Epoch 24: Train Loss = 0.3577, Eval Loss = 0.2511\n",
            "Epoch 25: Train Loss = 0.3515, Eval Loss = 0.2508\n",
            "Epoch 26: Train Loss = 0.3446, Eval Loss = 0.2507\n",
            "Epoch 27: Train Loss = 0.3379, Eval Loss = 0.2510\n",
            "Epoch 28: Train Loss = 0.3320, Eval Loss = 0.2505\n",
            "Epoch 29: Train Loss = 0.3265, Eval Loss = 0.2506\n",
            "Epoch 30: Train Loss = 0.3213, Eval Loss = 0.2503\n",
            "Epoch 31: Train Loss = 0.3175, Eval Loss = 0.2503\n",
            "Epoch 32: Train Loss = 0.3121, Eval Loss = 0.2503\n",
            "Epoch 33: Train Loss = 0.3086, Eval Loss = 0.2502\n",
            "Epoch 34: Train Loss = 0.3037, Eval Loss = 0.2504\n",
            "Epoch 35: Train Loss = 0.2992, Eval Loss = 0.2505\n",
            "Epoch 36: Train Loss = 0.2964, Eval Loss = 0.2504\n",
            "Epoch 37: Train Loss = 0.2933, Eval Loss = 0.2503\n",
            "Epoch 38: Train Loss = 0.2899, Eval Loss = 0.2504\n",
            "Epoch 39: Train Loss = 0.2857, Eval Loss = 0.2503\n",
            "Epoch 40: Train Loss = 0.2834, Eval Loss = 0.2503\n",
            "Epoch 41: Train Loss = 0.2811, Eval Loss = 0.2503\n",
            "Epoch 42: Train Loss = 0.2785, Eval Loss = 0.2503\n",
            "Epoch 43: Train Loss = 0.2756, Eval Loss = 0.2500\n",
            "Epoch 44: Train Loss = 0.2737, Eval Loss = 0.2503\n",
            "Epoch 45: Train Loss = 0.2723, Eval Loss = 0.2502\n",
            "Epoch 46: Train Loss = 0.2691, Eval Loss = 0.2500\n",
            "Epoch 47: Train Loss = 0.2683, Eval Loss = 0.2500\n",
            "Epoch 48: Train Loss = 0.2666, Eval Loss = 0.2501\n",
            "Epoch 49: Train Loss = 0.2646, Eval Loss = 0.2500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:54:39,762] Trial 7 finished with value: 0.2500690221786499 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 4.318908417858992e-05, 'alpha': 0.18182390053148564}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.2632, Eval Loss = 0.2501\n",
            "Epoch 1: Train Loss = 0.6734, Eval Loss = 0.2589\n",
            "Epoch 2: Train Loss = 0.5527, Eval Loss = 0.2551\n",
            "Epoch 3: Train Loss = 0.5154, Eval Loss = 0.2538\n",
            "Epoch 4: Train Loss = 0.4825, Eval Loss = 0.2519\n",
            "Epoch 5: Train Loss = 0.4318, Eval Loss = 0.2495\n",
            "Epoch 6: Train Loss = 0.3863, Eval Loss = 0.2497\n",
            "Epoch 7: Train Loss = 0.3522, Eval Loss = 0.2512\n",
            "Epoch 8: Train Loss = 0.3259, Eval Loss = 0.2504\n",
            "Epoch 9: Train Loss = 0.3191, Eval Loss = 0.2515\n",
            "Epoch 10: Train Loss = 0.3008, Eval Loss = 0.2521\n",
            "Epoch 11: Train Loss = 0.2932, Eval Loss = 0.2525\n",
            "Epoch 12: Train Loss = 0.2861, Eval Loss = 0.2544\n",
            "Epoch 13: Train Loss = 0.2878, Eval Loss = 0.2562\n",
            "Epoch 14: Train Loss = 0.2779, Eval Loss = 0.2548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:55:13,179] Trial 8 finished with value: 0.25510016083717346 and parameters: {'hidden_dim': 128, 'n_layers': 2, 'lr': 0.00042072335824518153, 'alpha': 0.2067189353286171}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss = 0.2669, Eval Loss = 0.2551\n",
            "Early stopping triggered at epoch 15\n",
            "Epoch 1: Train Loss = 0.7685, Eval Loss = 0.2619\n",
            "Epoch 2: Train Loss = 0.5763, Eval Loss = 0.2613\n",
            "Epoch 3: Train Loss = 0.5308, Eval Loss = 0.2599\n",
            "Epoch 4: Train Loss = 0.4885, Eval Loss = 0.2574\n",
            "Epoch 5: Train Loss = 0.4576, Eval Loss = 0.2565\n",
            "Epoch 6: Train Loss = 0.4265, Eval Loss = 0.2570\n",
            "Epoch 7: Train Loss = 0.4009, Eval Loss = 0.2562\n",
            "Epoch 8: Train Loss = 0.3778, Eval Loss = 0.2571\n",
            "Epoch 9: Train Loss = 0.3583, Eval Loss = 0.2563\n",
            "Epoch 10: Train Loss = 0.3394, Eval Loss = 0.2560\n",
            "Epoch 11: Train Loss = 0.3243, Eval Loss = 0.2562\n",
            "Epoch 12: Train Loss = 0.3087, Eval Loss = 0.2563\n",
            "Epoch 13: Train Loss = 0.2973, Eval Loss = 0.2569\n",
            "Epoch 14: Train Loss = 0.2892, Eval Loss = 0.2558\n",
            "Epoch 15: Train Loss = 0.2791, Eval Loss = 0.2560\n",
            "Epoch 16: Train Loss = 0.2737, Eval Loss = 0.2561\n",
            "Epoch 17: Train Loss = 0.2681, Eval Loss = 0.2558\n",
            "Epoch 18: Train Loss = 0.2577, Eval Loss = 0.2561\n",
            "Epoch 19: Train Loss = 0.2555, Eval Loss = 0.2567\n",
            "Epoch 20: Train Loss = 0.2463, Eval Loss = 0.2562\n",
            "Epoch 21: Train Loss = 0.2431, Eval Loss = 0.2566\n",
            "Epoch 22: Train Loss = 0.2366, Eval Loss = 0.2570\n",
            "Epoch 23: Train Loss = 0.2310, Eval Loss = 0.2575\n",
            "Epoch 24: Train Loss = 0.2242, Eval Loss = 0.2574\n",
            "Epoch 25: Train Loss = 0.2189, Eval Loss = 0.2574\n",
            "Epoch 26: Train Loss = 0.2137, Eval Loss = 0.2575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:56:12,572] Trial 9 finished with value: 0.2581893801689148 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 6.130609866412128e-05, 'alpha': 0.23358087853358633}. Best is trial 3 with value: 0.2493184357881546.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: Train Loss = 0.2077, Eval Loss = 0.2582\n",
            "Early stopping triggered at epoch 27\n",
            "Epoch 1: Train Loss = 0.6154, Eval Loss = 0.2380\n",
            "Epoch 2: Train Loss = 0.5264, Eval Loss = 0.2364\n",
            "Epoch 3: Train Loss = 0.4724, Eval Loss = 0.2326\n",
            "Epoch 4: Train Loss = 0.4382, Eval Loss = 0.2328\n",
            "Epoch 5: Train Loss = 0.3742, Eval Loss = 0.2324\n",
            "Epoch 6: Train Loss = 0.3409, Eval Loss = 0.2333\n",
            "Epoch 7: Train Loss = 0.3270, Eval Loss = 0.2319\n",
            "Epoch 8: Train Loss = 0.2851, Eval Loss = 0.2353\n",
            "Epoch 9: Train Loss = 0.2840, Eval Loss = 0.2353\n",
            "Epoch 10: Train Loss = 0.2831, Eval Loss = 0.2385\n",
            "Epoch 11: Train Loss = 0.2424, Eval Loss = 0.2387\n",
            "Epoch 12: Train Loss = 0.2597, Eval Loss = 0.2384\n",
            "Epoch 13: Train Loss = 0.2549, Eval Loss = 0.2400\n",
            "Epoch 14: Train Loss = 0.2270, Eval Loss = 0.2404\n",
            "Epoch 15: Train Loss = 0.2216, Eval Loss = 0.2424\n",
            "Epoch 16: Train Loss = 0.2229, Eval Loss = 0.2445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:56:57,969] Trial 10 finished with value: 0.24233458936214447 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.00021591891526882726, 'alpha': 0.10034863051565202}. Best is trial 10 with value: 0.24233458936214447.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.2195, Eval Loss = 0.2423\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 0.6213, Eval Loss = 0.2385\n",
            "Epoch 2: Train Loss = 0.5327, Eval Loss = 0.2364\n",
            "Epoch 3: Train Loss = 0.4932, Eval Loss = 0.2355\n",
            "Epoch 4: Train Loss = 0.4504, Eval Loss = 0.2330\n",
            "Epoch 5: Train Loss = 0.4056, Eval Loss = 0.2335\n",
            "Epoch 6: Train Loss = 0.3822, Eval Loss = 0.2338\n",
            "Epoch 7: Train Loss = 0.3171, Eval Loss = 0.2357\n",
            "Epoch 8: Train Loss = 0.3001, Eval Loss = 0.2360\n",
            "Epoch 9: Train Loss = 0.2871, Eval Loss = 0.2398\n",
            "Epoch 10: Train Loss = 0.2740, Eval Loss = 0.2393\n",
            "Epoch 11: Train Loss = 0.2581, Eval Loss = 0.2396\n",
            "Epoch 12: Train Loss = 0.2543, Eval Loss = 0.2420\n",
            "Epoch 13: Train Loss = 0.2361, Eval Loss = 0.2410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:57:36,290] Trial 11 finished with value: 0.24336041510105133 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.00022656908651131377, 'alpha': 0.10127550990352197}. Best is trial 10 with value: 0.24233458936214447.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.2406, Eval Loss = 0.2434\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.6204, Eval Loss = 0.2403\n",
            "Epoch 2: Train Loss = 0.5327, Eval Loss = 0.2361\n",
            "Epoch 3: Train Loss = 0.4812, Eval Loss = 0.2327\n",
            "Epoch 4: Train Loss = 0.4520, Eval Loss = 0.2289\n",
            "Epoch 5: Train Loss = 0.4127, Eval Loss = 0.2318\n",
            "Epoch 6: Train Loss = 0.3662, Eval Loss = 0.2342\n",
            "Epoch 7: Train Loss = 0.3188, Eval Loss = 0.2357\n",
            "Epoch 8: Train Loss = 0.3135, Eval Loss = 0.2376\n",
            "Epoch 9: Train Loss = 0.2842, Eval Loss = 0.2391\n",
            "Epoch 10: Train Loss = 0.2878, Eval Loss = 0.2394\n",
            "Epoch 11: Train Loss = 0.2499, Eval Loss = 0.2389\n",
            "Epoch 12: Train Loss = 0.2623, Eval Loss = 0.2395\n",
            "Epoch 13: Train Loss = 0.2334, Eval Loss = 0.2437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:58:13,683] Trial 12 finished with value: 0.24161292612552643 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.0002464192702033118, 'alpha': 0.10067209047115924}. Best is trial 12 with value: 0.24161292612552643.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.2342, Eval Loss = 0.2416\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.8319, Eval Loss = 0.3044\n",
            "Epoch 2: Train Loss = 0.6947, Eval Loss = 0.3013\n",
            "Epoch 3: Train Loss = 0.6581, Eval Loss = 0.2975\n",
            "Epoch 4: Train Loss = 0.6214, Eval Loss = 0.2973\n",
            "Epoch 5: Train Loss = 0.5589, Eval Loss = 0.2960\n",
            "Epoch 6: Train Loss = 0.5099, Eval Loss = 0.2974\n",
            "Epoch 7: Train Loss = 0.4614, Eval Loss = 0.2975\n",
            "Epoch 8: Train Loss = 0.4508, Eval Loss = 0.2962\n",
            "Epoch 9: Train Loss = 0.4406, Eval Loss = 0.2972\n",
            "Epoch 10: Train Loss = 0.4291, Eval Loss = 0.2974\n",
            "Epoch 11: Train Loss = 0.4120, Eval Loss = 0.2978\n",
            "Epoch 12: Train Loss = 0.3970, Eval Loss = 0.2991\n",
            "Epoch 13: Train Loss = 0.4019, Eval Loss = 0.3009\n",
            "Epoch 14: Train Loss = 0.3939, Eval Loss = 0.3022\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:58:53,204] Trial 13 finished with value: 0.3035815954208374 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.00016492090308313788, 'alpha': 0.4940885555302093}. Best is trial 12 with value: 0.24161292612552643.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss = 0.3877, Eval Loss = 0.3036\n",
            "Early stopping triggered at epoch 15\n",
            "Epoch 1: Train Loss = 0.7387, Eval Loss = 0.2365\n",
            "Epoch 2: Train Loss = 0.6230, Eval Loss = 0.2362\n",
            "Epoch 3: Train Loss = 0.5203, Eval Loss = 0.2363\n",
            "Epoch 4: Train Loss = 0.5144, Eval Loss = 0.2385\n",
            "Epoch 5: Train Loss = 0.4653, Eval Loss = 0.2392\n",
            "Epoch 6: Train Loss = 0.4301, Eval Loss = 0.2383\n",
            "Epoch 7: Train Loss = 0.4065, Eval Loss = 0.2406\n",
            "Epoch 8: Train Loss = 0.3669, Eval Loss = 0.2381\n",
            "Epoch 9: Train Loss = 0.3217, Eval Loss = 0.2393\n",
            "Epoch 10: Train Loss = 0.2900, Eval Loss = 0.2391\n",
            "Epoch 11: Train Loss = 0.2900, Eval Loss = 0.2403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:59:20,104] Trial 14 finished with value: 0.24102436006069183 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 0.0008825527218508858, 'alpha': 0.1020428973603548}. Best is trial 14 with value: 0.24102436006069183.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss = 0.2623, Eval Loss = 0.2410\n",
            "Early stopping triggered at epoch 12\n",
            "Epoch 1: Train Loss = 0.7211, Eval Loss = 0.2424\n",
            "Epoch 2: Train Loss = 0.5932, Eval Loss = 0.2419\n",
            "Epoch 3: Train Loss = 0.5332, Eval Loss = 0.2407\n",
            "Epoch 4: Train Loss = 0.4820, Eval Loss = 0.2415\n",
            "Epoch 5: Train Loss = 0.4641, Eval Loss = 0.2431\n",
            "Epoch 6: Train Loss = 0.4498, Eval Loss = 0.2460\n",
            "Epoch 7: Train Loss = 0.3930, Eval Loss = 0.2451\n",
            "Epoch 8: Train Loss = 0.3959, Eval Loss = 0.2465\n",
            "Epoch 9: Train Loss = 0.3647, Eval Loss = 0.2490\n",
            "Epoch 10: Train Loss = 0.3058, Eval Loss = 0.2476\n",
            "Epoch 11: Train Loss = 0.2867, Eval Loss = 0.2485\n",
            "Epoch 12: Train Loss = 0.2737, Eval Loss = 0.2480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-09 16:59:48,778] Trial 15 finished with value: 0.24867789447307587 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 0.0008624623241199027, 'alpha': 0.13003617666739756}. Best is trial 14 with value: 0.24102436006069183.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.2652, Eval Loss = 0.2487\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.6677, Eval Loss = 0.2475\n",
            "Epoch 2: Train Loss = 0.5572, Eval Loss = 0.2449\n",
            "Epoch 3: Train Loss = 0.5178, Eval Loss = 0.2432\n",
            "Epoch 4: Train Loss = 0.4772, Eval Loss = 0.2426\n",
            "Epoch 5: Train Loss = 0.4661, Eval Loss = 0.2444\n",
            "Epoch 6: Train Loss = 0.3989, Eval Loss = 0.2451\n",
            "Epoch 7: Train Loss = 0.3560, Eval Loss = 0.2463\n"
          ]
        }
      ],
      "source": [
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "study.optimize(objective, n_trials=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4e3bb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Best hyperparameters:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90832a27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MAE: 44.8259\n",
            "Test RMSE: 257.4293\n"
          ]
        }
      ],
      "source": [
        "# predict\n",
        "\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = mlp_model(torch.tensor(x_test_mlp, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_mlp  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HAyut1x8xchV",
      "metadata": {
        "id": "HAyut1x8xchV"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "red-river-energy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
