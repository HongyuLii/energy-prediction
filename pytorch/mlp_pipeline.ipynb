{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9cac5cff",
      "metadata": {
        "id": "9cac5cff"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "41f63eb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=4,5\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_VISIBLE_DEVICES=4,5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6c4a11a8",
      "metadata": {
        "id": "6c4a11a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# (Optional) If you're working inside Jupyter\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e80aa0ce",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "2ff202c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from data_processor_v2 import DataProcessorUpdated\n",
        "\n",
        "processor = DataProcessorUpdated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "caae40c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-12-31 23:00:00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/ephnvme/weiliang/synthesis-data/energy-prediction/pytorch/data_processor_v2.py:41: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[time_col] = pd.to_datetime(df[time_col])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-01-01 23:00:00\n",
            "2023-12-31 23:00:00\n",
            "2023-12-31 23:00:00\n"
          ]
        }
      ],
      "source": [
        "processor.load_and_clean_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "35901f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.combine_all_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "8c5cff35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "DAP_SystemLambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SCED_system_lambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_coal_and_lignite",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_hydro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_nuclear",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_power_storage",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_solar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_wind",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_natural_gas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_other",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Load_load",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "delta_price",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "89087e79-2cb7-4b9a-a25a-b083a06ad77c",
              "rows": [
                [
                  "2019-01-01 00:00:00",
                  null,
                  "13.8375616073608",
                  "6116.41904",
                  "185.465296",
                  "3895.95194",
                  "0.0",
                  "0.0",
                  "14311.36445",
                  "12512.80815",
                  "2.534772",
                  "36951.0",
                  null
                ],
                [
                  "2019-01-01 01:00:00",
                  null,
                  "15.4648694992065",
                  "6423.24236",
                  "186.667008",
                  "3894.973176",
                  "0.0",
                  "0.0",
                  "14298.52586",
                  "12434.13638",
                  "2.947464",
                  "37112.0",
                  null
                ],
                [
                  "2019-01-01 02:00:00",
                  null,
                  "15.4877195358276",
                  "6309.280752",
                  "187.408832",
                  "3894.733152",
                  "0.0",
                  "0.0",
                  "14030.82875",
                  "12797.25831",
                  "-1.954544",
                  "37154.0",
                  null
                ],
                [
                  "2019-01-01 03:00:00",
                  null,
                  "15.770092010498",
                  "6416.671292",
                  "187.817564",
                  "3894.714576",
                  "0.0",
                  "0.0",
                  "13610.13937",
                  "13279.01803",
                  "1.887324",
                  "37283.0",
                  null
                ],
                [
                  "2019-01-01 04:00:00",
                  null,
                  "16.0360851287842",
                  "6569.580884",
                  "186.990116",
                  "3892.748912",
                  "0.0",
                  "0.0",
                  "13414.14969",
                  "13585.26799",
                  "-0.2011",
                  "37817.0",
                  null
                ],
                [
                  "2019-01-01 05:00:00",
                  null,
                  "16.7470397949219",
                  "6806.102292",
                  "222.169372",
                  "3893.877024",
                  "0.0",
                  "0.0",
                  "12743.16529",
                  "14786.60827",
                  "2.955692",
                  "38763.0",
                  null
                ],
                [
                  "2019-01-01 06:00:00",
                  null,
                  "17.5206718444824",
                  "7356.916872",
                  "223.598596",
                  "3894.202416",
                  "0.0",
                  "0.0",
                  "11695.73501",
                  "16435.8807",
                  "4.032436",
                  "39849.0",
                  null
                ],
                [
                  "2019-01-01 07:00:00",
                  null,
                  "17.7318916320801",
                  "7627.659176",
                  "223.522816",
                  "3891.496004",
                  "0.0",
                  "0.0",
                  "10769.46719",
                  "17849.76048",
                  "2.988096",
                  "40410.0",
                  null
                ],
                [
                  "2019-01-01 08:00:00",
                  null,
                  "18.4140319824219",
                  "8034.6643",
                  "222.1581",
                  "3892.873952",
                  "0.0",
                  "15.504816",
                  "9749.372156",
                  "18761.96472",
                  "3.074772",
                  "40892.0",
                  null
                ],
                [
                  "2019-01-01 09:00:00",
                  null,
                  "19.588623046875",
                  "8861.727808",
                  "223.473352",
                  "3894.109608",
                  "0.0",
                  "73.208772",
                  "8688.958132",
                  "19735.37034",
                  "3.040152",
                  "41671.0",
                  null
                ],
                [
                  "2019-01-01 10:00:00",
                  null,
                  "20.7471313476563",
                  "9938.088416",
                  "223.699976",
                  "3890.997248",
                  "0.0",
                  "165.856592",
                  "7236.261324",
                  "20776.384",
                  "3.8969",
                  "42146.0",
                  null
                ],
                [
                  "2019-01-01 11:00:00",
                  null,
                  "21.3603363037109",
                  "10401.91125",
                  "200.562196",
                  "3892.734124",
                  "0.0",
                  "233.450596",
                  "6421.903592",
                  "21216.38172",
                  "3.608564",
                  "42206.0",
                  null
                ],
                [
                  "2019-01-01 12:00:00",
                  null,
                  "21.6746959686279",
                  "10843.79388",
                  "186.330668",
                  "3892.944372",
                  "0.0",
                  "311.36348",
                  "5665.944092",
                  "21339.63762",
                  "-0.050588",
                  "41807.0",
                  null
                ],
                [
                  "2019-01-01 13:00:00",
                  null,
                  "21.7823867797852",
                  "11049.00355",
                  "186.441272",
                  "3892.50776",
                  "0.0",
                  "259.819596",
                  "5217.935984",
                  "21018.28545",
                  "3.15518",
                  "41320.0",
                  null
                ],
                [
                  "2019-01-01 14:00:00",
                  null,
                  "21.9466972351074",
                  "11187.95622",
                  "186.049876",
                  "3891.574964",
                  "0.0",
                  "203.82868",
                  "4859.254484",
                  "20871.27624",
                  "1.594112",
                  "40949.0",
                  null
                ],
                [
                  "2019-01-01 15:00:00",
                  null,
                  "26.3067970275879",
                  "11535.01104",
                  "211.481304",
                  "3892.253344",
                  "0.0",
                  "110.826784",
                  "4233.964036",
                  "21118.54924",
                  "2.546792",
                  "40975.0",
                  null
                ],
                [
                  "2019-01-01 16:00:00",
                  null,
                  "26.8361930847168",
                  "11924.04599",
                  "249.026864",
                  "3892.451464",
                  "0.0",
                  "66.500996",
                  "3554.642004",
                  "21802.12896",
                  "3.056364",
                  "41783.0",
                  null
                ],
                [
                  "2019-01-01 17:00:00",
                  null,
                  "27.5510845184326",
                  "12276.57683",
                  "248.96194",
                  "3892.762276",
                  "0.0",
                  "15.013288",
                  "3354.061648",
                  "23212.87701",
                  "2.998796",
                  "43966.0",
                  null
                ],
                [
                  "2019-01-01 18:00:00",
                  null,
                  "33.4604682922363",
                  "12373.18407",
                  "221.384096",
                  "3892.680796",
                  "0.0",
                  "0.0",
                  "2992.843944",
                  "25837.25857",
                  "3.79044",
                  "45406.0",
                  null
                ],
                [
                  "2019-01-01 19:00:00",
                  null,
                  "34.9075584411621",
                  "12439.40505",
                  "221.815728",
                  "3892.293888",
                  "0.0",
                  "0.0",
                  "2857.59244",
                  "25935.07676",
                  "1.267524",
                  "45261.0",
                  null
                ],
                [
                  "2019-01-01 20:00:00",
                  null,
                  "34.0498199462891",
                  "12438.36693",
                  "195.830184",
                  "3892.080304",
                  "0.0",
                  "0.0",
                  "2759.597352",
                  "25786.21502",
                  "-1.325144",
                  "44875.0",
                  null
                ],
                [
                  "2019-01-01 21:00:00",
                  null,
                  "31.0697078704834",
                  "12465.79535",
                  "196.451852",
                  "3891.513288",
                  "0.0",
                  "0.0",
                  "2724.787952",
                  "24951.17857",
                  "-0.377196",
                  "43945.0",
                  null
                ],
                [
                  "2019-01-01 22:00:00",
                  null,
                  "31.1546306610107",
                  "12436.69127",
                  "158.890524",
                  "3890.599492",
                  "0.0",
                  "0.0",
                  "2434.006624",
                  "23910.70212",
                  "0.041472",
                  "42277.0",
                  null
                ],
                [
                  "2019-01-01 23:00:00",
                  null,
                  "26.8461532592773",
                  "11874.96931",
                  "159.464984",
                  "3891.757256",
                  "0.0",
                  "0.0",
                  "2510.4403",
                  "22597.71201",
                  "2.822164",
                  "40543.0",
                  null
                ],
                [
                  "2019-01-02 00:00:00",
                  "23.925",
                  "26.1592845916748",
                  "11019.0404",
                  "211.80336",
                  "3891.427324",
                  "0.0",
                  "0.0",
                  "2556.493476",
                  "21857.30259",
                  "0.776324",
                  "39277.0",
                  "2.2342845916748004"
                ],
                [
                  "2019-01-02 01:00:00",
                  "23.314",
                  "25.9841365814209",
                  "10388.7317",
                  "188.16956",
                  "3891.118712",
                  "0.0",
                  "0.0",
                  "2417.738312",
                  "21725.04409",
                  "1.218988",
                  "38589.0",
                  "2.6701365814208984"
                ],
                [
                  "2019-01-02 02:00:00",
                  "23.3475",
                  "25.3712673187256",
                  "10148.57656",
                  "187.471732",
                  "3890.877504",
                  "0.0",
                  "0.0",
                  "2693.351584",
                  "21409.53292",
                  "-2.470856",
                  "38431.0",
                  "2.0237673187256"
                ],
                [
                  "2019-01-02 03:00:00",
                  "23.0595",
                  "25.2762241363525",
                  "9846.024556",
                  "187.525788",
                  "3891.413216",
                  "0.0",
                  "0.0",
                  "3128.780528",
                  "21428.29015",
                  "-1.432144",
                  "38828.0",
                  "2.2167241363525"
                ],
                [
                  "2019-01-02 04:00:00",
                  "25.2672",
                  "24.5719661712646",
                  "9829.751588",
                  "188.180748",
                  "3892.101792",
                  "0.0",
                  "0.0",
                  "3289.184004",
                  "22151.42388",
                  "-3.166144",
                  "40043.0",
                  "-0.6952338287354003"
                ],
                [
                  "2019-01-02 05:00:00",
                  "28.8611",
                  "25.0743083953857",
                  "10341.36317",
                  "225.203888",
                  "3891.783612",
                  "0.0",
                  "0.0",
                  "3539.563424",
                  "23384.49495",
                  "-0.08526",
                  "42402.0",
                  "-3.786791604614301"
                ],
                [
                  "2019-01-02 06:00:00",
                  "39.4101",
                  "25.9785709381104",
                  "11733.04428",
                  "250.607476",
                  "3890.602976",
                  "0.0",
                  "0.0",
                  "2871.80052",
                  "25467.92225",
                  "0.570452",
                  "45219.0",
                  "-13.431529061889599"
                ],
                [
                  "2019-01-02 07:00:00",
                  "39.1896",
                  "29.2044925689697",
                  "12243.0151",
                  "247.146256",
                  "3889.973712",
                  "0.0",
                  "0.0",
                  "2553.030404",
                  "27772.4965",
                  "2.102536",
                  "47432.0",
                  "-9.985107431030297"
                ],
                [
                  "2019-01-02 08:00:00",
                  "36.3108",
                  "36.638427734375",
                  "12250.63438",
                  "248.447572",
                  "3890.307104",
                  "0.0",
                  "0.005384",
                  "2011.634756",
                  "29664.07621",
                  "2.383692",
                  "48598.0",
                  "0.3276277343749996"
                ],
                [
                  "2019-01-02 09:00:00",
                  "39.6983",
                  "40.1176872253418",
                  "12207.58335",
                  "263.57132",
                  "3895.736976",
                  "0.0",
                  "35.411584",
                  "2025.567152",
                  "30648.5328",
                  "-1.2047",
                  "49657.0",
                  "0.4193872253417936"
                ],
                [
                  "2019-01-02 10:00:00",
                  "40.2148",
                  "59.4540328979492",
                  "12269.39236",
                  "273.484616",
                  "3893.812596",
                  "0.0",
                  "107.043332",
                  "1867.155328",
                  "31570.85504",
                  "0.898424",
                  "50661.0",
                  "19.2392328979492"
                ],
                [
                  "2019-01-02 11:00:00",
                  "37.2478",
                  "62.8075675964355",
                  "12340.60632",
                  "230.893108",
                  "3894.783856",
                  "0.0",
                  "131.75698",
                  "1195.121152",
                  "33235.95221",
                  "1.521576",
                  "51295.0",
                  "25.5597675964355"
                ],
                [
                  "2019-01-02 12:00:00",
                  "34.5007",
                  "38.1134338378906",
                  "12180.95975",
                  "230.128864",
                  "3894.444364",
                  "0.0",
                  "147.411984",
                  "1308.978972",
                  "33378.0454",
                  "0.758804",
                  "51412.0",
                  "3.6127338378905947"
                ],
                [
                  "2019-01-02 13:00:00",
                  "34.7428",
                  "43.5680694580078",
                  "12255.0393",
                  "231.139796",
                  "3894.801384",
                  "0.0",
                  "212.907912",
                  "1337.093948",
                  "33392.38348",
                  "1.925832",
                  "51492.0",
                  "8.825269458007796"
                ],
                [
                  "2019-01-02 14:00:00",
                  "34.6144",
                  "36.8626899719238",
                  "12046.10978",
                  "230.807104",
                  "3893.390536",
                  "0.0",
                  "189.23948",
                  "1407.03348",
                  "33137.96618",
                  "2.24628",
                  "51264.0",
                  "2.2482899719237963"
                ],
                [
                  "2019-01-02 15:00:00",
                  "34.4056",
                  "32.3479118347168",
                  "11908.7674",
                  "267.818492",
                  "3894.09848",
                  "0.0",
                  "137.89176",
                  "2095.40284",
                  "32660.76262",
                  "1.693052",
                  "51152.0",
                  "-2.057688165283203"
                ],
                [
                  "2019-01-02 16:00:00",
                  "36.2957",
                  "38.1546897888184",
                  "11771.16732",
                  "304.06906",
                  "3893.31228",
                  "0.0",
                  "71.420348",
                  "1784.647496",
                  "33119.553",
                  "1.7932",
                  "51384.0",
                  "1.8589897888184055"
                ],
                [
                  "2019-01-02 17:00:00",
                  "64.5798",
                  "37.7884407043457",
                  "11733.58142",
                  "276.826592",
                  "3892.46698",
                  "0.0",
                  "20.599708",
                  "1647.287948",
                  "33945.36833",
                  "1.68566",
                  "52665.0",
                  "-26.791359295654303"
                ],
                [
                  "2019-01-02 18:00:00",
                  "66.9318",
                  "52.0153732299805",
                  "11649.02181",
                  "247.01132",
                  "3893.367304",
                  "0.0",
                  "0.0",
                  "1341.622648",
                  "35414.46146",
                  "-2.14424",
                  "53313.0",
                  "-14.916426770019498"
                ],
                [
                  "2019-01-02 19:00:00",
                  "41.2162",
                  "49.0191993713379",
                  "11712.16229",
                  "246.696932",
                  "3894.021436",
                  "0.0",
                  "0.0",
                  "892.246312",
                  "35377.1919",
                  "2.401672",
                  "52396.0",
                  "7.802999371337897"
                ],
                [
                  "2019-01-02 20:00:00",
                  "40.3369",
                  "49.094799041748",
                  "11802.12156",
                  "275.703976",
                  "3895.365856",
                  "0.0",
                  "0.0",
                  "544.153644",
                  "34717.37072",
                  "2.39128",
                  "51125.0",
                  "8.757899041747997"
                ],
                [
                  "2019-01-02 21:00:00",
                  "35.5165",
                  "38.3151359558105",
                  "11684.58332",
                  "277.337932",
                  "3895.42118",
                  "0.0",
                  "0.0",
                  "847.33536",
                  "32946.87372",
                  "1.697152",
                  "49288.0",
                  "2.7986359558104965"
                ],
                [
                  "2019-01-02 22:00:00",
                  "31.5755",
                  "36.8169250488281",
                  "11558.77353",
                  "275.119676",
                  "3893.64908",
                  "0.0",
                  "0.0",
                  "985.165264",
                  "30704.09202",
                  "-1.911472",
                  "46749.0",
                  "5.241425048828095"
                ],
                [
                  "2019-01-02 23:00:00",
                  "26.4935",
                  "30.2865982055664",
                  "11808.90794",
                  "276.018164",
                  "3892.330012",
                  "0.0",
                  "0.0",
                  "644.977968",
                  "28252.50481",
                  "1.073252",
                  "44381.0",
                  "3.793098205566398"
                ],
                [
                  "2019-01-03 00:00:00",
                  "26.6577",
                  "28.0744132995605",
                  "11447.44826",
                  "326.796432",
                  "3893.92314",
                  "0.0",
                  "0.0",
                  "1051.607656",
                  "26255.36574",
                  "-0.792896",
                  "42547.0",
                  "1.4167132995605023"
                ],
                [
                  "2019-01-03 01:00:00",
                  "24.3462",
                  "25.5825328826904",
                  "10882.30282",
                  "301.526784",
                  "3893.651784",
                  "0.0",
                  "0.0",
                  "1576.489276",
                  "24983.27008",
                  "0.819768",
                  "41478.0",
                  "1.2363328826904016"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 43848
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>23.1651</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>23.2113</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>21.3244</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>20.3351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>19.2456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00               NaN           13.837562   \n",
              "2019-01-01 01:00:00               NaN           15.464869   \n",
              "2019-01-01 02:00:00               NaN           15.487720   \n",
              "2019-01-01 03:00:00               NaN           15.770092   \n",
              "2019-01-01 04:00:00               NaN           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00           23.1651                 NaN   \n",
              "2024-01-01 20:00:00           23.2113                 NaN   \n",
              "2024-01-01 21:00:00           21.3244                 NaN   \n",
              "2024-01-01 22:00:00           20.3351                 NaN   \n",
              "2024-01-01 23:00:00           19.2456                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "73e0d9a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_dap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "1a9b0f63",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "datetime64[ns]",
                  "type": "datetime"
                },
                {
                  "name": "DAP_SystemLambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "SCED_system_lambda",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_coal_and_lignite",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_hydro",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_nuclear",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_power_storage",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_solar",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_wind",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_natural_gas",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Fuel_other",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "Load_load",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "delta_price",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "3f12bc76-9a2b-490f-a6e2-d950e438a9d8",
              "rows": [
                [
                  "2019-01-01 00:00:00",
                  "23.925",
                  "13.8375616073608",
                  "6116.41904",
                  "185.465296",
                  "3895.95194",
                  "0.0",
                  "0.0",
                  "14311.36445",
                  "12512.80815",
                  "2.534772",
                  "36951.0",
                  null
                ],
                [
                  "2019-01-01 01:00:00",
                  "23.314",
                  "15.4648694992065",
                  "6423.24236",
                  "186.667008",
                  "3894.973176",
                  "0.0",
                  "0.0",
                  "14298.52586",
                  "12434.13638",
                  "2.947464",
                  "37112.0",
                  null
                ],
                [
                  "2019-01-01 02:00:00",
                  "23.3475",
                  "15.4877195358276",
                  "6309.280752",
                  "187.408832",
                  "3894.733152",
                  "0.0",
                  "0.0",
                  "14030.82875",
                  "12797.25831",
                  "-1.954544",
                  "37154.0",
                  null
                ],
                [
                  "2019-01-01 03:00:00",
                  "23.0595",
                  "15.770092010498",
                  "6416.671292",
                  "187.817564",
                  "3894.714576",
                  "0.0",
                  "0.0",
                  "13610.13937",
                  "13279.01803",
                  "1.887324",
                  "37283.0",
                  null
                ],
                [
                  "2019-01-01 04:00:00",
                  "25.2672",
                  "16.0360851287842",
                  "6569.580884",
                  "186.990116",
                  "3892.748912",
                  "0.0",
                  "0.0",
                  "13414.14969",
                  "13585.26799",
                  "-0.2011",
                  "37817.0",
                  null
                ],
                [
                  "2019-01-01 05:00:00",
                  "28.8611",
                  "16.7470397949219",
                  "6806.102292",
                  "222.169372",
                  "3893.877024",
                  "0.0",
                  "0.0",
                  "12743.16529",
                  "14786.60827",
                  "2.955692",
                  "38763.0",
                  null
                ],
                [
                  "2019-01-01 06:00:00",
                  "39.4101",
                  "17.5206718444824",
                  "7356.916872",
                  "223.598596",
                  "3894.202416",
                  "0.0",
                  "0.0",
                  "11695.73501",
                  "16435.8807",
                  "4.032436",
                  "39849.0",
                  null
                ],
                [
                  "2019-01-01 07:00:00",
                  "39.1896",
                  "17.7318916320801",
                  "7627.659176",
                  "223.522816",
                  "3891.496004",
                  "0.0",
                  "0.0",
                  "10769.46719",
                  "17849.76048",
                  "2.988096",
                  "40410.0",
                  null
                ],
                [
                  "2019-01-01 08:00:00",
                  "36.3108",
                  "18.4140319824219",
                  "8034.6643",
                  "222.1581",
                  "3892.873952",
                  "0.0",
                  "15.504816",
                  "9749.372156",
                  "18761.96472",
                  "3.074772",
                  "40892.0",
                  null
                ],
                [
                  "2019-01-01 09:00:00",
                  "39.6983",
                  "19.588623046875",
                  "8861.727808",
                  "223.473352",
                  "3894.109608",
                  "0.0",
                  "73.208772",
                  "8688.958132",
                  "19735.37034",
                  "3.040152",
                  "41671.0",
                  null
                ],
                [
                  "2019-01-01 10:00:00",
                  "40.2148",
                  "20.7471313476563",
                  "9938.088416",
                  "223.699976",
                  "3890.997248",
                  "0.0",
                  "165.856592",
                  "7236.261324",
                  "20776.384",
                  "3.8969",
                  "42146.0",
                  null
                ],
                [
                  "2019-01-01 11:00:00",
                  "37.2478",
                  "21.3603363037109",
                  "10401.91125",
                  "200.562196",
                  "3892.734124",
                  "0.0",
                  "233.450596",
                  "6421.903592",
                  "21216.38172",
                  "3.608564",
                  "42206.0",
                  null
                ],
                [
                  "2019-01-01 12:00:00",
                  "34.5007",
                  "21.6746959686279",
                  "10843.79388",
                  "186.330668",
                  "3892.944372",
                  "0.0",
                  "311.36348",
                  "5665.944092",
                  "21339.63762",
                  "-0.050588",
                  "41807.0",
                  null
                ],
                [
                  "2019-01-01 13:00:00",
                  "34.7428",
                  "21.7823867797852",
                  "11049.00355",
                  "186.441272",
                  "3892.50776",
                  "0.0",
                  "259.819596",
                  "5217.935984",
                  "21018.28545",
                  "3.15518",
                  "41320.0",
                  null
                ],
                [
                  "2019-01-01 14:00:00",
                  "34.6144",
                  "21.9466972351074",
                  "11187.95622",
                  "186.049876",
                  "3891.574964",
                  "0.0",
                  "203.82868",
                  "4859.254484",
                  "20871.27624",
                  "1.594112",
                  "40949.0",
                  null
                ],
                [
                  "2019-01-01 15:00:00",
                  "34.4056",
                  "26.3067970275879",
                  "11535.01104",
                  "211.481304",
                  "3892.253344",
                  "0.0",
                  "110.826784",
                  "4233.964036",
                  "21118.54924",
                  "2.546792",
                  "40975.0",
                  null
                ],
                [
                  "2019-01-01 16:00:00",
                  "36.2957",
                  "26.8361930847168",
                  "11924.04599",
                  "249.026864",
                  "3892.451464",
                  "0.0",
                  "66.500996",
                  "3554.642004",
                  "21802.12896",
                  "3.056364",
                  "41783.0",
                  null
                ],
                [
                  "2019-01-01 17:00:00",
                  "64.5798",
                  "27.5510845184326",
                  "12276.57683",
                  "248.96194",
                  "3892.762276",
                  "0.0",
                  "15.013288",
                  "3354.061648",
                  "23212.87701",
                  "2.998796",
                  "43966.0",
                  null
                ],
                [
                  "2019-01-01 18:00:00",
                  "66.9318",
                  "33.4604682922363",
                  "12373.18407",
                  "221.384096",
                  "3892.680796",
                  "0.0",
                  "0.0",
                  "2992.843944",
                  "25837.25857",
                  "3.79044",
                  "45406.0",
                  null
                ],
                [
                  "2019-01-01 19:00:00",
                  "41.2162",
                  "34.9075584411621",
                  "12439.40505",
                  "221.815728",
                  "3892.293888",
                  "0.0",
                  "0.0",
                  "2857.59244",
                  "25935.07676",
                  "1.267524",
                  "45261.0",
                  null
                ],
                [
                  "2019-01-01 20:00:00",
                  "40.3369",
                  "34.0498199462891",
                  "12438.36693",
                  "195.830184",
                  "3892.080304",
                  "0.0",
                  "0.0",
                  "2759.597352",
                  "25786.21502",
                  "-1.325144",
                  "44875.0",
                  null
                ],
                [
                  "2019-01-01 21:00:00",
                  "35.5165",
                  "31.0697078704834",
                  "12465.79535",
                  "196.451852",
                  "3891.513288",
                  "0.0",
                  "0.0",
                  "2724.787952",
                  "24951.17857",
                  "-0.377196",
                  "43945.0",
                  null
                ],
                [
                  "2019-01-01 22:00:00",
                  "31.5755",
                  "31.1546306610107",
                  "12436.69127",
                  "158.890524",
                  "3890.599492",
                  "0.0",
                  "0.0",
                  "2434.006624",
                  "23910.70212",
                  "0.041472",
                  "42277.0",
                  null
                ],
                [
                  "2019-01-01 23:00:00",
                  "26.4935",
                  "26.8461532592773",
                  "11874.96931",
                  "159.464984",
                  "3891.757256",
                  "0.0",
                  "0.0",
                  "2510.4403",
                  "22597.71201",
                  "2.822164",
                  "40543.0",
                  null
                ],
                [
                  "2019-01-02 00:00:00",
                  "26.6577",
                  "26.1592845916748",
                  "11019.0404",
                  "211.80336",
                  "3891.427324",
                  "0.0",
                  "0.0",
                  "2556.493476",
                  "21857.30259",
                  "0.776324",
                  "39277.0",
                  "2.2342845916748004"
                ],
                [
                  "2019-01-02 01:00:00",
                  "24.3462",
                  "25.9841365814209",
                  "10388.7317",
                  "188.16956",
                  "3891.118712",
                  "0.0",
                  "0.0",
                  "2417.738312",
                  "21725.04409",
                  "1.218988",
                  "38589.0",
                  "2.6701365814208984"
                ],
                [
                  "2019-01-02 02:00:00",
                  "24.9133",
                  "25.3712673187256",
                  "10148.57656",
                  "187.471732",
                  "3890.877504",
                  "0.0",
                  "0.0",
                  "2693.351584",
                  "21409.53292",
                  "-2.470856",
                  "38431.0",
                  "2.0237673187256"
                ],
                [
                  "2019-01-02 03:00:00",
                  "24.4683",
                  "25.2762241363525",
                  "9846.024556",
                  "187.525788",
                  "3891.413216",
                  "0.0",
                  "0.0",
                  "3128.780528",
                  "21428.29015",
                  "-1.432144",
                  "38828.0",
                  "2.2167241363525"
                ],
                [
                  "2019-01-02 04:00:00",
                  "25.1232",
                  "24.5719661712646",
                  "9829.751588",
                  "188.180748",
                  "3892.101792",
                  "0.0",
                  "0.0",
                  "3289.184004",
                  "22151.42388",
                  "-3.166144",
                  "40043.0",
                  "-0.6952338287354003"
                ],
                [
                  "2019-01-02 05:00:00",
                  "30.1396",
                  "25.0743083953857",
                  "10341.36317",
                  "225.203888",
                  "3891.783612",
                  "0.0",
                  "0.0",
                  "3539.563424",
                  "23384.49495",
                  "-0.08526",
                  "42402.0",
                  "-3.786791604614301"
                ],
                [
                  "2019-01-02 06:00:00",
                  "55.3082",
                  "25.9785709381104",
                  "11733.04428",
                  "250.607476",
                  "3890.602976",
                  "0.0",
                  "0.0",
                  "2871.80052",
                  "25467.92225",
                  "0.570452",
                  "45219.0",
                  "-13.431529061889599"
                ],
                [
                  "2019-01-02 07:00:00",
                  "40.4756",
                  "29.2044925689697",
                  "12243.0151",
                  "247.146256",
                  "3889.973712",
                  "0.0",
                  "0.0",
                  "2553.030404",
                  "27772.4965",
                  "2.102536",
                  "47432.0",
                  "-9.985107431030297"
                ],
                [
                  "2019-01-02 08:00:00",
                  "36.2088",
                  "36.638427734375",
                  "12250.63438",
                  "248.447572",
                  "3890.307104",
                  "0.0",
                  "0.005384",
                  "2011.634756",
                  "29664.07621",
                  "2.383692",
                  "48598.0",
                  "0.3276277343749996"
                ],
                [
                  "2019-01-02 09:00:00",
                  "37.3772",
                  "40.1176872253418",
                  "12207.58335",
                  "263.57132",
                  "3895.736976",
                  "0.0",
                  "35.411584",
                  "2025.567152",
                  "30648.5328",
                  "-1.2047",
                  "49657.0",
                  "0.4193872253417936"
                ],
                [
                  "2019-01-02 10:00:00",
                  "33.4478",
                  "59.4540328979492",
                  "12269.39236",
                  "273.484616",
                  "3893.812596",
                  "0.0",
                  "107.043332",
                  "1867.155328",
                  "31570.85504",
                  "0.898424",
                  "50661.0",
                  "19.2392328979492"
                ],
                [
                  "2019-01-02 11:00:00",
                  "30.6697",
                  "62.8075675964355",
                  "12340.60632",
                  "230.893108",
                  "3894.783856",
                  "0.0",
                  "131.75698",
                  "1195.121152",
                  "33235.95221",
                  "1.521576",
                  "51295.0",
                  "25.5597675964355"
                ],
                [
                  "2019-01-02 12:00:00",
                  "27.9434",
                  "38.1134338378906",
                  "12180.95975",
                  "230.128864",
                  "3894.444364",
                  "0.0",
                  "147.411984",
                  "1308.978972",
                  "33378.0454",
                  "0.758804",
                  "51412.0",
                  "3.6127338378905947"
                ],
                [
                  "2019-01-02 13:00:00",
                  "27.0113",
                  "43.5680694580078",
                  "12255.0393",
                  "231.139796",
                  "3894.801384",
                  "0.0",
                  "212.907912",
                  "1337.093948",
                  "33392.38348",
                  "1.925832",
                  "51492.0",
                  "8.825269458007796"
                ],
                [
                  "2019-01-02 14:00:00",
                  "24.1565",
                  "36.8626899719238",
                  "12046.10978",
                  "230.807104",
                  "3893.390536",
                  "0.0",
                  "189.23948",
                  "1407.03348",
                  "33137.96618",
                  "2.24628",
                  "51264.0",
                  "2.2482899719237963"
                ],
                [
                  "2019-01-02 15:00:00",
                  "24.7873",
                  "32.3479118347168",
                  "11908.7674",
                  "267.818492",
                  "3894.09848",
                  "0.0",
                  "137.89176",
                  "2095.40284",
                  "32660.76262",
                  "1.693052",
                  "51152.0",
                  "-2.057688165283203"
                ],
                [
                  "2019-01-02 16:00:00",
                  "27.272",
                  "38.1546897888184",
                  "11771.16732",
                  "304.06906",
                  "3893.31228",
                  "0.0",
                  "71.420348",
                  "1784.647496",
                  "33119.553",
                  "1.7932",
                  "51384.0",
                  "1.8589897888184055"
                ],
                [
                  "2019-01-02 17:00:00",
                  "41.3426",
                  "37.7884407043457",
                  "11733.58142",
                  "276.826592",
                  "3892.46698",
                  "0.0",
                  "20.599708",
                  "1647.287948",
                  "33945.36833",
                  "1.68566",
                  "52665.0",
                  "-26.791359295654303"
                ],
                [
                  "2019-01-02 18:00:00",
                  "44.7316",
                  "52.0153732299805",
                  "11649.02181",
                  "247.01132",
                  "3893.367304",
                  "0.0",
                  "0.0",
                  "1341.622648",
                  "35414.46146",
                  "-2.14424",
                  "53313.0",
                  "-14.916426770019498"
                ],
                [
                  "2019-01-02 19:00:00",
                  "34.7473",
                  "49.0191993713379",
                  "11712.16229",
                  "246.696932",
                  "3894.021436",
                  "0.0",
                  "0.0",
                  "892.246312",
                  "35377.1919",
                  "2.401672",
                  "52396.0",
                  "7.802999371337897"
                ],
                [
                  "2019-01-02 20:00:00",
                  "33.7482",
                  "49.094799041748",
                  "11802.12156",
                  "275.703976",
                  "3895.365856",
                  "0.0",
                  "0.0",
                  "544.153644",
                  "34717.37072",
                  "2.39128",
                  "51125.0",
                  "8.757899041747997"
                ],
                [
                  "2019-01-02 21:00:00",
                  "30.1116",
                  "38.3151359558105",
                  "11684.58332",
                  "277.337932",
                  "3895.42118",
                  "0.0",
                  "0.0",
                  "847.33536",
                  "32946.87372",
                  "1.697152",
                  "49288.0",
                  "2.7986359558104965"
                ],
                [
                  "2019-01-02 22:00:00",
                  "27.0621",
                  "36.8169250488281",
                  "11558.77353",
                  "275.119676",
                  "3893.64908",
                  "0.0",
                  "0.0",
                  "985.165264",
                  "30704.09202",
                  "-1.911472",
                  "46749.0",
                  "5.241425048828095"
                ],
                [
                  "2019-01-02 23:00:00",
                  "23.5828",
                  "30.2865982055664",
                  "11808.90794",
                  "276.018164",
                  "3892.330012",
                  "0.0",
                  "0.0",
                  "644.977968",
                  "28252.50481",
                  "1.073252",
                  "44381.0",
                  "3.793098205566398"
                ],
                [
                  "2019-01-03 00:00:00",
                  "22.1953",
                  "28.0744132995605",
                  "11447.44826",
                  "326.796432",
                  "3893.92314",
                  "0.0",
                  "0.0",
                  "1051.607656",
                  "26255.36574",
                  "-0.792896",
                  "42547.0",
                  "1.4167132995605023"
                ],
                [
                  "2019-01-03 01:00:00",
                  "22.1915",
                  "25.5825328826904",
                  "10882.30282",
                  "301.526784",
                  "3893.651784",
                  "0.0",
                  "0.0",
                  "1576.489276",
                  "24983.27008",
                  "0.819768",
                  "41478.0",
                  "1.2363328826904016"
                ]
              ],
              "shape": {
                "columns": 12,
                "rows": 43848
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DAP_SystemLambda</th>\n",
              "      <th>SCED_system_lambda</th>\n",
              "      <th>Fuel_coal_and_lignite</th>\n",
              "      <th>Fuel_hydro</th>\n",
              "      <th>Fuel_nuclear</th>\n",
              "      <th>Fuel_power_storage</th>\n",
              "      <th>Fuel_solar</th>\n",
              "      <th>Fuel_wind</th>\n",
              "      <th>Fuel_natural_gas</th>\n",
              "      <th>Fuel_other</th>\n",
              "      <th>Load_load</th>\n",
              "      <th>delta_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>23.9250</td>\n",
              "      <td>13.837562</td>\n",
              "      <td>6116.419040</td>\n",
              "      <td>185.465296</td>\n",
              "      <td>3895.951940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14311.36445</td>\n",
              "      <td>12512.80815</td>\n",
              "      <td>2.534772</td>\n",
              "      <td>36951.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>23.3140</td>\n",
              "      <td>15.464869</td>\n",
              "      <td>6423.242360</td>\n",
              "      <td>186.667008</td>\n",
              "      <td>3894.973176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14298.52586</td>\n",
              "      <td>12434.13638</td>\n",
              "      <td>2.947464</td>\n",
              "      <td>37112.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>23.3475</td>\n",
              "      <td>15.487720</td>\n",
              "      <td>6309.280752</td>\n",
              "      <td>187.408832</td>\n",
              "      <td>3894.733152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14030.82875</td>\n",
              "      <td>12797.25831</td>\n",
              "      <td>-1.954544</td>\n",
              "      <td>37154.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>23.0595</td>\n",
              "      <td>15.770092</td>\n",
              "      <td>6416.671292</td>\n",
              "      <td>187.817564</td>\n",
              "      <td>3894.714576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13610.13937</td>\n",
              "      <td>13279.01803</td>\n",
              "      <td>1.887324</td>\n",
              "      <td>37283.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>25.2672</td>\n",
              "      <td>16.036085</td>\n",
              "      <td>6569.580884</td>\n",
              "      <td>186.990116</td>\n",
              "      <td>3892.748912</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13414.14969</td>\n",
              "      <td>13585.26799</td>\n",
              "      <td>-0.201100</td>\n",
              "      <td>37817.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 19:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 20:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 21:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 22:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-01-01 23:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43848 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     DAP_SystemLambda  SCED_system_lambda  \\\n",
              "2019-01-01 00:00:00           23.9250           13.837562   \n",
              "2019-01-01 01:00:00           23.3140           15.464869   \n",
              "2019-01-01 02:00:00           23.3475           15.487720   \n",
              "2019-01-01 03:00:00           23.0595           15.770092   \n",
              "2019-01-01 04:00:00           25.2672           16.036085   \n",
              "...                               ...                 ...   \n",
              "2024-01-01 19:00:00               NaN                 NaN   \n",
              "2024-01-01 20:00:00               NaN                 NaN   \n",
              "2024-01-01 21:00:00               NaN                 NaN   \n",
              "2024-01-01 22:00:00               NaN                 NaN   \n",
              "2024-01-01 23:00:00               NaN                 NaN   \n",
              "\n",
              "                     Fuel_coal_and_lignite  Fuel_hydro  Fuel_nuclear  \\\n",
              "2019-01-01 00:00:00            6116.419040  185.465296   3895.951940   \n",
              "2019-01-01 01:00:00            6423.242360  186.667008   3894.973176   \n",
              "2019-01-01 02:00:00            6309.280752  187.408832   3894.733152   \n",
              "2019-01-01 03:00:00            6416.671292  187.817564   3894.714576   \n",
              "2019-01-01 04:00:00            6569.580884  186.990116   3892.748912   \n",
              "...                                    ...         ...           ...   \n",
              "2024-01-01 19:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 20:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 21:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 22:00:00                    NaN         NaN           NaN   \n",
              "2024-01-01 23:00:00                    NaN         NaN           NaN   \n",
              "\n",
              "                     Fuel_power_storage  Fuel_solar    Fuel_wind  \\\n",
              "2019-01-01 00:00:00                 0.0         0.0  14311.36445   \n",
              "2019-01-01 01:00:00                 0.0         0.0  14298.52586   \n",
              "2019-01-01 02:00:00                 0.0         0.0  14030.82875   \n",
              "2019-01-01 03:00:00                 0.0         0.0  13610.13937   \n",
              "2019-01-01 04:00:00                 0.0         0.0  13414.14969   \n",
              "...                                 ...         ...          ...   \n",
              "2024-01-01 19:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 20:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 21:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 22:00:00                 NaN         NaN          NaN   \n",
              "2024-01-01 23:00:00                 NaN         NaN          NaN   \n",
              "\n",
              "                     Fuel_natural_gas  Fuel_other  Load_load  delta_price  \n",
              "2019-01-01 00:00:00       12512.80815    2.534772    36951.0          NaN  \n",
              "2019-01-01 01:00:00       12434.13638    2.947464    37112.0          NaN  \n",
              "2019-01-01 02:00:00       12797.25831   -1.954544    37154.0          NaN  \n",
              "2019-01-01 03:00:00       13279.01803    1.887324    37283.0          NaN  \n",
              "2019-01-01 04:00:00       13585.26799   -0.201100    37817.0          NaN  \n",
              "...                               ...         ...        ...          ...  \n",
              "2024-01-01 19:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 20:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 21:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 22:00:00               NaN         NaN        NaN          NaN  \n",
              "2024-01-01 23:00:00               NaN         NaN        NaN          NaN  \n",
              "\n",
              "[43848 rows x 12 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processor.df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "e5902795",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.split_data(feature_columns=['DAP_SystemLambda', 'SCED_system_lambda'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "857623c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.standardize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "89475b19",
      "metadata": {},
      "outputs": [],
      "source": [
        "processor.shift_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "9aff786e",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_mlp, x_val_mlp, x_test_mlp, y_train_mlp, y_val_mlp, y_test_mlp = processor.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "08bcb91b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26089, 336)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_mlp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "2fe58215",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26089, 24)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_mlp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "404fc096",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "336"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_train_mlp[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaeebb4",
      "metadata": {},
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "c0fde9ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLPModel(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=336, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Linear(in_features=256, out_features=24, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from MLP import MLPModel\n",
        "\n",
        "new_model = MLPModel(\n",
        "    input_shape=len(x_train_mlp[1]),    # 5 features\n",
        "    output_shape=len(y_train_mlp[1]),   # 1 price per time step\n",
        "    hidden_layers=[256, 256, 256,256]  # or [256, 256]\n",
        ")\n",
        "\n",
        "mlp_model = new_model.get_model()\n",
        "mlp_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c595cd21",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "prD6Bpb9fMdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prD6Bpb9fMdc",
        "outputId": "2b5275e4-590f-4b76-d355-5ae9fd1d9e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 0.8973, Eval Loss = 0.2441\n",
            "Epoch 2: Train Loss = 0.7201, Eval Loss = 0.2412\n",
            "Epoch 3: Train Loss = 0.6010, Eval Loss = 0.2398\n",
            "Epoch 4: Train Loss = 0.5786, Eval Loss = 0.2430\n",
            "Epoch 5: Train Loss = 0.6067, Eval Loss = 0.2397\n",
            "Epoch 6: Train Loss = 0.5832, Eval Loss = 0.2421\n",
            "Epoch 7: Train Loss = 0.5108, Eval Loss = 0.2431\n",
            "Epoch 8: Train Loss = 0.5079, Eval Loss = 0.2437\n",
            "Epoch 9: Train Loss = 0.4854, Eval Loss = 0.2450\n",
            "Epoch 10: Train Loss = 0.4539, Eval Loss = 0.2430\n",
            "Epoch 11: Train Loss = 0.4449, Eval Loss = 0.2415\n",
            "Epoch 12: Train Loss = 0.4416, Eval Loss = 0.2408\n",
            "Epoch 13: Train Loss = 0.4458, Eval Loss = 0.2452\n",
            "Epoch 14: Train Loss = 0.4099, Eval Loss = 0.2440\n",
            "Epoch 15: Train Loss = 0.4188, Eval Loss = 0.2376\n",
            "Epoch 16: Train Loss = 0.4091, Eval Loss = 0.2403\n",
            "Epoch 17: Train Loss = 0.4026, Eval Loss = 0.2427\n",
            "Epoch 18: Train Loss = 0.3905, Eval Loss = 0.2435\n",
            "Epoch 19: Train Loss = 0.3819, Eval Loss = 0.2445\n",
            "Epoch 20: Train Loss = 0.3632, Eval Loss = 0.2409\n",
            "Epoch 21: Train Loss = 0.3604, Eval Loss = 0.2454\n",
            "Epoch 22: Train Loss = 0.3759, Eval Loss = 0.2432\n",
            "Epoch 23: Train Loss = 0.3386, Eval Loss = 0.2429\n",
            "Epoch 24: Train Loss = 0.3333, Eval Loss = 0.2436\n",
            "Epoch 25: Train Loss = 0.3190, Eval Loss = 0.2428\n",
            "Epoch 26: Train Loss = 0.3193, Eval Loss = 0.2447\n",
            "Epoch 27: Train Loss = 0.3118, Eval Loss = 0.2454\n",
            "Epoch 28: Train Loss = 0.3097, Eval Loss = 0.2463\n",
            "Epoch 29: Train Loss = 0.2874, Eval Loss = 0.2456\n",
            "Epoch 30: Train Loss = 0.3015, Eval Loss = 0.2463\n",
            "Epoch 31: Train Loss = 0.3027, Eval Loss = 0.2437\n",
            "Epoch 32: Train Loss = 0.2678, Eval Loss = 0.2451\n",
            "Epoch 33: Train Loss = 0.2776, Eval Loss = 0.2466\n",
            "Epoch 34: Train Loss = 0.2443, Eval Loss = 0.2522\n",
            "Epoch 35: Train Loss = 0.2556, Eval Loss = 0.2464\n",
            "Epoch 36: Train Loss = 0.2518, Eval Loss = 0.2555\n",
            "Epoch 37: Train Loss = 0.2427, Eval Loss = 0.2583\n",
            "Epoch 38: Train Loss = 0.2588, Eval Loss = 0.2517\n",
            "Epoch 39: Train Loss = 0.2301, Eval Loss = 0.2572\n",
            "Epoch 40: Train Loss = 0.2336, Eval Loss = 0.2705\n",
            "Epoch 41: Train Loss = 0.2284, Eval Loss = 0.2615\n",
            "Epoch 42: Train Loss = 0.2288, Eval Loss = 0.2624\n",
            "Epoch 43: Train Loss = 0.2347, Eval Loss = 0.2684\n",
            "Epoch 44: Train Loss = 0.2260, Eval Loss = 0.2692\n",
            "Epoch 45: Train Loss = 0.2099, Eval Loss = 0.2676\n",
            "Epoch 46: Train Loss = 0.2092, Eval Loss = 0.2602\n",
            "Epoch 47: Train Loss = 0.2358, Eval Loss = 0.2583\n",
            "Epoch 48: Train Loss = 0.2126, Eval Loss = 0.2611\n",
            "Epoch 49: Train Loss = 0.2061, Eval Loss = 0.2622\n",
            "Epoch 50: Train Loss = 0.2069, Eval Loss = 0.2685\n",
            "Epoch 51: Train Loss = 0.1937, Eval Loss = 0.2601\n",
            "Epoch 52: Train Loss = 0.2096, Eval Loss = 0.2784\n",
            "Epoch 53: Train Loss = 0.2100, Eval Loss = 0.2813\n",
            "Epoch 54: Train Loss = 0.1974, Eval Loss = 0.2685\n",
            "Epoch 55: Train Loss = 0.2018, Eval Loss = 0.2670\n",
            "Epoch 56: Train Loss = 0.2043, Eval Loss = 0.2742\n",
            "Epoch 57: Train Loss = 0.1900, Eval Loss = 0.2763\n",
            "Epoch 58: Train Loss = 0.1903, Eval Loss = 0.2678\n",
            "Epoch 59: Train Loss = 0.2029, Eval Loss = 0.2719\n",
            "Epoch 60: Train Loss = 0.1916, Eval Loss = 0.2815\n",
            "Epoch 61: Train Loss = 0.1909, Eval Loss = 0.2606\n",
            "Epoch 62: Train Loss = 0.1869, Eval Loss = 0.2697\n",
            "Epoch 63: Train Loss = 0.1976, Eval Loss = 0.2866\n",
            "Epoch 64: Train Loss = 0.1874, Eval Loss = 0.2816\n",
            "Epoch 65: Train Loss = 0.1831, Eval Loss = 0.2740\n",
            "Early stopping triggered at epoch 65\n"
          ]
        }
      ],
      "source": [
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss  # or define it above in your notebook\n",
        "\n",
        "trainer = ModelTrainer(\n",
        "    model=mlp_model,\n",
        "    features_training_data=x_train_mlp,\n",
        "    target_training_data=y_train_mlp,\n",
        "    features_eval_data=x_val_mlp,\n",
        "    target_eval_data=y_val_mlp,\n",
        "    device=device,\n",
        "    loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=0.133)\n",
        ")\n",
        "\n",
        "\n",
        "trainer.train(epochs=100, batch_size=32, patience=50, learning_rate= 0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "f5f33e55",
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_2 = trainer.history\n",
        "with open('MLP_Worst.csv', 'w') as f:\n",
        "    pd.DataFrame(loss_2).to_csv(f, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "78d4fd71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE: 37.7043, SMSE: 0.9812\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# predict\n",
        "\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = mlp_model(torch.tensor(x_test_mlp, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_mlp  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "\n",
        "# 1. Flatten both (remove batch and window dimensions if needed)\n",
        "y_pred_flat = y_pred.reshape(-1)\n",
        "y_test_flat = y_test_mlp.reshape(-1)\n",
        "\n",
        "# 2. Denormalize both using your processor's function\n",
        "y_pred_real = processor.denormalization(y_pred_flat)\n",
        "y_test_real = processor.denormalization(y_test_flat)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
        "mse = np.mean((y_test_real - y_pred_real) ** 2)\n",
        "variance = np.var(y_test_real)\n",
        "smse = mse / variance\n",
        "\n",
        "print(f\"MAE: {mae:.4f}, SMSE: {smse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ecf126",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAv4dJREFUeJzs3Xd401X7x/F3ultoy6Zllj1EQECWIggIKKKg/hzIA+IGcfHogziYIqA4QUFxICLilqWVjSJoQYYiG0EQWlahBUp3fn8ckjRt0qZ78HldVy7y3SdpaXJ/zzn3bbFarVZEREREREREpMB5FXcDRERERERERMoqBd0iIiIiIiIihURBt4iIiIiIiEghUdAtIiIiIiIiUkgUdIuIiIiIiIgUEgXdIiIiIiIiIoVEQbeIiIiIiIhIIVHQLSIiIiIiIlJIFHSLiIiIiIiIFBIF3SIiIuLSPffcQ0RERJ6OHTduHBaLpWAbJCIiUgop6BYREXFjzpw5WCwWLBYL69aty7LdarVSu3ZtLBYLN954o9M2i8XCiBEjsj1/t27d7Oe3WCxUqlSJK6+8kg8//JD09HS3x2U8JrvHmjVr8vS6S7t77rmH8uXLF3czREREAPAp7gaIiIiUdAEBAcyfP5+rr77aaf3atWv5999/8ff3z/O5a9WqxeTJkwE4ceIEc+fO5b777mPPnj1MmTLF5TGffPKJ0/LcuXNZvnx5lvXNmjXLc7sAZs+enW3wn53nn3+eZ555Jl/XFxERKQsUdIuIiOTghhtu4Msvv+Stt97Cx8fx0Tl//nzatm3LyZMn83zu0NBQBg0aZF9+6KGHaNKkCTNmzGDixIn4+vpmOSbj/gC//vory5cvz7I+s4SEBIKCgjxum6tre8rHx8fpvRIREblUaXi5iIhIDu666y5OnTrF8uXL7euSk5P56quvGDhwYIFeKygoiI4dO3L+/HlOnDiR5/N069aNFi1a8Pvvv3PNNdcQFBTEs88+C8DChQvp27cvNWrUwN/fnwYNGjBx4kTS0tKczpF5TvfBgwexWCxMmzaN9957jwYNGuDv78+VV17Jxo0bnY51NafbNuT+u+++o0WLFvj7+3PZZZcRGRmZpf1r1qyhXbt2BAQE0KBBA959990Cnyf+5Zdf0rZtWwIDA6lSpQqDBg3iyJEjTvvExMQwdOhQatWqhb+/P+Hh4dx8880cPHjQvs+mTZvo3bs3VapUITAwkHr16nHvvfcWWDtFRKR00y1oERGRHERERNCpUyc+++wzrr/+egB++OEH4uLiuPPOO3nrrbcK9Hp///033t7eVKhQIV/nOXXqFNdffz133nkngwYNonr16oCZq16+fHlGjhxJ+fLlWbVqFWPGjCE+Pp5XXnklx/POnz+fs2fP8tBDD2GxWHj55Ze55ZZb+Pvvv3PsHV+3bh3ffPMNw4cPJzg4mLfeeotbb72VQ4cOUblyZQC2bNlCnz59CA8PZ/z48aSlpTFhwgSqVq2ar/cjozlz5jB06FCuvPJKJk+ezLFjx3jzzTf55Zdf2LJli/29v/XWW/nrr7949NFHiYiI4Pjx4yxfvpxDhw7Zl3v16kXVqlV55plnqFChAgcPHuSbb74psLaKiEjppqBbRETEAwMHDmT06NFcuHCBwMBAPv30U7p27UqNGjXydd60tDT78PSTJ08yc+ZMNm/eTL9+/XI1FNyVmJgYZs2axUMPPeS0fv78+QQGBtqXH374YR5++GHeeecdXnzxxRznqB86dIi9e/dSsWJFAJo0acLNN9/Mjz/+mCWhXGY7d+5kx44dNGjQAIBrr72WVq1a8dlnn9kTz40dOxZvb29++eUX+/t7++2353uOuk1KSgqjRo2iRYsW/PTTTwQEBABw9dVXc+ONN/L6668zfvx4zpw5w/r163nllVd46qmn7MePHj3a/nz9+vWcPn2aZcuW0a5dO/v6F198sUDaKiIipZ+Gl4uIiHjg9ttv58KFCyxZsoSzZ8+yZMmSAhlavmvXLqpWrUrVqlVp1qwZ06dPp2/fvnz44Yf5Pre/vz9Dhw7Nsj5jwH327FlOnjxJly5dSEhIYNeuXTme94477rAH3ABdunQBTA99Tnr27GkPuAFatmxJSEiI/di0tDRWrFhB//79nW5oNGzY0D7KIL82bdrE8ePHGT58uD3gBujbty9NmzZl6dKlgHmf/Pz8WLNmDadPn3Z5LluP+JIlS0hJSSmQ9omISNmioFtERMQDVatWpWfPnsyfP59vvvmGtLQ0brvttnyfNyIiguXLl7NixQrWrVtHTEwMS5YsoUqVKvk+d82aNfHz88uy/q+//mLAgAGEhoYSEhJC1apV7UnY4uLicjxvnTp1nJZtAbi7wDS7Y23H2449fvw4Fy5coGHDhln2c7UuL/755x/A9NBn1rRpU/t2f39/pk6dyg8//ED16tW55pprePnll4mJibHv37VrV2699VbGjx9PlSpVuPnmm/noo49ISkoqkLaKiEjpp6BbRETEQwMHDuSHH35g1qxZXH/99fmecw1Qrlw5evbsSY8ePbjqqquoVq1a/ht6UcYebZszZ87QtWtXtm3bxoQJE1i8eDHLly9n6tSpAB6VCPP29na53mq1FuqxxeGJJ55gz549TJ48mYCAAF544QWaNWvGli1bAJMc7quvvmLDhg2MGDGCI0eOcO+999K2bVvOnTtXzK0XEZGSQEG3iIiIhwYMGICXlxe//vprgWctLypr1qzh1KlTzJkzh8cff5wbb7yRnj17Og0XL07VqlUjICCAffv2Zdnmal1e1K1bF4Ddu3dn2bZ79277dpsGDRrw3//+l2XLlrF9+3aSk5N59dVXnfbp2LEjkyZNYtOmTXz66af89ddfLFiwoEDaKyIipZuCbhEREQ+VL1+emTNnMm7cOPr161fczckTW09zxp7l5ORk3nnnneJqkhNvb2969uzJd999x9GjR+3r9+3bxw8//FAg12jXrh3VqlVj1qxZTsPAf/jhB3bu3Enfvn0BU9c8MTHR6dgGDRoQHBxsP+706dNZeulbt24NoCHmIiICKHu5iIhIrgwZMsTjfTdt2uQyi3W3bt24+uqrC7JZHuvcuTMVK1ZkyJAhPPbYY1gsFj755JMSNbx73LhxLFu2jKuuuophw4aRlpbGjBkzaNGiBVu3bvXoHCkpKS7f+0qVKjF8+HCmTp3K0KFD6dq1K3fddZe9ZFhERARPPvkkAHv27KFHjx7cfvvtNG/eHB8fH7799luOHTvGnXfeCcDHH3/MO++8w4ABA2jQoAFnz55l9uzZhISEcMMNNxTYeyIiIqWXgm4REZFC8ttvv/Hbb79lWT9x4sRiC7orV67MkiVL+O9//8vzzz9PxYoVGTRoED169KB3797F0qbM2rZtyw8//MBTTz3FCy+8QO3atZkwYQI7d+70KLs6mN77F154Icv6Bg0aMHz4cO655x6CgoKYMmUKo0aNoly5cgwYMICpU6fa5+rXrl2bu+66i5UrV/LJJ5/g4+ND06ZN+eKLL7j11lsBk0gtKiqKBQsWcOzYMUJDQ2nfvj2ffvop9erVK7D3RERESi+LtSTd2hYRERFxo3///vz111/s3bu3uJsiIiLiMc3pFhERkRLnwoULTst79+7l+++/p1u3bsXTIBERkTxST7eIiIiUOOHh4dxzzz3Ur1+ff/75h5kzZ5KUlMSWLVto1KhRcTdPRETEY5rTLSIiIiVOnz59+Oyzz4iJicHf359OnTrx0ksvKeAWEZFSRz3dIiIiIiIiIoVEc7pFREREREREComCbhEREREREZFCojndeZSens7Ro0cJDg7GYrEUd3NERERERESkCFmtVs6ePUuNGjXw8nLfn62gO4+OHj1K7dq1i7sZIiIiIiIiUowOHz5MrVq13G5X0J1HwcHBgHmDQ0JCirk1IiIiIiIiUpTi4+OpXbu2PTZ0R0F3HtmGlIeEhCjoFhERERERuUTlNN1YidREREREREREComCbhEREREREZFCoqBbREREREREpJBoTnchS0tLIyUlpbibIXLJ8/X1xdvbu7ibISIiIiKXGAXdhcRqtRITE8OZM2eKuykiclGFChUICwvLMdmFiIiIiEhBUdBdSGwBd7Vq1QgKCtKXfJFiZLVaSUhI4Pjx4wCEh4cXc4tERERE5FKhoLsQpKWl2QPuypUrF3dzRAQIDAwE4Pjx41SrVk1DzUVERESkSCiRWiGwzeEOCgoq5paISEa2/5PKsyAiIiIiRUVBdyHSkHKRkkX/J0VERESkqCnoFhERERERESkkCrolX9asWYPFYskxS3tERARvvPFGkbRJSh9Pf49EREREREobBd0lWFq6lQ37T7Fw6xE27D9FWrq10K41a9YsgoODSU1Nta87d+4cvr6+dOvWzWlfW4C0f/9+OnfuTHR0NKGhoQDMmTOHChUqFFo7c+JpcB8REYHFYsFisVCuXDnatGnDl19+WfgNLCSFGbTOmTPH/l65exw8eDBf18j8eyQiIiLikTOH4ehW948zh4uxcSKGspeXUJHboxm/eAfRcYn2deGhAYzt15w+LQq+3NG1117LuXPn2LRpEx07dgTg559/JiwsjN9++43ExEQCAgIAWL16NXXq1KFBgwYAhIWFFXh7isKECRN44IEHiI+P59VXX+WOO+6gZs2adO7cOdfnSk5Oxs/PrxBaWbSsVitpaWn4+Dj+NNxxxx306dPHvnzLLbfQokULJkyYYF9XtWrVfF3Xz8+v1P4eiYiISDE5cxjebg8pCe738Q2CR6KgQu2ia5dIJurpLoEit0czbN5mp4AbICYukWHzNhO5PbrAr9mkSRPCw8NZs2aNfd2aNWu4+eabqVevHr/++qvT+muvvdb+3NbDumbNGoYOHUpcXJy9B3TcuHH24xISErj33nsJDg6mTp06vPfee05t+PPPP+nevTuBgYFUrlyZBx98kHPnztm3d+vWjSeeeMLpmP79+3PPPffYt//zzz88+eST9utnJzg4mLCwMBo3bszbb79NYGAgixcvJi0tjfvuu4969eoRGBhIkyZNePPNN52Oveeee+jfvz+TJk2iRo0aNGnSBIBPPvmEdu3a2c89cOBAe23ojO/Xjz/+yBVXXEFgYCDdu3fn+PHj/PDDDzRr1oyQkBAGDhxIQoLjAyQ9PZ3Jkyfb29SqVSu++uorAA4ePGj/eVSsWBGLxWJ/T7I7LmN7fvjhB9q2bYu/vz/r1q1zeq2BgYGEhYXZH35+fgQFBdmXO3bsyPTp052Oad26tdPP3mKx8P777zNgwACCgoJo1KgRixYtytIOW0+9bcTEjz/+SLNmzShfvjx9+vQhOtrxu5+amspjjz1GhQoVqFy5MqNGjWLIkCH0798/25+7iIiIlBEJp0zAfctseHBt1scts832hFPF3VK5xCnoLmHS0q2MX7wDVwPJbevGL95RKEPNr732WlavXm1fXr16Nd26daNr16729RcuXOC3336zB3kZde7cmTfeeIOQkBCio6OJjo7mqaeesm9/9dVXadeuHVu2bGH48OEMGzaM3bt3A3D+/Hl69+5NxYoV2bhxI19++SUrVqxgxIgRHrf/m2++oVatWkyYMMF+fU/5+Pjg6+tLcnIy6enp1KpViy+//JIdO3YwZswYnn32Wb744gunY1auXMnu3btZvnw5S5YsAUwpqokTJ7Jt2za+++47Dh48aA+AMxo3bhwzZsxg/fr1HD58mNtvv5033niD+fPns3TpUpYtW+YUyE6ePJm5c+cya9Ys/vrrL5588kkGDRrE2rVrqV27Nl9//TUAu3fvJjo62n6TILvjMnrmmWeYMmUKO3fupGXLlh6/b7kxfvx4br/9dv744w9uuOEG7r77bmJjY93un5CQwLRp0/jkk0/46aefOHTokNPv09SpU/n000/56KOP+OWXX4iPj+e7774rlLaLiIhICValMdRoDcf+gj8+h4oRZrlK42JumIih4eVFpN/0dZw4m5TjfkmpaZxOcF9D2ApExyXS7sXl+Pt453i+qsH+LH70ao/aeO211/LEE0+QmprKhQsX2LJlC127diUlJYVZs2YBsGHDBpKSklwG3X5+foSGhmKxWFwOFb7hhhsYPnw4AKNGjeL1119n9erVNGnShPnz55OYmMjcuXMpV64cADNmzKBfv35MnTqV6tWr59j+SpUq4e3tbe9l9lRycjKvvvoqcXFxdO/eHV9fX8aPH2/fXq9ePTZs2MAXX3zB7bffbl9frlw53n//fadh5ffee6/9ef369Xnrrbe48sorOXfuHOXLl7dve/HFF7nqqqsAuO+++xg9ejT79++nfv36ANx2222sXr2aUaNGkZSUxEsvvcSKFSvo1KmT/dzr1q3j3XffpWvXrlSqVAmAatWq2efUe3KczYQJE7juuus8fs/y4p577uGuu+4C4KWXXuKtt94iKirKaeh6RrbfO9s0hhEjRjgNaZ8+fTqjR49mwIABgPl9+f777wv1NYiIiEgJFfs3LDTfM7Fa4fopxdsekQwUdBeRE2eTiIlPzHlHD5nA3H1wnhfdunXj/PnzbNy4kdOnT9O4cWOqVq1K165dGTp0KImJiaxZs4b69etTp06dXJ8/Yw+qLTC3Db3euXMnrVq1sgfcAFdddRXp6ens3r3bo6A7t0aNGsXzzz9PYmIi5cuXZ8qUKfTt2xeAt99+mw8//JBDhw5x4cIFkpOTad26tdPxl19+eZZ53L///jvjxo1j27ZtnD59mvT0dAAOHTpE8+bN7ftlfC+qV69OUFCQPeC2rYuKigJg3759JCQkZAmKk5OTueKKK9y+vtwc165dO7fnKSgZX3O5cuUICQlxGnqfWVBQkD3gBggPD7fvHxcXx7Fjx2jfvr19u7e3N23btrW/5yIiInIJifnT8XznIugzufjaIpKJgu4iUjXY36P9curptqkY5OtxT7enGjZsSK1atVi9ejWnT5+294TWqFGD2rVrs379elavXk337t09PmdGvr6+TssWiyVXAZKXlxdWq/Ow+pSUvN94ePrpp7nnnnsoX7481atXt88BX7BgAU899RSvvvoqnTp1Ijg4mFdeeYXffvvN6fiMNwjAMUS+d+/efPrpp1StWpVDhw7Ru3dvkpOTnfbN+F5YLJZs3xvbvPalS5dSs2ZNp/38/d3/fHNzXObXkhue/lxy+/N3tX/m64iIiIgAcGq/43n8EYj5o/jaIpKJgu4i4ukQ77R0K1dPXUVMXKLLed0WICw0gHWjuuPtlX2isLy49tprWbNmDadPn+bpp5+2r7/mmmv44YcfiIqKYtiwYW6P9/PzIy0tLdfXbdasGXPmzOH8+fP2APCXX37By8vLnqSsatWqTvO009LS2L59u9NQ99xcv0qVKjRs2DDL+l9++YXOnTvbh8ID7N+/P8t+me3atYtTp04xZcoUatc2GTI3bdrkUVuy07x5c/z9/Tl06JDTkPCMbD3uGV+7J8cVhMw/l/j4eA4cOFBo1wMIDQ2levXqbNy4kWuuuQYwr33z5s1ZRiSIiIjIJSA203e13ZHQuHfxtEUkEyVSK2G8vSyM7WeGIWcOqW3LY/s1L5SAG0zQvW7dOrZu3eoUqHXt2pV3332X5ORkl/O5bSIiIjh37hwrV67k5MmTThm4s3P33XcTEBDAkCFD2L59O6tXr+bRRx/lP//5j31oeffu3Vm6dClLly5l165dDBs2LEtd6oiICH766SeOHDnCyZMnc/8GAI0aNWLTpk38+OOP7NmzhxdeeIGNGzfmeFydOnXw8/Nj+vTp/P333yxatIiJEyfmqQ0ZBQcH89RTT/Hkk0/y8ccfs3//fjZv3sz06dP5+OOPAahbty4Wi4UlS5Zw4sQJzp0759FxBaF79+588skn/Pzzz/z5558MGTIEb++cR2Hk16OPPsrkyZNZuHAhu3fv5vHHH+f06dM5Zq0XERGRMubkHoje5rxu+1dmvUgJoKC7BOrTIpyZg9oQFhrgtD4sNICZg9oUSp1um2uvvZYLFy7QsGFDp3nUXbt25ezZs/bSYu507tyZhx9+mDvuuIOqVavy8ssve3TdoKAgfvzxR2JjY7nyyiu57bbb6NGjBzNmzLDvc++99zJkyBAGDx5M165dqV+/fpYbABMmTODgwYM0aNAgz7WjH3roIW655RbuuOMOOnTowKlTp5x6vd2pWrUqc+bM4csvv6R58+ZMmTKFadOm5akNmU2cOJEXXniByZMn06xZM/r06cPSpUupV68eADVr1mT8+PE888wzVK9e3Z71PafjCsLo0aPp2rUrN954I3379qV///5Oc7ELy6hRo7jrrrsYPHgwnTp1onz58vTu3dteT15ERETKuKDKpg73Nw84z+kGE3B/84DZHlS5eNpX2pw5DEe3un+cOVyMjSvdLFZNksyT+Ph4QkNDiYuLIyQkxGlbYmIiBw4coF69evkKANLSrUQdiOX42USqBQfQvl6lQuvhFint0tPTadasGbfffrvbEQYF9X9TRERESogzh+HMIZhzQ9ZtV4+EdvdChdpF367S5sxheLu9qWvujm8QPBKl9zOD7GLCjDSnuwTz9rLQqYHuzIm48s8//7Bs2TK6du1KUlISM2bM4MCBAwwcOLC4myYiIiJFpUJtSMgwpTCspSOJ2rHtRRMgnjkMCafcbw+qXPID1YRTJuC+Zbapb56aBD4ZEu/aRg4knCr5r6UEUtAtIqWSl5cXc+bM4amnnsJqtdKiRQtWrFhBs2bNirtpIiIiUpQyZi5vcQucPwFno+HvtZB0DvzLF961y1oPcZXGULUJzO4ODbpDjzHOwbfkiYJuESmVateuzS+//FLczRAREZHiljHortwQmlwPmz6EtCT4ezU061d4187cQ5xZaewhXvY8HN9hHudPwi3vFneLSj0F3SIiIiIiUnrFZgq6fQJM0A2mdFhhBt02VRpDjdZ5P76kDFE/+AtsfN889wmELiML/5qXAAXdIiIiIiJSep3ad/GJBSrWMw/fcpByHvZEQnoaeBV+OVOsVvjxOdi3HNoMgfYPenZcSRqi/tNUx/M+L5mh5pJvCrpFRERERKR0slodQXdobfC9WJ2kwbWwa4lJsvbvJqjTofDbcuwv+PVt83zZc/D7R3Dl/Wb53DFTdsuVk3uKf4i6raBVYpz5t0lfaDu0cK51CVLQLSIiIiIipVNCrCNQrFzfsb7JDSboBtj9fdEE3TsWOi+f2geRz5jnnw+CtOTsjw8Izd8Q9fz48wvH86Aq0OEhiN7mWHdyT9G3qQxR0C0iIiIiIqVTxvnclRo4njfuDVgAqxlift34Qm6IFXZ8d/G5BWq1g383OjanJZts4FePBP9g50N3LoGfX4Gtn8HvH8OxPyG8FdzyvqPnvjBFb4Pf3nMsJ5yEuTdl3c83yMwtl1xT0C0iIiIiIqWTfT43JomaTbkqULsDHP4VTuwyGc4rN8h6fEH5e42jNzjscrjhFdi/GtZPhwuxZv3+VWaIeddRJpj+dxMc+d1kCQfY8a3jfGcOmaHqXf5beG0GSD4PX90H1lSz3PJO6DjM9b6lod54CaWgW3LFarXy0EMP8dVXX3H69Gm2bNlC69ati7tZUoQOHjxIvXr19LMXERGR4udULixTUN2kjwm6wfR2d3qk4K8fVNn0AK8Y51gX8we8182xbPFxBLUXYiFylGfn/ulVaH13QbXUdYb0n6fBqb3mebVmcNN08PEruGsKAF7F3QBx4cxhcxfM3ePM4UK9/IYNG/D29qZv375ZtkVGRjJnzhyWLFlCdHQ0LVq0wGKx8N133xVae7p164bFYsFisRAQEEDz5s155513Cu16he3gwYNYLBa2bt1a4Odes2aN/b1y91izZk2+rlG7dm37z15ERESkWGUuF5ZRkxscz3f/UDjXr1D7YlbxCMe6gV/Bg2sdj7vmm/UNe2Y93uINobXM8zb3wCMbod29ZjnlPKycWDDttGVIf6+r82PnYsc+sQdMwjcpcOrpLmlKQMmADz74gEcffZQPPviAo0ePUqNGDfu2/fv3Ex4eTufOnQv8uikpKfj6+rrc9sADDzBhwgQSEhKYO3cujzzyCBUrVuSuu+7K9XWSk5Px8ysbd/Ayv2edO3cmOjravvz4448THx/PRx99ZF9XqVKlfF3T29ubsLCwfJ1DREREpEDYhpdbvKFCHedtVRpDpfoQ+zf8sx4unIbAigXfhpQEOHPQPK/dARpf57zdlrW8+wtmaPmupaaHvFY7CG9tEr5984AJvlMSoHl/2PYFpJyDrfOgYt38tzHhlHOG9PMn4KuhkHTWbG8zGDbPLdwM6Zcw9XSXNBn/Q2S8Q2Z73DLbbM88NKSAnDt3js8//5xhw4bRt29f5syZY992zz338Oijj3Lo0CEsFgsRERFEREQAMGDAAPs6m4ULF9KmTRsCAgKoX78+48ePJzU11b7dYrEwc+ZMbrrpJsqVK8ekSZPctisoKIiwsDDq16/PuHHjaNSoEYsWLQJg1KhRNG7cmKCgIOrXr88LL7xASkqK/dhx48bRunVr3n//ferVq0dAgElIERkZydVXX02FChWoXLkyN954I/v3O+6W2nqkv/jiC7p06UJgYCBXXnkle/bsYePGjbRr147y5ctz/fXXc+LECaf2vv/++zRr1oyAgACaNm3q1DNfr149AK644gosFgvdunXz6Dhbez7//HO6du1KQEAAn376qdN1/fz8CAsLsz8CAwPx9/e3L995553873//czqmf//+3HPPPfbliIgIXnrpJe69916Cg4OpU6cO773nSK6Ruafe1ru+cuVK2rVrR1BQEJ07d2b37t1O13nxxRepVq0awcHB3H///TzzzDMani4iIiJ5Z7XCqb/N84oR4J2p88ZicfR2W9Ng74rCaceORY7nzW/Oft/a7U1St6seg7qdwS/IZC0HWP2i6X2ee5MJuG1WTyq4JGZVGps557+86Qi4m93k6F2XQqGgu6Sq0tiUDMj8cFW7rwB98cUXNG3alCZNmjBo0CA+/PBDrBfr9r355ptMmDCBWrVqER0dzcaNG9m40WRl/Oijj+zrAH7++WcGDx7M448/zo4dO3j33XeZM2dOlsB63LhxDBgwgD///JN77/X8P3tgYCDJyabsQnBwMHPmzGHHjh28+eabzJ49m9dff91p/3379vH111/zzTff2IPF8+fPM3LkSDZt2sTKlSvx8vJiwIABpKenOx07duxYnn/+eTZv3oyPjw8DBw7kf//7H2+++SY///wz+/btY8yYMfb9P/30U8aMGcOkSZPYuXMnL730Ei+88AIff/wxAFFRUQCsWLGC6OhovvnmG4+Os3nmmWd4/PHH2blzJ7179/b4PcuNV199lXbt2rFlyxaGDx/OsGHDsgTRmT333HO8+uqrbNq0CR8fH6ef56effsqkSZOYOnUqv//+O3Xq1GHmzJmF0nYRERG5RJyNMUOwwX2StCbXO57v/r5w2mHPWo4JYN05ucf11FFbybOMnW73rXAMOwfoNbHgeqDXvgwHfzbPQ2pCvzcxmd6lsGh4eVF5tyucO57zfrb6ffNuBW8XQ6Bz2p5Z+Wrw0FqPm/nBBx8waNAgAPr06UNcXBxr166lW7duhIaGEhwc7HJ4cYUKFZzWjR8/nmeeeYYhQ4YAUL9+fSZOnMj//vc/xo4da99v4MCBDB061OP2paWl8dlnn/HHH3/w4IMPAvD888/bt0dERPDUU0+xYMECpx7d5ORk5s6dS9WqVe3rbr31Vqdzf/jhh1StWpUdO3Y4zVd+6qmn7MHt448/zl133cXKlSu56qqrALjvvvucRgSMHTuWV199lVtuuQUwPdu2Gw9Dhgyxt6Fy5cpO71lOx9k88cQT9n0Kyw033MDw4cMBM5Lg9ddfZ/Xq1TRp0sTtMZMmTaJr166AuTHQt29fEhMTCQgIYPr06dx33332n/WYMWNYtmwZ586dc3s+ERERkWy5KxeWUe2OEFABEs/AvpWQmlywicJO7oNj283zmu1cB8a2ZGvfPOD+PL5BUKeT8/E3vAqf3WGer3sTWg/KfwmxHQth3WsXFyxwy3sQVMlkS5dCo6C7qJw7DmePer5/wsn8bc+D3bt3ExUVxbffmnIFPj4+3HHHHXzwwQdOQ6A9sW3bNn755Rennu20tDQSExNJSEggKCgIgHbt2nl0vnfeeYf333+f5ORkvL29efLJJxk2zJQz+Pzzz3nrrbfYv38/586dIzU1lZCQEKfj69at6xRwA+zdu5cxY8bw22+/cfLkSXsP96FDh5yC7pYtW9qfV69eHYDLL7/cad3x4+aGyvnz59m/fz/33XcfDzzg+MOamppKaGio29eXm+M8fc/yI+NrtlgshIWF2V+jJ8eEh4cDcPz4cerUqcPu3bvtQbxN+/btWbVqVQG2WkRERC4pTuXC3ATd3j7QqBf8+QUkxcGh9VC/W8G1YedCx3N3Q8ttydaymx7qqhxX495Q/1r4ezXEFVAJMXvADVw3ASKuzt/5xCMKuotK+Wqe7ZeWbALqoCrue7qz257X62J6uVNTU50Sp1mtVvz9/ZkxY0a2QWNm586dY/z48S57ZG1zqgHKlSvn0fnuvvtunnvuOQIDAwkPD8fLy8yM2LBhA3fffTfjx4+nd+/ehIaGsmDBAl599VWn411dp1+/ftStW5fZs2dTo0YN0tPTadGihX3Yuk3GRGUWi8XlOlvAbuu5nT17Nh06dHA6j7e3t9vXl5vjPH3PXPHy8rJPF7DJOP/dJnNCu4yv0R1X71NOx4iIiIjkWXblwmzOHDalsGw2zzU93zb5rT29I2PQnc3Q8gq1c38diwV6vwSzrgJruqOEWHAeEtoejnJevuoJM69cikSxB91vv/02r7zyCjExMbRq1Yrp06fTvn17l/vOnj2buXPnsn27GcLRtm1bXnrpJaf9z507xzPPPMN3333HqVOnqFevHo899hgPP/yw07k2bNjAc889x2+//Ya3tzetW7fmxx9/JDAwsHBeqKdDvI9uNQkUBn1t5nDndnsepaamMnfuXF599VV69erltK1///589tlnWd5DG19fX9LS0pzWtWnTht27d9OwYUOXx+RWaGioy3OtX7+eunXr8txzz9nX/fPPPzme79SpU+zevZvZs2fTpUsXANatW5fvdlavXp0aNWrw999/c/fdrusq2jKnZ3zPPDmuIFStWtUpu3laWhrbt2/n2muvLbRrAjRp0oSNGzcyePBg+zrb/H8RERG5hLmqHZ1RdkFx7N+O55nLhdnOnbkq0PavzcMmP1WBYg9A9DbzvMYVJplbQave3CQ52/i+o4RY/7dzd45Dv8HyFxzLTfvCZf0dWdXBzDeXQlOsQffnn3/OyJEjmTVrFh06dOCNN96gd+/e7N69m2rVsvbQrlmzhrvuuovOnTsTEBDA1KlT6dWrF3/99Rc1a9YEYOTIkaxatYp58+YRERHBsmXLGD58ODVq1OCmm8zdpw0bNtCnTx9Gjx7N9OnT8fHxYdu2bfbe0xLB3S9+If2HWLJkCadPn+a+++7L0qN966238sEHH7gNuiMiIuxznP39/alYsSJjxozhxhtvpE6dOtx22214eXmxbds2tm/fzosvvlhg7W7UqBGHDh1iwYIFXHnllSxdutQ+PD47FStWpHLlyrz33nuEh4dz6NAhnnnmmQJp0/jx43nssccIDQ2lT58+JCUlsWnTJk6fPs3IkSOpVq0agYGBREZGUqtWLQICAggNDc3xuILQvXt3Ro4cydKlS2nQoAGvvfYaZ86cKZBzZ+fRRx/lgQceoF27dnTu3JnPP/+cP/74g/r16xf6tUVERKSEym+pXNvwcm9/CKmVdXvGqkC/zYIjv5v1t82BSvXM9+pvHsh7mawdHgwtLwjdnoVtn0PyWVNCrP41UCVTnh13c9Vj/4ZFj0JqomPdrqXmkVlBZUiXLIo16H7ttdd44IEH7MmVZs2axdKlS/nwww9dBkCZyyO9//77fP3116xcudLeg7Z+/XqGDBlin4P84IMP8u677xIVFWUPup988kkee+wxp2tklyCqSHmaaKGA/0N88MEH9OzZ0+UQ8ltvvZWXX36ZP/74w+Wxr776KiNHjmT27NnUrFmTgwcP0rt3b5YsWcKECROYOnUqvr6+NG3alPvvv79A233TTTfx5JNPMmLECJKSkujbty8vvPAC48aNy/Y4Ly8vFixYwGOPPUaLFi1o0qQJb731Vq7nrrty//33ExQUxCuvvMLTTz9NuXLluPzyy3niiScAM1f+rbfeYsKECYwZM4YuXbqwZs2aHI8rCPfeey/btm1j8ODB+Pj48OSTTxZ6LzeY6QF///03Tz31FImJidx+++3cc8899kzuIiIicgnKXDs6s+yC4vQ009MMJoDOrvOsSmNoeYcj6D6xE1oMcGw/d8y51zczd73tRRV0pyRAWoag+ZsH83ae8NZww7SspdVs8jvUXtyyWDNP8CwiycnJBAUF8dVXX9G/f3/7+iFDhnDmzBkWLlzo/uCLzp49S7Vq1fjyyy+58cYbARNkb9myhe+++44aNWqwZs0abrrpJpYuXco111zD8ePHqV69Om+99RafffYZ+/fvp2nTpkyaNImrr3afSCApKYmkpCT7cnx8PLVr1yYuLi5L0q7ExEQOHDjgVBM6V/IzzEaklLjuuusICwvjk08+KbJr5vv/poiIiBQc27TJB9eaaZPpaeDl7X57Rqf/gTcvJnFteiPc6dw5l+X4wIqO/cH0FNfuAFvmgk+Ac09wZq562zNeP6wlPPyzxy8712yvo3x1c4MAoOc4k2QNYO9yU+P72ueh0XVmXUIsLHzEOZHz0B9MbXApMPHx8YSGhrqMCTMqtp7ukydPkpaWZs8GbVO9enV27drl0TlGjRpFjRo16Nmzp33d9OnTefDBB6lVqxY+Pj54eXkxe/ZsrrnmGgD+/tvM/Rg3bhzTpk2jdevWzJ07lx49erB9+3YaNWrk8lqTJ09m/PjxeXmpuZeXRAsiJVhCQgKzZs2id+/eeHt789lnn7FixQqWL19e3E0TERGRkmDLPFg4Ai4bALd9aJKIZcepXJgH09Uq1oU6nU32coCTu80DTMDdqI/p/a7aBKea1e5623cucjwvzF7ujK56An4cbZ5v/AD8g80NgfMXK8ykXjA3Lrx9zBxuW8BdoS6c+cfsK8Wi2BOp5dWUKVNYsGABa9asceqxmj59Or/++iuLFi2ibt26/PTTTzzyyCP24NyWTfmhhx6yD2u/4oorWLlyJR9++CGTJ092eb3Ro0c7zau19XSLSM4sFgvff/89kyZNIjExkSZNmvD111873TATERGRS1RqIvz4HGCFv76BrqOgWtPsj3HKXO5h4t6Bn8PWT2HHIji0wVzPZm+keYTWgfYPQKcR2Q9Zdxpa3t+z6+dX3U4ZSogdhqWZyof9/Kp5ZBRa29T7nn9b0bRRXCq2oLtKlSp4e3tz7Ngxp/XHjh0jLCz7NPjTpk1jypQprFixwqk28IULF3j22Wf59ttv6du3L2BqB2/dupVp06bRs2dPe/3g5s2bO52zWbNmHDrkvii8v78//v7+uXqNImIEBgayYsWK4m6GiIiIlER7l0HimQzLP+Yy6HZTLiyzgBDoOMw8zsbArzPhlzec94k7ZHqJ/90IA2a5Pk/cv2Y7QPUWUKVgqvXkzAJ9JsN715pe7ZwEVYH/fAfJ5wq9ZZK9Ygu6/fz8aNu2LStXrrTP6U5PT2flypWMGDHC7XEvv/wykyZN4scff6Rdu3ZO21JSUkhJScmShdzb29vewx0REUGNGjXYvXu30z579uzh+uuvL4BXJiVCajKkp7rf7uXjOsOjiIiIiBStP792Xt7zI1z1ePbHOA0vzyHodlf9p/pljuddnoKjm+HvNaYm9s5FZkj2tS9kPW5HMQwtt6nWDIZvgKNbzAiB5PNw6FfY/pUZIl+xjkm8ZvGCjo+YGwLZJYmTIlGsw8tHjhzJkCFDaNeuHe3bt+eNN97g/Pnz9mHfgwcPpmbNmvYh31OnTmXMmDHMnz+fiIgIYmJiAChfvjzly5cnJCSErl278vTTTxMYGEjdunVZu3Ytc+fO5bXXXgPMMNenn36asWPH0qpVK1q3bs3HH3/Mrl27+Oqrr4rnjZCClZpsslJa093vY/GCqs0UeIuIiEjuKemtUVDvw5mDzsv/bIADP8PZaPfH2MqF+ZaDYDejZD2pCmRLotasH/R4AfYsg6/uNeW5orfBtw9lPaaospa7U6meedgEhJqg+/JboeXtRd8eyVGxBt133HEHJ06cYMyYMcTExNC6dWsiIyPtydUOHTrk1Gs9c+ZMkpOTue025zkJY8eOtZeIWrBgAaNHj+buu+8mNjaWunXrMmnSJKca00888QSJiYk8+eSTxMbG0qpVK5YvX06DBh4OTfGQrXddilh6qgm4K9Q1f0gzS000dy7TUwEF3ZcS/Z8UEZF8y29t6bKiIN6HoMpg8QZrWqYN6fDxjY5zZC6Vm5ZisocDVK7vPulahdrm+tndGDh3DOZnCFQb94L7l8P8O8z3xQsXj91yMTv6+RNw+NeL54+AlAvmvSiKn7W7Hnvbe3H6H9e92u6OkyJTbCXDSrvs0sOnp6ezd+9evL29qVq1Kn5+flhyysAoBSf5Apw5ABXqgV+g+cNstTp6tTNvlzLParWSnJzMiRMnSEtLo1GjRlmmoYiIiHjEVr4pp9rSrspclTT56akuiPfh1H6Y3sY8L1cNrnkafnjaLDe8Dro/77oNJ/fBjLbm+WUD4P/muH8NOXH3OhLPwLLnIebPnM9R2DdZPLnBkZNL4UZQMSjxJcPKMi8vL+rVq0d0dDRHjx7N+QDJytZb7Y7Fy8zLdiUtGc6egHhvc47zJ03QXa4K+AY6b/dWT/elJCgoiDp16ijgFhGR/KvSGKo2NYm4AivBlfdnn+06twp7CHtB9dhXaWyC6hN7IOks1GrreRuiZjuedxoObe+BlRPM0O4jv0PY5c51u21yM587J54MQc/IyxfSU8zz/5tjOndclRQrSJ702KcmZz9t8lKZ8lBCKeguJH5+ftSpU4fU1FTS0jIPmZFsxUebYT7ZZWX0CYSBX0BIeNZtx3dC5H+h10uw+iVIuZix0S8E7poPFxLN9ts/gWr1sh4vZZK3tzc+Pj4adSIiIgUnchT8Psc8P30Qek8qmPMWxRD2hFPm/Dn1VHsSTG760JSvsqZD31fNDYicJMab2txgvte1GWKCxobdzZzpC7Hw7yao0yHrsXkpF+ZOTgHtyd3wzYOOZVvAXaWxKRUWvS1/1/dUhdoKmksxBd2FyGKx4Ovri6+vb3E3pXSJjYMze3L+EEiNgwAXQbOPBc4dhsgnIeGk87bFD0OvSWa7jwUCXMz5LihKsiIiIlJ2HfndEXAD/Po2lK9q6ijnV0EGxDmp0hhSk2D399C4j6kFnRsbZzuCZ4DIZ6G2i0A5s63zTY82mORfQZXM80a9HYnK9kS6Cbr3OZ57Wi4sO54EtL1egtWTIOW8WW5+s/u55CKZKOiWkqtKYwhvBacPmKRoroYXuZIYb/61Bdw128K54xB3GA5tcP6ALCxKsiIiIlK2rX0567oV4+AaD+one6pKY5NkLHI0VKpv5jx7GmTmdPP/3DHz7w/PwOEN5vkvb0D7B6HnuJzPn3axxzdjwA2QlmSyf9/0lvtj09Mh6l3HcgdHwmMaXQdYAKup391zbNbjC3J4uaciroL7lsHCR0yPfnsXWc1F3FDQLSWYFb4aCn99az50bpoOdTpmf0hKIix7zrEcUgt6jIEz/8KiR4F02DK3UFsNFO0dahERESl650zpWupeDQ2uhVUTzfJPLoLxvEo6a4Y2nz0Kh3+DP7+ENoOh6cXM3u6yUp87Bl8MyX6qHhfnn9sCbpuo90ywe/VI99dIPgdL/pthhcUMrd+2AGL+MMf8kk3QvXcZxP5tntfrCtWbO7aVrwY125iRBMe2u84MbhteHlDB0UNeFMJawENri+56UmYo6JaSa+9yE3CD+eP9YW9odx+0uMWxLiNrurnDHPOHY138vzDXVf1Ei0nGVthsyUUS48wHZ2itgj2/hrCLiEhZU9I/26IzfM/w9oeOwyC0JpzYZYJirI798pu9fMPbJuC2SU8186c3X+xdzin5V58pUCfDcPHzJ2Hzx7BriXPC2pCa0OwmMxow9YKZn774Mc+uYfExvdF1r4LQOvDN/aY86+7v3R/z20zH847Dsm5v3McE3WAC9Cvvc2xLuQBx/5rnlRtoiLeUCgq6peRa7+IO6aYPYPs35nmOHzSToU5nx7LVCt//9+Ifcau5Iz3wi8L/Yx39B3zS33yBaNgTuj3rGCqfXd3EnL5UaAi7iIiUNSX9sy3lAvz0imM5LQk+v9v1vj+MAr9yroeDe3rjYM8P5l+/YGh/P0S9b+ZBpyeb9d7+JuN3i1vBx99x3N7lsPpF0wtcoY7p+d62AH57N2vvd8fh0GMs+AZA+wfgu+GOOtQAgRXhuokmk3jsAVPS6/wJx3ZrKix/wf1rSMl0veM74e815nnFemYOd2aNepn50wB7fnQOumMPYL+xkd8karnh7jubamCLBxR0S8mVdDG5xmUDTEKOlRNN8orE02Z91abQe7L5QNn2Gfw26+KBF+cB1emc9Q7znZ/BrKvMh8XeZWYo+uW3Z712UGXzb37vtJ85DEuecJxn3wrzqHGxJmV2Nw5y+lKhIewiIlLWlPTPttWTIO6QeV7tMrh5hvPIubQUWDrSjLpLTYCv73V9npw+423fgWz6vGSGlXcaAT+/aoJna5oJ+qPehZ2LzUjAC2fg/HE4sdMc983DgIsSrD6BjuC7xhWml95+rcmw/Sv49V0TUF84baboXXE37FgMSXFmv/JhZoh9lp+VFVa9aL7vgKl1fW8keF9MLGz/voaZP+6qzFp4KwgOh7PRcGAtJCeAX5DZVtTzuT0pKeYb5PjuKOKCgm4peQ7/5njuV96UkAisCLd9AD+/Bv9GmW0ndsFX95igeWOGOo9dR8HaKa7PHVwdek2Eby8m7Njwtnlk5hMAWLKfC+XJnfbv/+tI6OblY4aFARzdbP6t3Bi6/g+qNHI+LjdfKqo0hkr1YN0b5hpXP+n4YBIRESmNbAnEot6HKwaZJFbF7d9Nju8M3v6mRnNVFzcGbngZPuzjWA6pCTe/bb7LgGef8RnnQ9dqb3qZj241yy3vMIH+hhmOfc4edV62yxRwe/uZcl6Ne5vpdz4BHtantjonTKtxhekd/6S/YypdRrd9BO9eY5LhHtlkhqq3f8gku936mdnHJxDqd3N9OYvFJFTbPNcMVT/4s2kzZCoXVgRBtyc1sot7yoOUeAq6pWRJOgfrXncsJ58zf9DdSYxzDri7Pw8Nr3MfdANUbea8HFwDbn3fDAEDx4ch5P1Oe+IZ868tM2j1FvCf72DXYvhpGsQfMetP7TFzn5rdBN1GOycS8VTcv6YttuFN//wCdy3I/XlERERKioRT8PV9ppd1x0J4+OeiCbBsMs8rT0uBr+93zIPuOMx1wA0mmAQzrPvMIfOZv2IsDF4EgRVyvvaupbBvmWP53yh4r5vrfa+fBn+vcj9/OqQWVG1ikpNVqGtuYFSo7Qjgb58L5au7Ptb2XafDMDOPPC3JrG/UG/7vIzi51/1rCAgxvfOf3WWWt843j4xSL8D7Pdx3YDTuY4JuMEPM7UF3AZcL84RqZEs+KeiWkmXVi2YoEZgh2De+hhkunoHtQ6BhL+cPpXb3QpenIHqbZ9eq2swMvzp7FH7/CPq+CgmxzolFYrab7JopCVDvGmjQI+c54Inx8P1TjuWQmtDrRfOhW6MN/N/HJvDeG+nYZ+ciMzTsikFw3QTP2m/z7UPm5oTNP7+Yu9c9x+fuPCIiIiXFT6+YgBvM1LJvH4KhkdkfY5NTIrbUZPDxy377JzdnP6886j3TY5xdIHbDNFjypPn8j94Gs7qYm/wZ515nlhALi59wLHcbbYLPzGzfhWpfCR0egBN7zHXKV4Ny1WD/SvOe9RxramC7U756zsneWt0J7Yaa3vfK9aHz4+DtQQgRXMN5ObCSyWljmw/e60Uz9NxdB0a9rqZnPi3ZBN1Wq/kOZst6DkVXLkwknxR0S8nx7ybHPB+fQDOcvFJ99/t3fw46PmyGeoVdbkqD5SYpWo8x5gMpKd5kG/3zy6z7rH/T8fyXN80Qr2ufddypzpw8IzUJvn/a+e5v/BH3vfVt7jFJUs4dwwzd+gR2/wAdcqj9aLU6MrvbAu4qjc0H2YXTZvi6LeuoiIhIaXMoUxmrfzfCutdMgq3seJKILSc+AWZIs22028k98M1DQLrJ1N39OVg5PucpYOWrw6Bv4KPr4UKsmQv+0fXQ7h73x3z/tJmTDSbY7jrKs+82VRs797zb5pmf/sfRq51RbpN/VW0C/V1Mx/NErSvNz+9CrGNdo94Q0SX74/zLm332rzTVaI79ZUp22Xq6y1UzPeoipYCCbikZUpNh0WPYs1FeOzr7gNumYQ/zyIuQGtDvDfjKTZITV/6NMgG0bYh6TvOgbngNarXNut52h7rdUJOwZNMHsPZlcwMg4aQjY6erD8r0VHMDYOcix7rGfcyXg7h/TfvOHTPzqMAxxD2vSnrpFhERKTvOHXdevuZpkzjMmg5rpuT8eZNTIjZbVu9rnzdzhjPLOMWsSmOofhksHIF9bnTXp6FBdxN0e6JaU3joJ3POQxvMPPWNH5hth35z3vfATyaBGYB/CNz4Rs4Bt7vg2fa5vfpF83DF0+Rf+c3afe1zptb4+Qw/244Pe3Zs494m6AbY+yNUrOv4XlOU0w1E8klBtxQ9V0Hclrlw/C/zvGpT6PhIzucpiNINLW6F+KNmvphfeZPkxJoOO74z2699zmTQTIwzSdxs2UBt/1aMgGv+B9Wamw81W6ZOb38z96lW25yHbfkFQedHocVtEPmM49oASx7P+TXUu8bcCbcNt+r7msmcavtQ+vZhuGm66xrhKksmIiIFKT83aq1W+Ollx3Kj3tD0Rjh7zHxPsKbB8rGetaNKY3Pz/qeXzQ1s3yDTc2r7bIzeaoaY+5U3WbUTTpka1icyfIf49P/MzfDURLNcvQVcPRKO7/CsDTYVasOQJWbI/E8vO6axRf7P/TGpiY7kq654klHbJyD7Ods5fQcoqKzdgRVhwCyYd4tZrtoU6l/r2XTARr3gh4vv054fTelVGw0tl1JEQbcULU+CuNMHzbxudx8EBV26ofOj5mFzdKsj8G3UyxE0t7jVDOleM9kxtOn0QVg4HCo3glMXh5R7+8P1U8w8rpxkvkFw9ZNQpyOsfQUuZPjSUqEOXPEfk8jENucdLyDd3Bmffa37a1yIdV9DtKDKkh3a4P5LlnrCRUTKjuyC6nPH4Ishea/88ftHZhiyzd4fzSPzNbx8cv6MPxsN3w1zHyDvWmIe2cnYM2vxNuXBspsLnlnmz/gm15s8L8ueM8G8TfP+Zi73wZ/Mcnhrc1Mgu+HrRZFRuyCv0bCH+S6xYyF0e8bz6YCV6kGVJnByt/ndOBzl2KaebilFFHRL0cocxFmtZu5xzB9me6Nepn52UXzQeNJTnnmfyg1hwHvwy+sm8ZmNLeC2eJsSIiGZkoe4al9ONw4s3uauPpjsp7Yh52DmMfUcZwJ+dwHx4Y3wQ4aEbv7BJqlL1aaO15absmQ1WpufFzg+LG09BvmpNy4iIqWDp/Ol+0yBOp2yrs/uc+f0Qfjxecfy9a9A7fbO1/76PjOKLD0Vju/M/nPl24cdlUTyKqAihIRDuaqmRnaNKzw7zpPP+IwyjnALrGhKcc0bkPNxRZFRuyCv0fL27JO6udO4lwm6rekmgZ2Ngm4pRRR0S+4VxBxfWxC36SNHwF0xArr81wTdOcnPh4CnQ7Kw5PyBeeWDJhFa3GGz3P8daHqD67nYGXly4+DcMZh/uyPLuk1YS7jrMzMMDlzXx8yoSlM4uQuSzsLSp+A/35psp7m150f4+gHzZadSfZPBNDXZbLtiMFw2AIIq4pRtPjeBvYiIlGyezpcOqpzz1KqM0tPhu0dMlnKANkOgw4PO+9RoDedfgqX/NcsLH4HhG6BcFef99lzMcG4LuCs1gDs/NYFz8jn48xtYNd5k4K7V1pQqTUsymbXLVTV5Vb4YbI4d/F3uXodNTp/xts/GLiNhwzuO4etgbo4HVcr9NUuy/E4HbNwH1k/Pekzlhvlrl0gRUtBd1hR20quCmuObmmwSh/00zbHuxjcuBruFzNOecsj5A/OKu6H3JNi3HILDoKaLpGnZtSO798gWuPd/B478bhKv1OkAvV8yNcVtQXdObnzN9JL/8wskn4XP7oD7V3reTjDZ2Bc/5vi5H/vTPGy2zDUPv/KmJ+Cap6F+19xdQ0RESocqjSE9zVQcOX/cVO5ITTRzrwG+/x9EjjbrQ2uZXuLWAx3HZw62/vwK/llnnofUMJ+rrrS7z9wA3rvMXPfLe6DXRMBiRmJFvQfbMtSCrtcVbv/Y9B6DCdArXMxvEtYCmt+c9RoZb5rnJ1j0pHOg2c1w+e2m/vex7eZ9anGr56VPS7qCmg4YUhN8y0PKOef1SWfNz0vT2KQUUNBdlhRF0qv8zvG1fVB9dY8ppWXT+m5ocG3OPcQFxdOeck/28fGDpn3z3yZ3LF7Q/gHzyAu/cnD3V6bX/ODP5ucy/3aTcM1TP452/F4FVTFlyWxD3zNKPmeucfBnkwDH9iUruy8opeXDUlncRaS0K6i/Y+veuDgk2up6e+Jpx/MTO81nyKoXoW5Hsy67ICzhFFw4Y6ZEZWaxQLdnHSPiDv4M73VzfZ5aHUxp0NP/mIeN7XlOpbR8Agoud0x2qjWDh9eZOeg5TU0rbQpiOuCZwzCzs+vvth/2Nv9qGpuUAgq6yxJPA+KCGOpbpbHp1dzxnflgbNDDzK3xZI4vOAJuizd0HAbdX8hfe4pLQWRQLwp+QXDHPPjgOtO2k3tguQfveWqS+ff8CfNvzXZwzxKTxObMIfh9Dqx/y2Qh9fKG47tMLU1wToBT2ud8K4u7iJR2nvwdyzbbtdUkwQLY8a2L7RaTBTwtGQIqQGAF8xkfu99sTjkP+y6OsgqtA1feB3WvgsWPO6qX1O8Of6/K/ntK5gRcPoEQHA6n/3Ze/+9v8H42JUVzKqX1n4XZJ00ryButFkvZC7ht8jsn3Pbdtt29JpmsTY0rzAhJTWOTUkJBd1lUpTGEXW7mO7W71zkRSUHZ+D788bn5cLWpUAcq1DXPuzwFzfqZ52kp8McXZvhxxnlLdTpD31ehevOCb19hK+gM6tkpqMA+sAIM/ALe72nmrB3dcnGDm54KqxXWTnEsl6tmSqid2O1Y5x9i/m090CRHSU+HP7+AlROcRzJ4+ULbwWYYXcYpBKXlw7Iob2iJiBSGnP6OHdpgylbO9zDRlW8QXPusGRLtG2Ruxv75pflbeMMrjoRZJ3ZD1GzY9pkZDQUQdwhWjDWfIbYs3pXqQ7f/maDbE02uh90/mEzptoDbPxS6Pw8/PO3+dYKZ4lZUAXV2SsuN+5KgeX+TB8j2nSW8dd7m24sUEwXdZdWGGeYD7o/PTRmqrs94dly2Q8+ssPNieY0tn7g49pB5APz8qplDHHE1/PWdI7u3TbObocuTJmj3ZP5USVMUpToKKrDP/J5eN8H0LKSnmOWt811nZF37MuzP8OXn/HH32VQDQs2/Xl7Q6k4zT+7Xd2DNy5CWaK618QPY9QP0eAFa3mn2LW2qNDaJ7KLeMz0TVz5QOl+HiFy6bH/HNkyHmD8htLYpy2TLE3Ltc6aSCJjEmX98Dr9/bJKN2dTpDLe8a262u5J56PYVg0yyzXVvwr4MJcDsZbMs0H9m7vK6dH7MZDA/fdAsV6xnbizbevJzSjJanIryxn1ZERAKta6Efy+WDFMSNSllFHSXRVarySAKprzCz6+a+U9X/zf74zwtBWLj5QudHjFZNvetNHfJ7T3fVrN8aINjf4sXNOwFeyNh50LzcKW0fNAUdqmO/Ab2npYsiXrPJCmp382xbv8qWPOSY7nXSxBxVdZjbT28iXFZ58Y16AGJZ015NSyAFc4eNXVTo/8wtcxLow0zHEPzk8+b7LMikneXSr6EEvM6raZO9K/vuN68dips/9oEsacPOlfPsGl7j6krnRDrvN72+rIbug1w7fNwdLPpqcYK1zwFdTrmLq+LbxD838fw3XAzva3fm+b7SFHlhsmPorhxXxY17esIusMuL962iOSSgu6yyGKB/3wHv7wBayabO9Uxf8I395vtGYcHZ3RyT9ahZ6lJpid066eOnlEwWboHvAtVGpnlqx43AcjqyebueflqcO64Y/9aV5qh5FarCbqzG/alDxqH/AT2OX2ob5lrep/BDPNzx8sXmt/kuh2eBvZ9XzMZ3nd/b5Z/mwktbgHvbIb3FaSC+rKbEGtGANisfdlkmhWHEhNYSKlwqeRLKEmvc8s8M0XMnfRUOLHLPGwsXnDZLbD9K9Mb/e2D7o/Pbl647UZto+ug69MQd8SMovK0/nVmNVrD8PV5O7a4FUWN7bKmw8Mmd1BABah3TXG3RiRXFHSXVd4+5s5xo+vgm4fMner0VLMtuw9LcGQMPbQBfp0JZ/7Juk/7h0yQnfmOsm2Yca9JULsD/LMeylc1yVG8vBz7l+RhX2VJdh/q4a3gzBFzEwTMh1ivF2H5WLhwMWiq0xkOrXc/V9nTWqQ128CV98Ivbzl6iZc8aXomCltBftmNes+UXbNJvQDfPw3Xjva8LYVd0q84A96SFFhI6XCp5EsoSa8zY8Dde7K5eR57wCS+3LcCyoeZChW24eThraHfG4DFBN1uE61dlJu/M6E1zUPEE74B0GdycbdCJE8UdJdFmefw9nsLNs42Ca5sfILgqkdNIpLUFBOUb/8aDqyFL+4x83Az8vKBFrfBHwtyvssNJviuWNc8pGSyWMyNGVvQnXgGFo1wbK/T2cz//qBn9ufJzd36jsNNop2YP0xN0u1fe3ZcfoLJgvyyu+cH869/qMkIfzbafFGNuNqz11CYAWlJCHiLKrAo7psLUvAulRuxVRqbuajLnoPkBLh+qhkSXRT2Z0pQ1nM8dBruWA6sYILuXhPN5/3Zo5CSaBKcZbxpXr56/n9WBZFATEnILi36eUspp6C7LPF0qC9AasLFeVvfmJ7sjFnIMwfcEV1MJtLUJBN0Z3eXO7s5vrbtUnJ4+5p/Q2o5Sn2ByUJ/xzyIO1ww18n4c+84HL572Dy3DW/PTkEFk7Yv9dHb4OA6M1QyJNyj5mPNlOG9zWAoV8UxLP/nV3M+R2EHpCWpJ832Xm/51Nzw6zjckck4v0rCzQUpHOdOmHrOZ2PghmlQrWlxt6jgpSbDgrvgwE9mOeEk3O3hzcf82LcSVk1yLLe6y+TxyPg5nbGWtZcXhNYq+HYURAIxJSG7tOjnLWWEgu6yxNOhvo2vd/TYZc4qDqaER4PuULezeVRvYXpFPbnLrT+OpdP1U00v94XT5uc/8AsoVzn/QXdOvw9pSaaOa3a/DwUVTF44DQtHmPmMWGHD23DfMs9exz+Z5gxumO68nHjGjAbx5Pe6SmMznPOf9WYKRkCIZ23wVMYeQ6s1a03bohJ7wJEl/5sHzfz9ihGeHZtdT7ar3BOZt5eF4chFpaSMGji5Fxbc7bj59+n/wQMelo4qKgXxXq0Y45xgdP8qc9Ou0XWF18ZjO2Dpk2BNdazb9pl5uJJwqvBumhdEAjElIbu06OctZYSC7rLm4lDftHQrUQdiOX42kWrBAbSvVwlv2z7dnjHlO5Y8AedPQKUGULeTCX42fwx9p0HLO/J+ff1xLH1Ca8HQSFMKruXtBdfD5O73IeksfDEYLsSCNc0k+svpd8JW5mZPpAlw611j5nfZuPtCePxi5t0FgyDlnGN9/BH45BbTo5adpLOwPsPc8xtehVrtLp7jKHw5xIwUSU8zryen1xH3L3x1L8TuN1nj//MtVG2S/TE2OQWjYHI3bPvc3Bg4vsvcULnyPs/OX5BWTsiQfNHqqN2bE0+rKASEmrwEp/aZn1GNK4rvBkNpVZJGDSwaAakZRlnFHYLP7zb5QUqC/L5X1nTzry3g9g0yr9eabipFFMSNaI/+73jBnfNdj/I5dwy+GGJqdbtTEDfNCyKBmJKQXVr085YyQEF3GRS5PZrxi3cQHef4AhMeGsCrV1vpbFvR7EZo2NN8ONvmk/3xhQm6Tx/K311u/XEsnao1hd6F8AXX3e/DDa/A1xeDwe+fNkG0f3n350k+BwsGOkZp+AVD0xugQoRZzmlahS3g9gs2AVv8v3ByN0SOyv64n6aZL6MATW+E9vc7ttVobW5irZwAWE1yuPuWg5e3qzMZ3w1z1KaNPwIf9oG7v8r+GPA8GP30dkciPDBfoHOT5bUgevOO74S/vnFel5YMkc/lfP3sRjakXDA3hrZ+CisnwrcPmREMANc8Dd2fz/n8BcWT9wlK9g3I4p6Db7XCzxdvetkC7prtzM2ss0fh8G/wkwc3aopCft6r9HT4KUPVA58AGPg5HPrNlNWypl/8G1LAbTwbbUb3JFysv121ialeEhLufrTaiI0l+3dWRKSUUtBdxkRuj2bYvM1kmoFKTFwiL31/gCX+GVb6Bjj3FNoyj2dXX1NDw8um4khQ0uJWM9T779UmAF471STwceebh5znnSefhT8+dyxXvxxaDzTl6S7EwoZ34MAa53O0vht6jDVZxz/oZYLp4zvMtvRUsji13wxDB/D2N9ndM+v0qOlZPrkbjvwOv89x3bNsS2JkC7gt3qaX/0IsfNzPJK3Ljrsv/Qmx8NfXJkFdapJzwA0m2F06MufzQ8H1fP460/G8zxQzn3TfcseNj4zlBN2xjWzY/T3sXwmHN8Lxvxw9hsf+dN5/3evQ8s6cz1sQPHmffAIAi/ldy26f7HJkFESA48noiCqNzOiRnYtMnodOjzp/NuT3+p7cLAJo1Bu6PAVnDppgMS3JJCosSWyJ0P5eY0ZaZP75ZPmbaYX10y/Wo8aU3uo5zkzjadjTvL5/N0LixZtH6WkF00Yff/jxWUfAXeMK6P0SfHR99sfqprmISKFQ0F2GpKVbGb94R5aAG3Bal35iN16uTpAYZ/5VDe1LR3HOwbdYTO32dzqZL9cb3jbTGsJaOO/392rzry3gDqxovqzuWQZJcY79jv1pkjD5h5pAM3Ow03YotL3H9P6A+QK66DFIOW+W174Mdy0wCYRsfnzWMUS68wioVC/r6/Dxgxtfhzk3mOVlY0y238CKF3ewwpb5sPE9xzH1u8HNb5sbCf+sM234IYcedxvbnO2Te82X+W2fOSdCBBO8dHjITCE5c8gkbdq7POdzF1TPZ8w2829oLXMTpEZrE3ydvFj39/unoNaa7LM2H98JS/8LRza53yewEoTUMJnw01NNRuhuHpZvyw9P3ydwv8+hDWYUwvxsEszld2i3pwHvgkHON7SObIHbP87bNTNz9V6djYYfnzNTLDLa+6P7IPvo1pKR3Tw9DebeZG6wYTFzsdsOdWzPacSNNT374dt/fA612rrf7slNlF/ehB0LzU09gMqNTLK2gkqMKSIiuaaguwyJOhDrNKQ8s1hrMAlWf4KyK/flGwR1OimwvlQU9xz8yg2gy3/NnEZrmkm4dfPbJiBPTzOZrzMm+wm73GRVrxhhenX3r4Z1b8DhDImJMgbiQVWgxf9B1Ez4/SPzcGfvjyareseLJXQOR5n547bzXJ5NnoMKdczw8PQ005v7SX/3+9a9Crq/AOdPml73VRPg4M+OJEcb34MrXfwftX2h/mc9rByftfwP3kAatH/Q9OiDeS22L/i/5KImel7LNwVUACzYb/PF/Qvv98i635l/4OObzE0XH3/nbYejzL+2DPc2Fi+odpm5mXHwJ7juRXMjJCUBprczw5H3REIDF9dzpSCG0VdpDNUvM/Xb960Av/IQHObojTcNNzcGgio7TyGw/Tyvfd51Eq2CGNrtKuC9cNr87uxb4RjlkTHgBti9FBY+Ah2G5e26rth+pw7+Ys5te+99y5mbTq5uTmyZ66hwEDkK/MqZXvnMPPlZFVTCuO1fXQy4Aaywd5l5BFQwqzo9Bpffap5v/dT8bmTk6nVG/2GSDpIOUe9Co17QyEWpRk9vomSc2lGpPgz+rmASY4qISJ4p6C5Djp91H3ADHKUKPZNe4aU+NejWuKrrndSTfekp7uGEl98GayYDVjN8eHY31/uFtzZJwS6cgQtbzbrgMGjYwwTdnUaYQHb39+ZLafsHoesoOH3QBN3uehwP/ATLXzDP//jceci6TcJJ0y53vY4Jp0zA7Rvk+EJ83UTT25Sxp9bLB/75xXUgarPlU/Nw58dMPbn+IdBuKFRtauaLR72X9Ys+mDnxnmZYB/h3Eyx61Ew7GfAuVKyb8zH7V2IPuKtfDjdPxwThF8UfhW+HQdIZMzLhw145n7NKE+gxBup3Bf9gk3vi4E9mDnD0xR71dkNh9cV8BOtez/mcBTWM/vhOE0Ae2+5+n28u5gCweJvf15AaJoFe8sURFudPmF76kBpQPsx5pIUnryO7QNKWi6BCXZNwbuunZli0002Bi2p3NHP/f3nDjJz443NT3qogbVtg3i/bVI5KDcxQ6y/+4/pGT3griI8xNwFSEx3vZWa+QfCfhWbUiSu2BGHZDfX3dFTBpg8vPrl4MyX+iFlMPGP+3fAWnNpjbg5k/H/Y+XGTkNHV66zR2gwvXz7GLH81FG79AMpXy/o6XI2wOLrFjHrJOHLANwiuHmluTPkGZv+aRESk0CnoLkOqBec8B+8oVfCv3QZqaF62lBBJZ3GaAOFX3jzOxVxccbHnNHorfNjb/XnqXQONe0NaivmC7h9s1l+cKum297ZGa/OFOWOt7dod4fCv5nn1FtD5Mfj2wZx7HTuNcCRMsgXyYILd9FSTNdjl/F0rrHoJ9mUoYXb57dDketNrtXe5c2ZnMIFU+wdMzfCAUEfyw8xfyM+dMEFN6gXThvijHiRC22GGu9vmn8/pC0MWZ39M0tmLN08uuvE1M480oxqtoe8rzkNwm91kRtdsmOEIYAB8AqHnWLjyfkc9ecg598TZo2b/gihDd2iD66A2+g/zb+be+OxY08zriz8CbHSsj3rXPMD0St6z1ARzOfHkxoH3xSB03i3mpktmwTXh7BHoPRk6XRzhEd7SBKjWNNjxrUcvzSN/fA6/vuNYbtAdbvvQuTZ0ZhYLXPWECbptqjaDfm86RkjYflZz+2X9P5JZnynmdy0zj0YVXPwbZbvGlfebm4D7Vpg8Dru/d+y6J9IxSgbMTaMGPZyrIGTWvD+sGG/e96R4mP9/WffxufgZb/tbdvof83dmx0Ln/Wq1h/+bA6E13V9PRESKlILuMqR9vUqEhwYQE5focl63BQgLNeXDREqchteZZFvJ5xwBQrlqZij24kdzDpBsway3r3OQ5olmNzkH3baAG4sZ7u6pJjeYnnP78Zjh0D0nmNeQXY377s85B91/fmEemVVtZoLRRr1cZzx3dXOhxxhHD/mSJ+Ghtdm/R0ufcsx1BzMsdc6NcMPL7o9ZP9302gI0vxlqt3e9n+1naEskt3OReWTW8WETIB37y3m9u9wTx3bAwovDoX2Css+En7EtYZfDzsVm+HrtDhBc3dFDnNP8XJvql5t5/cHV4ewxOPQrLL+YSb1pX0hLNTeR4o863iNXYv827/2d2Yx0sHF34yDxjLlJ89e3jpsYGQPuCnXg8v+DFreZHvpvHjC97rabNqG1zQiRNS85jtm2IO/zqa0XP40yBtxX3g99poK3T/ZBNzh6r8tVg/PH4cRO04N86/vOJeJSE93/jdi73NygsXiZ3/sLp83r9GT0hs3+1Y7nQVXgsgGm1GH56ub9qtTQ9HIHVHQkRQPT29zlv64rgmR04bT5/xBYySRXBJPjot395nfn342w/i2zftkLZhrN8Z3O+Rwq1DY3Yxr1Mr9nmX/XCjMxpoiIZEtBdxni7WVhbL/mDJu3OeOsSidj+zXH20u1bKUE6vQI/BvlCKpqXWkyO9syXec0z7ggMrA3H+Dcu9fmP+aaOX1htrFYTPD17jUmAVvFeqYcmKteRneu+Z8po5RxCLBfefN+/L3aZH0PDjdf+DPK7nW2f9DMjY/5wwzh/3UmXPVY1v1sNc1tAXdEF/PF/cQuM+93kYtjAOKjTdANple/x9icX2e30Vl7qut0NgF75CgzTNzdUHFXuSdqtDbvz59fmIBkzVS4fkr2bUhNNvXidy1xrKsYAeXCzPP2D0Kru0ywdv6kmRd/8CfHvl6+0OMFM3fedhOjQh3nGxrX/M/59zY1yQTfW+aZn3PzW6BcJRMkJ5wyvbo7F5vzeML2/+LEHlg10WTJttdHv8gnwASJVwwy77FtCLttjm92FSsAfptp5lM365d1W3ZTktJSnEc/AFz7nCnvltua6n0mOxIfbv/K3KjxDTK/bzbr3oByVczrTT5vAtkLpx3B5w//c+zr5QO3vGf+P+XkwmnH7zeY6Sa2xImZDZhpfl92LjbZ99t7eOPGpvck8zrTU9xPd8n4OwhQrqr5P1euKnx2hyqQiIiUQAq6y5g+LcKZOahNljrdQX7evHZ7K/q0CC/G1olkI7AiDHgPVow12cl7jDFDSHMqL1WQGdiveswEA399Y77Adh+Tu9cAUL05DFlkeqau+I/J0O1p0A6mZzS8lemRDqoE7e41gd+hDSaozMsXam8fuPGNi3PJrSYQumyAc7D07+8mW7hN+BWm7nXKBdOW0wcc5YfOHHYOJNe85Bjm3O4+kyAvJ42uM1MAlj1v5jpfN8G0yTZPOy9VFHqONcFO6gWThK/dvVDVzTnA1IeP2eq87vRB8wDTo7ptAdRsa5Jn2Ybb23R4COp1zdobn/EGiLubIbahwk2vh5a3Q93O8NW9jnbd+r77dmcW9y981Mf9/O5B30DEVVnX20aHuHuvN7wDf14M+n6e5qipnZG7+dSpF2D5OOdRI11Gml5Y288YPL8pVrmhCZI/HwRYTQ9v5qz9x/9yeahL6anw9f3mxkDVptnvu3yso/c5oovr0oG2ETfBF2tgN85mKkx2qjU3pROzy3AOZqRIaC24rL/pSc9uiklGytsiIlIsSkTQ/fbbb/PKK68QExNDq1atmD59Ou3bux6aOHv2bObOncv27SZxTdu2bXnppZec9j937hzPPPMM3333HadOnaJevXo89thjPPxw1vl3VquVG264gcjISL799lv69+9fKK+xKPVpEc51zcNYu+cED3y8iTSrlQqBvvS+LKy4myaSvSZ9zCM3CjIDu8XLJDBqe49JhFTeTcLBnNTtbB551exG88gopwAJsn+dtdqaYb0bZ5sA+duHTNk0cJTnyjikPHqL+zn0i0YAVtMbe/oAbP7ErPctZ3pTPdXxYVNb3T84a89nXjKoh9aCq58wNxVsJcTu/jLrfhcuDv+1Bdy+5cyohug/4Ohm57nBSfGOsnVghha3GmiGEm+YYR6u2Op05zREPeGUCZYq1YfanUxSwHMxpoSdJ9JSTG+97fe/XDVodSfUamfWgxlm7urGj71Ot5v3utMwR9ANYPGBPi+ZYfi24z2dT43VTOHIOI3DxtObYs1uhP4zYfPHkHTO/B4nxjluBmXm7X+xLJ3FzPUPvwLCLjN5Dvb+aEaTfPuwCVrd+We9uR6AX7BJKpjdXOmCGHHT4WFzY2vnYjNloUJdUzd9yzyz/c7PzE0rd1NE8lp9QERECk2xB92ff/45I0eOZNasWXTo0IE33niD3r17s3v3bqpVq5Zl/zVr1nDXXXfRuXNnAgICmDp1Kr169eKvv/6iZk3zQThy5EhWrVrFvHnziIiIYNmyZQwfPpwaNWpw0003OZ3vjTfewJLbYW6lgLeXhe5Nq9G5YWV+3nuSo3GJ7Iw+S/MaIcXdNJGCV5AZ2L28TKbsvCiIL9w5yc8X6nb3mqAbTBb191y9Toup0Vwh03zXxDhY+CjE/WPmDX/xn6yHppw3gXpuaksHFPDfpM6Pwea5JtDcuwz2rnAuvxR7AL4b7lgOqmwC85oXayOnJsPPr8HaySZIiz9i5hIDtB5keiHPHDJBd043QMD9zSBbRm13PZoHfzIjPXIKRte/6ShhVaEuPLjGeXSFT0A+RoFc/GxscoNJFGZNNb2+zW40Pc+Wi18hMs6nPnfc1GE/c3Gutk+g6fUuqN7X1neZh83RrY7f4wdWQ9UmZnSGbxD4BZn1f3xh3oNOw82ogvR0M4Uh6j3MzQAXPfhgpgIsftyx3OMF9wF3QY64sVjMzY0+GebVH93qCLqTz2UdXQGasy0iUoIVe9D92muv8cADDzB06FAAZs2axdKlS/nwww955pmsX0Y+/dQ5wcz777/P119/zcqVKxk82NzVX79+PUOGDKFbt24APPjgg7z77rtERUU5Bd1bt27l1VdfZdOmTYSHl81h19c1r87Pe00vwMqdxxR0S8lVFAFrYbWhIL9wF+b7kHk4bmBlE1ikXJxzXqUJnNxtgjdXgf3NM0yvpo1vecex5aqa8k+2Gsw5BVGF9Tr9gqDneEd5qaUjTZZsLx84td8EhLahwoGVzLB7i7dzT7AtQV2n4Sbp2JlD5udnG/lw5pD515MbINm9DyM2Zg3K//wKNlycPxxcI2vZqMx2Xswq7xMAd3xysWc3g9vnusmYf5EnAe81T5tM6Du+MwH0ny5GD3z/tBmmffqgo/JA+epmNMXX9+W/99WT3xeLl5l77lfO9b6n/3H8nFsPNDeSMs6ZXj8dOj/qWP79Y8f5q19uRoq4U5AjbrKTr5soIiJSXIo16E5OTub3339n9GhH3VkvLy969uzJhg0bPDpHQkICKSkpVKrk+KLRuXNnFi1axL333kuNGjVYs2YNe/bs4fXXX3c6buDAgbz99tuEhZXdYdfdm1ZjzEJzR3zFruM82qNRMbdIJJOCDFiLqw0F8YW7KN+HWleaOecXMrQ3oovJoP5hNsP7bb3SVRrByb2OgBvMnOxqzXO+dlG8zjodTABmTTc9ru7qol+Idd1jbxMQanodc5PlOjdcjdAIuxwOrTe916cPmF73a0dnPfbkbuflq0eaTOG2oNIWLGaXMd9TFi/TU+1XDrbOx2WazsQzzln7K9U3c8ltiRHzypPfF58A09vuLjC3/b/MKWHc9q/Mw5VTe3Mut1cQI25yurlQEDdRRESkyBVr0H3y5EnS0tKoXt35A6R69ers2rXLo3OMGjWKGjVq0LOnY/jg9OnTefDBB6lVqxY+Pj54eXkxe/ZsrrnmGvs+Tz75JJ07d+bmm2/26DpJSUkkJSXZl+Pj47PZu+SoVTGIpmHB7Io5y7bDZzgen0i1kJzreYsUmaLqISrsNuT3C3dRvg9XPwlfDoW0i3/TIrrAwM9NIO2Jvq+b+sBHt5jl6i1MeaPMGdVdKYrXmRDrnP3dt5zJBm3r6a9U35TnyqkMXWJc9nOhC4OXN/R7ywyZTk81c6AvGwDVMiT7Sog1ScoyWvOSc5kvKNibVT5+0P8d6PuauRlwar8pj2erMR5Y2XETp0YbGPiFGRmQmySCrnjy+5KaDJ/cnHNg7i5gXfeac63rKwZB9HbHnP9GfWBvpGcjOPLK05tR1ZorqBYRKYWKfXh5fkyZMoUFCxawZs0aAgIcgeT06dP59ddfWbRoEXXr1uWnn37ikUcesQfnixYtYtWqVWzZssXja02ePJnx48cXxssodNc1r86umLMArNp1nDvbe1iKRqSoFOScbLUhZyE14fqpJnlao15w2wfuh+S64h8M//nOJKE6uccMO3dVM9ydonqdDXuZ2ucZE8Q16AFdnzY9+u6GPBf36IuwFmZu+rrXzM2Cr++Hm6abXndruhnKffao2bfaZdDvTddJtQrjZpVvAFRrZh6htRxB93++MVnrz8aYUnneBfj1wpPfl/zcyLl6pHPQbZs7DWaqRZcnTdBdmErCzUcRESk0xRp0V6lSBW9vb44dO+a0/tixYzkO+Z42bRpTpkxhxYoVtGzZ0r7+woULPPvss3z77bf07dsXgJYtW7J161amTZtGz549WbVqFfv376dChQpO57z11lvp0qULa9asyXK90aNHM3LkSPtyfHw8tWuXjg+/Hs2qM33VPgBW7FTQLSJAu6HQZnDuguWMAivAwAUF2qQC1+FB+Gedo5xZi9tM9uvjO7I/riQEQK0HXqxTboVjf8Lsbq73u+ktk6m8MHk6/94/2DyKQ0HcyLnqCfjlDed1N77uKO9W2ErCjT8RESkUxRp0+/n50bZtW1auXGkv1ZWens7KlSsZMWKE2+NefvllJk2axI8//ki7ds5fNlJSUkhJScHLy8tpvbe3N+npZrjhM888w/33OydEufzyy3n99dfp168frvj7++Pv75/bl1gitKwZStVgf06cTWLdvhMkpqQR4JvHL9oiUnbkNeAuLcpVNb3Aq1+CFrfCtc+Z7PSeKO4AKPk8TnOnfcuZmwjrbLlJLGa7VyF+jBfEfOrSlFH7sgFm6sHixwGrmTLRsEf+h8iLiMglr9iHl48cOZIhQ4bQrl072rdvzxtvvMH58+ft2cwHDx5MzZo1mTx5MgBTp05lzJgxzJ8/n4iICGJiTJbU8uXLU758eUJCQujatStPP/00gYGB1K1bl7Vr1zJ37lxee+01AMLCwlz2pNepU4d69eoV0SsvOl5eFno0rcaCjYdJTEnnl30n6dEsm0QsIlK25TdAKk0BVsvbzaO0anw97PnBDJFf50gGSqfhsOHtwr12Qc2nLk0ZtdsOMYkCj/0FV2STZE9ERCQXij3ovuOOOzhx4gRjxowhJiaG1q1bExkZaU+udujQIade65kzZ5KcnMxtt93mdJ6xY8cybtw4ABYsWMDo0aO5++67iY2NpW7dukyaNImHH364yF5XSdOjWXUWbDwMmCHmCrpFLkH5natc3HOdL0Udh8ORTXD+hGPdZbeYUmaFHXRD4c+nLonqdjYPERGRAlLsQTfAiBEj3A4nzzy/+uDBgzmeLywsjI8++ihXbbBaXZRAKUOublgFfx8vklLTWbnzGOnpLfDyshR3s0SkKOV3rnJJmOucG6WpR96dgBDoM8XUugao2swkVTu1r3jblVFxD8UvKGXh90VEREqkEhF0S+EL9PPm6oZVWLnrOMfPJrH9aBwta1Uo7maJSFEriNJmJT3AKms98i1uhbPRELPd1FL3L1/cLSpbytrvi4iIlDgKui8hPZpVZ+Wu44AZYq6gW0TKpNLWI58TiwU6P1rcrSi7ytrvi4iIlDgKui8hPZpVg2/N8xU7jjHyusbF2yARkcJSGnrkPaEhz0WjrPy+iIhIiaSg+xJSPSSAlrVC+ePfOHZEx3P0zAVqVAgs7maJiEhmGvIsIiJSZijovsT0aFqdP/6NA2DlruP8p2PdYm6RiIhkoSHPIiIiZYaC7ktMj2bVeH2FGZa4YscxBd0iIiWVhjyLiIiUCQq6LzGX1QghPDSA6LhENuw/xfmkVMr5F86vQVq6lagDsRw/m0i14ADa16uEt8qUiYiIiIjIJURB9yXGYrHQo1k15v16iOS0dF5btoeezavnKSDOLqiO3B7N+MU7iI5LtO8fHhrA2H7N6dMivEBfk4iIiIiISEmloPsSFBroa3/+wS8H+OCXA7kOiLMLqgGGzduMNdMxMXGJDJu3mZmD2ijwFhERERGRS4LFarVmjo3EA/Hx8YSGhhIXF0dISEhxN8djkdujXQbEtj5uTwLi7M5hxQT1cRdSXB5rAcJCA1g3qruGmouIiIiISKnlaUzoVYRtkmKWlm5l/OIdWYJlwL5u/OIdpKW7vw/jyTncBdy2faLjEok6EOthq0VEREREREovBd2XkKgDsU7DwTPzJCDO6RyeOn42/+cQEREREREp6RR0X0I8DXSz26+gguVqwQEFch4REREREZGSTEH3JcTTQDe7/aqW9893O4L8vLkyomK+zyMiIiIiIlLSKei+hLSvV4nw0ACyS1/m7+NF69oVXG5LS7fy9eZ/s72GBagQ5IsF3F4nITmNacv2kJqWzob9p1i49Qgb9p/Kdi65iIiIiIhIaaTs5XlU2rOXAy6ToQFc3yKMN+5ozeZDZ+w1uNvWrcgzX//BN1uOuD13xgzoQJaSYhUCfTmTIclaeX8fziWl2pdVx1tEREREREoLT2NCBd15VFqDbnBdY7tyOT/iE1NISTO/DgG+XiSmpNu3Z1z28bJw39URLNoW7bJOty1oTku3EnUg1h64t69Xic+iDvH8d9tdtis3ZctERERERESKk4LuQlaag25wHRD/su8k987ZSGo2w7y9vWDm3W3pdVmYy3PkVHs7Ld1K6wnLOJuY6nJ75jreebmGiIiIiIhIYfM0JvQpwjZJCeLtZaFTg8pO665qWIXgAB9OJ7ivsx0S4EuPZtXdniMnUQdi3Qbc4Fy2LO5CcpYeeQ1BFxERERGR0kSJ1MQu6kBstgE3wOmElGzreOfE05Jj7//8N8Pmbc5SEzwmLpFh8zYTuT06z20QEREREREpKgq6xa4g6njnxNOyZSt3HXeZ6M22bvziHcp2LiIiIiIiJZ6CbrEriDreOfGkbFlOMg5BFxERERERKckUdItdTgGxBTOnun29Snm+hreXhbH9mtvPl/n8FqBX82oenSs/Pe4iIiIiIiJFQUG32OUUEAOM7dc839nD+7QIZ+agNoSFOveYh4UGMHNQG4ZeVd+j81QLDiAt3cqG/adYuPUIG/af0pBzEREREREpUZS9XJzYAuLMWcPDCjhreJ8W4VzXPMxlObC0dCvhoQHExCW6nNcN4GWB3/4+xcgvtiq7uYiIiIiIlFiq051Hpb1Od06Kuz525PZohs3bDOA28HbF1sKZg9oo8BYRERERkULjaUyooDuPynrQXRJEbo/O0uNeLdif0EAf9h4/7/Y4C6Znft2o7gDFevNARERERETKJk9jQg0vlxLL3RD0X/8+xd3v/+b2OFt28xmr9rFg4yENPxcRERERkWKjoFtKNG8vC50aVHZad/JckkfHvr5iT5Z1MXGJDJu3WcPPRURERESkSCh7uZQ6+akTbptLMX7xDmU6FxERERGRQqegW0qdnOqJ58Q2/DzqQGxBNktERERERCQLBd1S6nhST9wTx88m5ryTiIiIiIhIPijollLJVk88LNR5qHlYaABP9mzk0TnyM0xdRERERETEE0qkJqWWu+zmAAs2HiYmLtFtje9AX2/a1a1YdI0VEREREZFLknq6pVSzZTe/uXVNOjWojLeXJdvh5zYXUtIYt/gvUtPS2bD/FAu3HmHD/lNKriYiIiIiIgXKYrVaFWXkgaeF0KX4RG6PZvziHU51uisG+RJ3IQVbbF3Oz5vzyWn27Xmp452Wbs3S2+7tldc0byIiIiIiUhp4GhMq6M4jBd2lg6uAePG2ozzx+VaX+9tCZU/reLsK7PMSuIuIiIiISOniaUyo4eVSprkaft6vVQ1CAlynM8hNHe/I7dEMm7fZKeAGiIlLZNi8zURujy6IlyAiIiIiIqWYgm655EQdiCU+MdXt9sx1vNPSrVnmfaelWxm/eIfLRG25CdxFRERERKRsKxFB99tvv01ERAQBAQF06NCBqKgot/vOnj2bLl26ULFiRSpWrEjPnj2z7H/u3DlGjBhBrVq1CAwMpHnz5syaNcu+PTY2lkcffZQmTZoQGBhInTp1eOyxx4iLiyu01yglh6f1uXcfiydyezRXT13FXbN/5fEFW7lr9q9cPXUVM1btzdLDnVHmwF1ERERERC5NxR50f/7554wcOZKxY8eyefNmWrVqRe/evTl+/LjL/desWcNdd93F6tWr2bBhA7Vr16ZXr14cOXLEvs/IkSOJjIxk3rx57Ny5kyeeeIIRI0awaNEiAI4ePcrRo0eZNm0a27dvZ86cOURGRnLfffcVyWuW4uVpfe5xi3bwsIvh49Fxiby+Yq9H5/A0wBcRERERkbKp2BOpdejQgSuvvJIZM2YAkJ6eTu3atXn00Ud55plncjw+LS2NihUrMmPGDAYPHgxAixYtuOOOO3jhhRfs+7Vt25brr7+eF1980eV5vvzySwYNGsT58+fx8cm5fLkSqZVeaelWrp66Kts63gXlswc60qlB5Rzbo+znIiIiIiKlS6lIpJacnMzvv/9Oz5497eu8vLzo2bMnGzZs8OgcCQkJpKSkUKlSJfu6zp07s2jRIo4cOYLVamX16tXs2bOHXr16uT2P7Y1yF3AnJSURHx/v9JDSKbs63rbljvUrkV/l/b1pV7eiyznhNu6GrysJm4iIiIhI2ZBzl24hOnnyJGlpaVSvXt1pffXq1dm1a5dH5xg1ahQ1atRwCtynT5/Ogw8+SK1atfDx8cHLy4vZs2dzzTXXuG3HxIkTefDBB91eZ/LkyYwfP96jNknJ16dFODMHtclS7ivsYrmvpNR0fv3bs/nYFnDZY34uKY07Zm/g6OkLxMQn2dfbSooBDJu3OcuxtuznnpYtExERERGRkqtYg+78mjJlCgsWLGDNmjUEBDjm6U6fPp1ff/2VRYsWUbduXX766SceeeSRLME5mCEBffv2pXnz5owbN87ttUaPHs3IkSOdjqtdu3aBvyYpOn1ahHNd8zCXQ7s37D/l0Tme7NmYBRsPOQXuIQE+nE1MxQps/udMlmNi4hJ5eN5mKgT5us1+bsFkP7+ueZiGmouIiIiIlGLFGnRXqVIFb29vjh075rT+2LFjhIWFZXvstGnTmDJlCitWrKBly5b29RcuXODZZ5/l22+/pW/fvgC0bNmSrVu3Mm3aNKeg++zZs/Tp04fg4GC+/fZbfH193V7P398ff3//vLxMKcFsdbwza1+vEuGhAW7nfVswveIjujdkRPeGWQL3VTuP8eAnv2dbUuxMQorbdmXMfp7TnHARERERESm5inVOt5+fH23btmXlypX2denp6axcuZJOnTq5Pe7ll19m4sSJREZG0q5dO6dtKSkppKSk4OXl/NK8vb1JT0+3L8fHx9OrVy/8/PxYtGiRU0+5iCfzvsf2a463l8UeuN/cuiadGlTG28tC+QDXvdi5peznIiIiIiKlW7EPLx85ciRDhgyhXbt2tG/fnjfeeIPz588zdOhQAAYPHkzNmjWZPHkyAFOnTmXMmDHMnz+fiIgIYmJiAChfvjzly5cnJCSErl278vTTTxMYGEjdunVZu3Ytc+fO5bXXXgMcAXdCQgLz5s1zSoxWtWpVvL29i+GdkJImp3nf2c23Lqhg2dPyZiIiIiIiUjIVe9B9xx13cOLECcaMGUNMTAytW7cmMjLSnlzt0KFDTr3WM2fOJDk5mdtuu83pPGPHjrXPyV6wYAGjR4/m7rvvJjY2lrp16zJp0iQefvhhADZv3sxvv/0GQMOGDZ3Oc+DAASIiIgrp1Uppk9287+zkN1i2DV9vXy//WdRFRERERKT4FHud7tJKdbolOznVArcAoUG+xF2c1+1qn1nKXi4iIiIiUmKVijrdImWVJ3PCp9xyOTMHtSEsNGuveHhIAL0vyz6ZoIiIiIiIlHzFPrxcpKzydE54xuHrb6/ex55j54iOT+TXv5W5XERERESktFPQLVKIPJkTnrFsmcVi4bHPtgDwya8HFXSLiIiIiJRyCrpFCpm7WuCu9LksjCrl/Tl5Lokf/zpGdNwFwkMDC7mFIiIiIiJSWDSnW6QE8fPxYmD72oBJxvbZb4eKuUUiIiIiIpIfCrpFSpiBHerah5/PjzpMcmp6MbdIRERERETySkG3SAkTFhpA78tMnfqT55L4YXt0kVw3Ld3Khv2nWLj1CBv2nyItXdUERURERETyS3O6RUqgwZ0i+P7PGAA+2fAPN7euWajXi9wenSXLenimLOsiIiIiIpJ76ukWKYE61KtE4+rlAdj0z2n+OhpXaNeK3B7NsHmbnQJugJi4RIbN20xkEfW0i4iIiIiURQq6RUogi8XC4E4R9uVPNvxTKNdJS7cyfvEOXA0kt60bv3iHhpqLiIiIiOSRgm6REmrAFTUJ9jczQL7beoS4hJQCv0bUgdgsPdwZWYHouESiDsQW+LVFRERERC4FCrpFSqhy/j7c2rYWAIkp6byybFeBJzk7ftZ9wJ2X/URERERExJkSqYmUYIM61mXO+oMAzPv1EPN+NXW7CyrJma0nPSfVggPydR0RERERkUuVerpFSrB9x8+6XF8QSc7OJqYwfdXeHPcLDw2gfb1Keb6OiIiIiMilTD3dIiWULcmZK1bAgklydl3zMMDMzz5+NpFqwSZI9vayOJ0r4/Zm4cHcO2cjWw7nnBX9qgaVnc4lIiIiIiKeU9AtUkJ5muRsxqp9LNh4yG2NbVc1uH29LaSkmXnhFYN8Gd6tIR/+csDl9b7afISrG1WlX6sa2Qb2IiIiIiKSlcVqtaoWUB7Ex8cTGhpKXFwcISEhxd0cKYMWbj3C4wu25ulYWyj84DX1eO+nAy5LggGU8/Pmy4c707xGSJbe8A1/n+StlfsA8LJAhUA/YhOS7ccW1LxyEREREZHSyNOYUD3dIiVUfpKX2YLs9352H3ADBPn50CQsGABvLwudGlS2b+tYvxInzyUz/7dDpFtxCrjBMa985qA2CrxFRERERNxQIjWREqp9vUqEhwaQnwHcOY1jOXEuyW0NbovFwrh+l+Hv4/rPhO3U4xfvKLASZiIiIiIiZY2CbpESytvLwth+zQGyBN4FOZM6uxrcv/9zmqTUdLfbbfPK3QXuIiIiIiKXOgXdIiVYnxbhzBzUhrBQ56HmYaEBPNmzUYFcI7th7NkF5HnZT0RERETkUqM53SIlXJ8W4VzXPCxL5nCABRsPExOX6HbetpfFDDF3td2CCd6zq8Ht6bzy/Mw/FxEREREpy9TTLVIK2JKc3dy6Jp0u1s3Oafi5BXigSz232wHG9muebdmvnOaVWzBZzLML3EVERERELmUKukVKseyGn88c1IbRNzTPdntOWcezC+xtcgrcRUREREQuZarTnUeq0y0lSeYa2+3rVXIKhHPanpPI7dGMX7yD6Djnudv3XhXBmH6XFUgbRURERERKE9XpFrmEZK6xndvtOck4r/yXfSeZsXofAL/sO0V6uhWvHIJnV0F7eGgAY/s1V41vERERESnTNLxcRDxiC9z/26sxbepUAGD3sbOs3HU82+Mit0czbN7mLL3kMXGJDJu3mcjt0YXVZBERERGRYqegW0RyxWKx8Mi1De3LM1bvw90slbR0K+MX73CZPd22bvziHaSla5aLiIiIiJRNCrpFJNe6N61G07BgALYdPsP6/adc7hd1IDZLD3dGViA6LpGoA7GF0UwRERERkWKnoFtEci1zb/fbF+d4Z3b8rPuAOy/7iYiIiIiUNgq6RSRPbrg8nHpVygGwfv8pNh86nWWfasEBWda54ul+IiIiIiKljYJuEckTby8Lw7o2sC+/46K3Oy09PcfzhIWY8mEiIiIiImWRgm4RybP+V9SkRqjppV6x8zg7o+Pt27YfiePheZtzPEeLmiGq1y0iIiIiZZaCbhHJMz8fLx68pr59ecKSHSzceoRvN//L4A9+41xSKgCX1wwhLMT1EPJVu46z7fCZomiuiIiIiEiRs1jd1fqRbMXHxxMaGkpcXBwhISHF3RyRYnMhOY0rJ62wB9iZXRlRkbn3dsDPx4uoA7EcP5tIteAAfj8Uy7Qf9wDQNCyYRSOuxs9H9wFFREREpHTwNCb0KcI2iUgZtHbPcbcBN8CdV9Yh0M8bgE4NKtvXt4uoyPd/xLAjOp5dMWd5d+1+Hu3RqNDbKyIiIiJSlNStJCJ5lpZuZfziHdnuM23ZbtLSsw6o8fX24uXbWtrnc09ftY/dMfFs2H+KhVuPsGH/KZfHiYiIiIiUJurpFpE8izoQS3Rc9jW2o+MSiToQ69TLbdOiZigPdKnPrLX7SU5L58bp60hJcwTa4aEBjO3XnD4twgu87SIiIiIiRaFE9HS//fbbREREEBAQQIcOHYiKinK77+zZs+nSpQsVK1akYsWK9OzZM8v+586dY8SIEdSqVYvAwECaN2/OrFmznPZJTEzkkUceoXLlypQvX55bb72VY8eOFcrrEymrjp/NPuD2ZL8nejaiWrA/gFPADRATl8iweZuJ3B6d90aKiIiIiBSjPAXdhw8f5t9//7UvR0VF8cQTT/Dee+/l+lyff/45I0eOZOzYsWzevJlWrVrRu3dvjh8/7nL/NWvWcNddd7F69Wo2bNhA7dq16dWrF0eOHLHvM3LkSCIjI5k3bx47d+7kiSeeYMSIESxatMi+z5NPPsnixYv58ssvWbt2LUePHuWWW27JdftFLmXVgl1nJM/Nfr7eXqS6GUZuWzt+8Q4NNRcRERGRUilPQffAgQNZvXo1ADExMVx33XVERUXx3HPPMWHChFyd67XXXuOBBx5g6NCh9h7poKAgPvzwQ5f7f/rppwwfPpzWrVvTtGlT3n//fdLT01m5cqV9n/Xr1zNkyBC6detGREQEDz74IK1atbL3iMfFxfHBBx/w2muv0b17d9q2bctHH33E+vXr+fXXX/PylohcktrXq0R4aADuqmxbMEPE29er5PYcUQdiiT2f7Ha7FccQdRERERGR0iZPQff27dtp3749AF988QUtWrRg/fr1fPrpp8yZM8fj8yQnJ/P777/Ts2dPR4O8vOjZsycbNmzw6BwJCQmkpKRQqZLjS33nzp1ZtGgRR44cwWq1snr1avbs2UOvXr0A+P3330lJSXG6btOmTalTp47b6yYlJREfH+/0ELnUeXtZGNuvOUCWwNu2PLZfc3uyNFcKYoi6iIiIiEhJlaegOyUlBX9/MwdzxYoV3HTTTYAJXKOjPZ97efLkSdLS0qhevbrT+urVqxMTE+PROUaNGkWNGjWcAujp06fTvHlzatWqhZ+fH3369OHtt9/mmmuuAUzvvJ+fHxUqVPD4upMnTyY0NNT+qF27tsevU6Qs69MinJmD2hAW6jyEPCw0gJmD2uSYBK0ghqiLiIiIiJRUecpeftlllzFr1iz69u3L8uXLmThxIgBHjx6lcuWsGYoLy5QpU1iwYAFr1qwhIMDxhXz69On8+uuvLFq0iLp16/LTTz/xyCOPZAnOc2P06NGMHDnSvhwfH6/AW+SiPi3Cua55GFEHYjl+NpFqwWZIeXY93Da2IeoxcYm4mrVtwQTw2Q1RFxEREREpqfIUdE+dOpUBAwbwyiuvMGTIEFq1agXAokWL7MPOPVGlShW8vb2zZA0/duwYYWFh2R47bdo0pkyZwooVK2jZsqV9/YULF3j22Wf59ttv6du3LwAtW7Zk69atTJs2jZ49exIWFkZycjJnzpxx6u3O7rr+/v723n0Rycrby+KyLJgnx43t15xh8zZjAZeBd05D1EVERERESqo8DS/v1q0bJ0+e5OTJk04Jzx588MEspbmy4+fnR9u2bZ2SoNmSonXq1MntcS+//DITJ04kMjKSdu3aOW1LSUkhJSUFLy/nl+bt7U16ejoAbdu2xdfX1+m6u3fv5tChQ9leV0QKh7sh6gDXNK6qOt0iIiIiUmrlqaf7woULWK1WKlasCMA///zDt99+S7Nmzejdu3euzjVy5EiGDBlCu3btaN++PW+88Qbnz59n6NChAAwePJiaNWsyefJkwPSyjxkzhvnz5xMREWGfg12+fHnKly9PSEgIXbt25emnnyYwMJC6deuydu1a5s6dy2uvvQZAaGgo9913HyNHjqRSpUqEhITw6KOP0qlTJzp27JiXt0RE8injEPV9x88yaelOElPT+XnvCXbHnKVJWHBxN1FEREREJNfyFHTffPPN3HLLLTz88MOcOXOGDh064Ovry8mTJ3nttdcYNmyYx+e64447OHHiBGPGjCEmJobWrVsTGRlpT6526NAhp17rmTNnkpyczG233eZ0nrFjxzJu3DgAFixYwOjRo7n77ruJjY2lbt26TJo0iYcffti+/+uvv46Xlxe33norSUlJ9O7dm3feeScvb4eIFBDbEPVODSoTn5jKKz/uJt0KE5fs4JP72mOxaIi5iIiIiJQuFqvV6moKZbaqVKnC2rVrueyyy3j//feZPn06W7Zs4euvv2bMmDHs3LmzMNpaosTHxxMaGkpcXBwhISHF3RyRMicxJY2er63l39MXAHh/cDt6Nq+ew1EiIiIiIkXD05gwT3O6ExISCA42Qz2XLVvGLbfcgpeXFx07duSff/7JW4tFRDII8PXm2Rua2Zcnfb+T5NT0YmyRiIiIiEju5SnobtiwId999x2HDx/mxx9/pFevXgAcP35cvb4iUmCubxFmLxV24OR55m44WLwNEhERERHJpTwF3WPGjOGpp54iIiKC9u3b2zN+L1u2jCuuuKJAGygily6LxcKYG5tjm8r9xoo9/Lg9moVbj7Bh/ynS0nM9O0ZEREREpEjlaU43QExMDNHR0bRq1cqe6CwqKoqQkBCaNm1aoI0siTSnW6TojPrqDz7fdDjL+vDQAMb2a66SYiIiIiJS5Ap1TjdAWFgYV1xxBUePHuXff/8FoH379pdEwC0iRatN3Qou18fEJTJs3mYit0cXbYNERERERDyUp6A7PT2dCRMmEBoaSt26dalbty4VKlRg4sSJpKcr0ZGIFJy0dCtvrNjrcpttmM74xTtIS7eSlm5lw/5TGn4uIiIiIiVGnup0P/fcc3zwwQdMmTKFq666CoB169Yxbtw4EhMTmTRpUoE2UkQuXVEHYomOS3S73QpExyUyY9U+Fmw85LSvhp+LiIiISHHL05zuGjVqMGvWLG666San9QsXLmT48OEcOXKkwBpYUmlOt0jRWLj1CI8v2JqnYy/mX2PmoDYKvEVERESkQBXqnO7Y2FiXc7ebNm1KbGxsXk4pIuJSteCAPB+befi5iIiIiEhRy1PQ3apVK2bMmJFl/YwZM2jZsmW+GyUiYtO+XiXCQwPsvda5ZRt+HnVANwRFREREpOjlaU73yy+/TN++fVmxYoW9RveGDRs4fPgw33//fYE2UEQubd5eFsb2a86weZux4Oi9BrIsZ+f4WffzwkVERERECkueerq7du3Knj17GDBgAGfOnOHMmTPccsst/PXXX3zyyScF3UYRucT1aRHOzEFtCAt1HmoeFhrAkz0beXSO/AxTFxERERHJqzwlUnNn27ZttGnThrS0tII6ZYmlRGoiRS8t3UrUgViOn02kWnAA7etVAuDqqauIiUt02+vtZYHPHuhIu4hKWY739nIeuO7qGpn3ERERERHxNCbM0/ByEZHi4O1loVODylnWuxt+bpNuhYHv/0p5f1/iLqTY12cuKRa5PZrxi3eo7JiIiIiIFJg8DS8XESlJ3A0/rx7iT5Pq5QFIS8cp4AaIiUtk2LzNRG6PJnJ7NMPmbc5SEzzjPiIiIiIiuaWebhEpE/q0COe65mFZhoanpqVzxcTlJCRnnfZi6xUf/fUfWCxeLnvJrZiEbeMX7+C65mEaai4iIiIiuZKroPuWW27JdvuZM2fy0xYRkXxxNfw86sAZlwF3RqcvpGa7PWPZMVfD20VERERE3MlV0B0aGprj9sGDB+erQSIiBakgS4Wp7JiIiIiI5Faugu6PPvqosNohIlIoCrJUWLXgAGU3FxEREZFc0ZxuESnT2terRHhogNuSYhZMwjWwcCzefdkxb4uFbYfPMPKLrcpuLiIiIiIeU/ZyESnTvL0sjO3XHDABdka25XE3Xca4m1zvY5NmtTIlcpeym4uIiIhIrijoFpEyz11JsbDQAGYOakOfFuFu96kW7E+dSoFuz23rGR+/eAdp6e76yUVERETkUmWxWq36lpgH8fHxhIaGEhcXR0hISHE3R0Q84Ml8bFf7rN93kv98GJXj+T97oKOym4uIiIhcIjyNCTWnW0QuGa5KinmyT2xCskfnV3ZzEREREclMw8tFRHLgaQb0gsyULiIiIiJlg4JuEZEc2DKgZ1cYLDzUDEUXEREREclIQbeISA6yy4Bu06VRFdXrFhEREZEsFHSLiHjAXXZzm69+/5cVO44VcatEREREpKRT9vI8UvZykUtT5uzmP+89wTtr9gMQ5OfNZw90JCE5LdsM6SIiIiJS+il7uYhIIcic3bxDvUocik1gyR/RJCSnMeCdX8hYrjs8NICx/ZrTp0V4MbRWRERERIqbhpeLiOSDl5eFaf/XinpVggCcAm6AmLhEhs3bTOT26GJonYiIiIgUNwXdIiL55OvtxfmkNJfbbDH4+MU7SMsckYuIiIhImaegW0Qkn8wc7yS3261AdFwiUQdii65RIiIiIlIiKOgWEcmn42cTC3Q/ERERESk7FHSLiORTtWDXZcTyup+IiIiIlB0KukVE8ql9vUqEhwaQXWGw8FBTPkxERERELi0KukVE8snby8LYfs0B3AbeLWqGql63iIiIyCVIQbeISAHo0yKcmYPaEBbqegj58h3HWLXrWBG3SkRERESKW4kIut9++20iIiIICAigQ4cOREVFud139uzZdOnShYoVK1KxYkV69uyZZX+LxeLy8corr9j32bNnDzfffDNVqlQhJCSEq6++mtWrVxfaaxSRsq9Pi3DWjerOZw905M07W/PZAx15vm8z+/aRX2zj6JkLxdhCERERESlqxR50f/7554wcOZKxY8eyefNmWrVqRe/evTl+/LjL/desWcNdd93F6tWr2bBhA7Vr16ZXr14cOXLEvk90dLTT48MPP8RisXDrrbfa97nxxhtJTU1l1apV/P7777Rq1Yobb7yRmJiYQn/NIlJ2eXtZ6NSgMje3rkmnBpW57+p69GpeHYAzCSk8+tkWElPS2LD/FAu3HmHD/lOq3y0iIiJShlmsVmuxftvr0KEDV155JTNmzAAgPT2d2rVr8+ijj/LMM8/keHxaWhoVK1ZkxowZDB482OU+/fv35+zZs6xcuRKAkydPUrVqVX766Se6dOkCwNmzZwkJCWH58uX07Nkzx+vGx8cTGhpKXFwcISEhnr5cEbkExSWk0Hf6z/x72vRyl/Pz5nxymn17eGgAY/s1p0+L8OJqooiIiIjkkqcxYbH2dCcnJ/P77787BbleXl707NmTDRs2eHSOhIQEUlJSqFTJdVbgY8eOsXTpUu677z77usqVK9OkSRPmzp3L+fPnSU1N5d1336VatWq0bds2fy9KRCST0CBfZgxsg/fFv7gZA26AmLhEhs3bTOT26GJonYiIiIgUJp/ivPjJkydJS0ujevXqTuurV6/Orl27PDrHqFGjqFGjhtve6Y8//pjg4GBuueUW+zqLxcKKFSvo378/wcHBeHl5Ua1aNSIjI6lYsaLL8yQlJZGUlGRfjo+P96h9IiIAl9cMJcjPh7OJqVm2WTFZz8cv3sF1zcOU5VxERESkDCn2Od35MWXKFBYsWMC3335LQIDrjMEffvghd999t9N2q9XKI488QrVq1fj555+Jioqif//+9OvXj+ho1z1NkydPJjQ01P6oXbt2obwmESmbog7Eugy4baxAdFwiUQdii65RIiIiIlLoijXorlKlCt7e3hw75lxG59ixY4SFhWV77LRp05gyZQrLli2jZcuWLvf5+eef2b17N/fff7/T+lWrVrFkyRIWLFjAVVddRZs2bXjnnXcIDAzk448/dnmu0aNHExcXZ38cPnw4F69URC51x88mFuh+IiIiIlI6FGvQ7efnR9u2be0JzsAkUlu5ciWdOnVye9zLL7/MxIkTiYyMpF27dm73++CDD2jbti2tWrVyWp+QkACY+eMZeXl5kZ6e7vJc/v7+hISEOD1ERDxVLdj1aBxX+6WlW5XdXERERKSMKNY53QAjR45kyJAhtGvXjvbt2/PGG29w/vx5hg4dCsDgwYOpWbMmkydPBmDq1KmMGTOG+fPnExERYS/xVb58ecqXL28/b3x8PF9++SWvvvpqlmt26tSJihUrMmTIEMaMGUNgYCCzZ8/mwIED9O3btwhetYhcatrXq0R4aAAxcYlkF0J/8utBnvx8KzHxjh5vZTcXERERKb2KfU73HXfcwbRp0xgzZgytW7dm69atREZG2pOrHTp0yGme9cyZM0lOTua2224jPDzc/pg2bZrTeRcsWIDVauWuu+7Kcs0qVaoQGRnJuXPn6N69O+3atWPdunUsXLgwS6+4iEhB8PayMLZfc8AkTXPn+z9jnAJuUHZzERERkdKs2Ot0l1aq0y0ieRG5PZrxi3cQHefck926Vig//HXM7XEWICw0gHWjuiu7uYiIiEgJ4GlMWOzDy0VELiV9WoRzXfMwog7EcvxsItWCA2hfrxJRB2KzDbozZjfv1KBy0TVYRERERPJFQbeISBHz9rJkCZyV3VxERESkbCr2Od0iIpK77OYiIiIiUnoo6BYRKQFs2c2zm63t7+NFy1qhRdYmEREREck/Bd0iIiWAJ9nNk1LTuf/jTcRfSFEdbxEREZFSQtnL80jZy0WkMLjKbl65nB/nklJJSk0HwNfbQkqa40+36niLiIiIFD1PY0IF3XmkoFtECktaujVLdvM//j3DwNm/ciElPcv+tp7xmYPa0KdFuMvjVWZMREREpGCpZJiISCnlKrt5y1oVKOfvw4WU5Cz7WzGB9/jFO0hPh4lLs9YBV0+4iIiISPHQnG4RkVIg6kAsJ89lDbhtbHW8h8/f7BRwA8TEJTJs3mYit0cXcitFREREJDMF3SIipUB+6nPb5hCNX7xDSddEREREipiCbhGRUiC/9bltPeFRB2ILpkEiIiIi4hHN6RYRKQVsdbxj4hLJT1+1rcdcydZEREREioaCbhGRUsBWx3vYvM1YwCnwzrycncOxCfzwZzQTlijZmoiIiEhR0PByEZFSok+LcGYOakNYqPNQ87DQAN4ZeAXhoQHk1Fc9bdkehn2qZGsiIiIiRUU93SIipUifFuFc1zzM5dBwLy+Ly55wT2QsO3Zd8zANNRcREREpIOrpFhEpZWx1vG9uXZNODSrbA2R3PeHhoQHMvLsNT/ZsnO15lWxNREREpOCpp1tEpAzJric8Oe2IR+fIT3kyEREREXGmoFtEpIyx9YRn5mnZsfyWJxMRERERBw0vFxG5RNjKjmU3W7tCoC/t61UqsjaJiIiIlHUKukVELhG2smOA28D7zIUU5m44SFq6lQ37T7Fw6xE27D9FWnp+qoOLiIiIXLosVqtV36TyID4+ntDQUOLi4ggJCSnu5oiIeCxyezTjFzvX6Q7y8yYhOc2+XN7fh3NJqfZl1fEWERERceZpTKigO48UdItIaZaWbnVKtnZlREXeWrWPt1budbm/rWd85qA2CrxFRERE8Dwm1PByEZFLUOayYz7eXjzeoxHBAa7za9ruzo5fvENDzUVERERyQUG3iIgAEHUglrOJqW63q463iIiISO4p6BYREcDz+tyq4y0iIiLiOQXdIiICqI63iIiISGFQ0C0iIoBndbxDAnxUx1tEREQkFxR0i4gI4Fkd7/jEVL7+/d+ia5SIiIhIKec6Ta2IiFyS+rQIZ+agNlnqeGes2/3MN38Q4OtF1eAAe8mx9vUq4e2VXR+5iIiIyKVJdbrzSHW6RaQsc1XHe/IPu/hg3QGX+4eHBjC2X3PV8BYREZFLhqcxoYLuPFLQLSKXGqvVyqD3f+OX/aeybLP1cc8c1EaBt4iIiFwSPI0JNadbREQ8km6F/SfOu9xmu3s7fvEO0tJ1L1dERETERkG3iIh4JOpALDHx7mt0W4HouESiDsR6dL60dCsb9p9i4dYjbNh/SsG6iIiIlElKpCYiIh45ftZ9wO20X3xiljnhmROt/X979x4dVXX/ffwzCZAJkIQEfuQCweCllYhcQwKivWgU1IdVCl7AIIgWCwJFs9oCWgj8qHJTawWMhZ/40IcilPbxgpQoBlD0CYLEWCMQ5WJxhUy4SRIuuZg5zx84Y4bMLZnMTC7v11pZyzlnzz77wDac79l7f3dOYUm9ZG2sCwcAAK0Ra7obiTXdANqavCNnNH7NHo/lEqPDVVlj1anzVfZjdQPqnMISTVufryv/8WFdOAAAaElY0w0AaFKpvWMUH2V2uYe3zTffXnIIuCXJUlapaevz9eanxZr35hf1Am6JdeEAAKB1IugGAHglNMSkrFHJklQv8LZ9NrmIyI3vf2ZtKtCpiirnhdTwdeEAAADNHUE3AMBrI/vGK3vCIMVFmR2Ox0WZ9UT6dWqqBUverh8HAABo7ppF0L1q1SolJSXJbDYrLS1Ne/fudVl2zZo1uuWWWxQdHa3o6Gilp6fXK28ymZz+LF++3KHc1q1blZaWpvDwcEVHR2v06NH+uD0AaFVG9o3Xh7Nv1WtThurP4wbotSlD9eHsW5XUrVOTXaN7hNlzIQAAgBYg6EH3pk2blJmZqaysLOXn56t///4aMWKETp486bT8rl27NH78eO3cuVN5eXlKTEzUHXfcoeLiYnuZkpISh5+1a9fKZDJp7Nix9jL//Oc/9eCDD2ry5Mn67LPP9NFHH+mBBx7w+/0CQGsQGmLSsGu66hcDemjYNV0VGmLyOlCO6dTB7brw2MgwpfaOaZqGAgAABFnQs5enpaVpyJAhWrlypSTJarUqMTFRM2fO1Jw5czx+v7a2VtHR0Vq5cqUmTpzotMzo0aNVUVGh3NxcSdJ3332npKQkLVy4UI888kij2k32cgBwVGs1dPPSHbKUVTpNlGbS5Wno8+5O1vQN+ZLktFyPLuHa9vgtijS392dzAQAAfNIispdXV1dr//79Sk9Ptx8LCQlRenq68vLyvKrj4sWLqqmpUUyM81GR0tJSbd261SG4zs/PV3FxsUJCQjRw4EDFx8frzjvvVGFhoW83BABtmDeJ1rJGJeuufs7XhYd+X6j43CU9+tdPdLH6O+UdOaM3C4qVd+QMGc0BAECL1C6YFz99+rRqa2sVGxvrcDw2NlaHDh3yqo7Zs2crISHBIXCva926dYqIiNCYMWPsx44ePSpJWrBggZ5//nklJSXpueee089+9jN9+eWXTgP4qqoqVVX9kHG3vLzcq/YBQFtiS7S2cMsBlZT9kAwtrs4+3bZytyfHae+xszpZUanuEWbFdOqgcavz9O3FGu05elaDFm1XZY3VXkf8FXUAAAC0BEENun21ZMkSbdy4Ubt27ZLZ7Hwt4dq1a5WRkeFw3mq9/BD31FNP2dd5v/rqq+rZs6c2b96sX//61/XqWbx4sRYuXOiHuwCA1sVZQJ3aO0ahIY7j37Z14XWtfWiI7v/LHlXXWh0CbumHvb6zJwzSyL7xqrUaHq8BAAAQbEENurt166bQ0FCVlpY6HC8tLVVcXJzb7z777LNasmSJ3nvvPfXr189pmd27d6uoqEibNm1yOB4ff3mUJDk52X4sLCxMV199tY4fP+60rrlz5yozM9P+uby8XImJiW7bCABtlbOA2hv9enZRp7BQVV+01jtn6PI09YVbDshqlRZtdRxNZyQcAAA0R0Fd092hQwcNHjzYnuBMujwKnZubq2HDhrn83rJly7Ro0SLl5OQoJSXFZblXXnlFgwcPVv/+/R2ODx48WGFhYSoqKrIfq6mp0ddff62rrrrKaV1hYWGKjIx0+AEANK29x87q24s1Ls8bkkrKKvXYhnyHgFv6YSQ8p7DEz60EAADwXtC3DMvMzNSaNWu0bt06HTx4UNOmTdOFCxc0efJkSdLEiRM1d+5ce/mlS5dq3rx5Wrt2rZKSkmSxWGSxWHT+/HmHesvLy7V582b96le/qnfNyMhITZ06VVlZWXr33XdVVFSkadOmSZLuvfdeP94tAMCdkxWVngu5YEuztnDLAZKuAQCAZiPoa7rvv/9+nTp1SvPnz5fFYtGAAQOUk5NjT652/PhxhYT88G4gOztb1dXVuueeexzqycrK0oIFC+yfN27cKMMwNH78eKfXXb58udq1a6cHH3xQly5dUlpamnbs2KHo6Oimv0kAgFe83evbFdtI+N5jZxs1vR0AAKCpBX2f7paKfboBoOl52uvbW38eN0C/GNCjydoFAABwpRaxTzcAAHV5s9e3N3wdMQcAAGgqBN0AgGbFttd3XJRj4BwXZdZLDwxUfJTZbQDesUOohiR5t1So1moo78gZvVlQrLwjZ1gLDgAAmlzQ13QDAHAld3t9h4SYNG19vkyS0ynoF6tr9fL7RzTj1uvcXiOnsEQLt7DtGAAA8C/WdDcSa7oBIHicBcxdwtvr3KUfthtbPOZG3ZeS6DRwzyks0bT1+fWCdtsIevaEQQTeAADALW9jQoLuRiLoBoDgqrUa9QLq/9l9VIu3HZJ0OYDu0rG9w77f8VFmzbu7jxZtPVhvn28bky5PZf9w9q0KDWnISnIAANCWeBsTMr0cANAihYaY6m0L9uufXqPT56u0ZvcxGZJDwC1JlrJKPbbhU7f1su0YAABoSiRSAwC0Kr8fcb3M7Z3/89aQqV0nK5yPhAMAADQEQTcAoFX55D/fqrLG6nM9bDsGAACaAtPLAQCtiq8j1LY13am9Y5qmQQAAoE1jpBsA0Ko0ZITaWZo0Q1LWqGSSqAEAgCZB0A0AaFVSe8coPsrsNKCWLgfa8VFmvfTAIMVF1Q/Qozu2109+9F9+bSMAAGg7CLoBAK1KaIhJWaOSJdUfybZ9zhqVrLv6xevD2bfqtSlD9ef7B6h/zyhJlzOer9xxOHANBgAArRpBNwCg1RnZN17ZE+qPZMdFmZU9YZBG9o2X9MO2Y78Y2EMvjBuoDqGX/1lcs/uojpw6H/B2AwCA1sdkGEZDdlDB97zdCB0AEDy1VkN7j53VyYpKdY+4nBzN3Vrt594t0orvR7lvua6b/vpwqkwm1+UbWj8AAGg9vI0JyV4OAGi1bCPZ3nrsZ9fq/+YXq/jcJe3+6rS2FVp0143xTsvmFJZo4ZYDKin7IVt6fJRZWaOS7SPpAAAATC8HAOB74R1C7evBJem/t3yhnYdO6s2CYuUdOaNa6+XJYTmFJZq2Pt8h4JYkS1mlpq3PV05hSUDbDQAAmi9GugEAqOP25Fj9/Mf/pZ1Fp2Qpr9Lk/73Pfi4+yqx5d/fRoq0H5WxtlqHLydoWbjmg25PjmGoOAAAY6QYAoC6TyaRbr+/u9JylrFKPbfi03gh3XYakkrJK7T121k8tBAAALQlBNwAAddRaDb2064jTcw3JPHqywnVgDgAA2g6CbgAA6th77KzbkWxvdY8wey4EAABaPYJuAADqaKoR6txDpbJaDdVaDeUdOVMvGRsAAGgbSKQGAEAdDRmhNsn1lPP/2X1M+f/5VifOXZKlvMp+nG3FAABoWxjpBgCgjtTeMYqPMstV3nGTLgfOLz0wSHFRjgF6fJRZD6Qmypa0PP/4OYeAW2JbMQAA2hpGugEAqCM0xKSsUcmatj6/3ki2LRC3jVSP6BunvcfO6mRFpbpHmJXaO0ahISbddn2sfvXXT9hWDAAAMNINAMCVRvaNV/aE+iPZcVFmZU8YZJ8aHhpi0rBruuoXA3po2DVd7QF0x7B2bjOds60YAABtByPdAAA4MbJvvG5Pdj6S7Ym3ydjYVgwAgNaPoBsAABdsI9kN5W0yNrYVAwCg9WN6OQAATcxTMjbpctK11N4xAWsTAAAIDoJuAACamC0ZmySXgfcf7u5DEjUAANoAgm4AAPzAVTI2myOnLgS4RQAAIBhMhmG4S7AKF8rLyxUVFaWysjJFRkYGuzkAgGaq1mrYk7Gdu1ijBW99IUOXR8P/Oe0mDUjsEuwmAgCARvA2JiSRGgAAfnRlMrYzF6r1Yu5XqrUaenzjp9r6m1vUKYx/jgEAaK2YXg4AQADNvPVa9f9+dPvrMxf1328fUN6RM3qzoFh5R86o1soENAAAWhOmlzcS08sBAI117PQF3fXn3bpUU1vvXHyUWVmjkjWyb3wQWgYAALzlbUzISDcAAAHWu1snjRnUw+k5S1mlpq3PV05hSYBbBQAA/IGgGwCAAKu1Gso9dNLpOdv0s4VbDjDVHACAVoCgGwCAANt77KwsZZUuzxuSSsoqtffYWY911VoN1oQDANCMkS4VAIAAO1nhOuC+slzdLce6R5iV2jtGoSEmSVJOYYkWbjmgkjoBPGvCAQBoXgi6AQAIsO4RZq/K5f/nWy3ZdshpUC1J09bn68pxbdua8OwJg+yBt7vA3ZvzAACg8ZrF9PJVq1YpKSlJZrNZaWlp2rt3r8uya9as0S233KLo6GhFR0crPT29XnmTyeT0Z/ny5fXqq6qq0oABA2QymVRQUNDUtwYAQD2pvWMUH2WWp7B2Xd5/HAJu6XJQPXV9vub838/rBdxS/TXhOYUlunnpDo1fs0ezNhZo/Jo9unnpDnuiNk/nAQCAb4IedG/atEmZmZnKyspSfn6++vfvrxEjRujkSecJZnbt2qXx48dr586dysvLU2Jiou644w4VFxfby5SUlDj8rF27ViaTSWPHjq1X3+9//3slJCT47f4AALhSaIjJPlrd0PFkW1B97mKN2zIlZZX69f/5RFPX5zsN3Ketz9fifx3QNDfnCbwBAPBd0PfpTktL05AhQ7Ry5UpJktVqVWJiombOnKk5c+Z4/H5tba2io6O1cuVKTZw40WmZ0aNHq6KiQrm5uQ7Ht23bpszMTP3zn//UDTfcoE8//VQDBgzwqt3s0w0A8JWrNdn3DOqhFTuP+P36JsnpaLntXFyUWR/OvpWp5gAAOOFtTBjUNd3V1dXav3+/5s6daz8WEhKi9PR05eXleVXHxYsXVVNTo5iYGKfnS0tLtXXrVq1bt67e8SlTpuiNN95Qx44dPV6nqqpKVVVV9s/l5eVetQ8AAFdG9o3X7clx9dZTv/3vEwG5vru37nUzqA+7pmtA2gMAQGsU1KD79OnTqq2tVWxsrMPx2NhYHTp0yKs6Zs+erYSEBKWnpzs9v27dOkVERGjMmDH2Y4Zh6KGHHtLUqVOVkpKir7/+2uN1Fi9erIULF3rVJgAAvBUaYqoX1HqbaM2dzmGhOl9V63M9njKoAwAA91p09vIlS5Zo48aN2rVrl8xm5w8oa9euVUZGhsP5FStWqKKiwmGE3ZO5c+cqMzPT/rm8vFyJiYmNbzwAAC7YEq1ZyiqdjkabJEV1bK+y79d1G1eck6Qpt1ytP733lc9t2XnopBZvO+SwrzjbkgEA4L2gJlLr1q2bQkNDVVpa6nC8tLRUcXFxbr/77LPPasmSJXr33XfVr18/p2V2796toqIi/epXv3I4vmPHDuXl5SksLEzt2rXTtddeK0lKSUnRpEmTnNYVFhamyMhIhx8AAPzBXaI12+clY25U9oRBiotyfOkcF2VW9oRBmnHrdR4zpIeYPCdye6PghEPALZFoDQCAhmgWidRSU1O1YsUKSZcTqfXq1UszZsxwmUht2bJlevrpp/XOO+9o6NChLut+6KGHVFhYqE8++cTh+PHjxx3WZJ84cUIjRozQP/7xD6Wlpalnz54e200iNQCAv7lKtFZ3lNnd1O+cwhJNW58vyflo+KM/6a3VHxyrd94bVyZaYwo6AKCtaRGJ1CQpMzNTkyZNUkpKilJTU/XCCy/owoULmjx5siRp4sSJ6tGjhxYvXixJWrp0qebPn68NGzYoKSlJFotFktS5c2d17tzZXm95ebk2b96s5557rt41e/Xq5fDZ9r1rrrnGq4AbAIBAcJVorW4w62xNeN3vZ08YVC9wj6sTuA/sFe00sB83JNHt9PS6idbKLlV7fDkAAEBbFfSg+/7779epU6c0f/58WSwWDRgwQDk5OfbkasePH1dIyA+z4LOzs1VdXa177rnHoZ6srCwtWLDA/nnjxo0yDEPjx48PyH0AAOAP7oJqb3gK3H3NoP7bzQUqPldZ77htCnr2hEEE3gCANi3o08tbKqaXAwBas7wjZzR+zR6f6mCvbwBAa+ZtTBjURGoAAKB5smVQd5uIzUMddaegAwDQVhF0AwCAejxlUDdJmnRTkld12fb6zjtyRm8WFCvvyBnVWploBwBoG4K+phsAADRPnhKxRYV30Kv/72uP9Xx89IyWbDtEojUAQJvEmu5GYk03AKCtcLUdWK3V0M1Ld8hSVtmoLcckkWgNANBisaYbAAA0CVsG9V8M6KFh13S1J0VzNwXdE1uQvnDLAaaaAwBaNYJuAADQaLYp6HFRZofj8VFm/ea2a91+t26iNU9rvlkTDgBoqVjTDQAAfOLrXt/bD1iU+fcCl2u+cwpL6q0rZ004AKClYE13I7GmGwAA93zZ69s2Xf3Rn/TW6g+O1VszzppwAECwsaYbAAAElTd7fbtifP/jLOC2nZdYEw4AaP4IugEAgF942uvbG+7C6bprwgEAaK4IugEAgN+4SrQWF2XWI8OTmuQaJysqPRcCACBISKQGAAD8ylWitb3HzuqVj772uf6vT1+U5Ho/cQAAgomgGwAA+J1tr++6bGu+LWWVLqeRh5gkw3A/zfxP732pPUfP6Ojp8yotr7IfJ8M5AKA5YHo5AAAICk9rvk2SptzS2+X5uvKOnnEIuCXJUlapaevzlVNY0lRNBgCgwQi6AQBA0Lhb8509YZDm3pXs+nzGIC0de6PLpGxXZjivtRrKO3JGbxYUK+/IGbKeAwACgunlAAAgqFyt+batx3Z3Pu/IGa8ynK/ccVgb9x1XSdkPSdeYfg4ACASTYRi85m0EbzdCBwAA/vNmQbFmbSxo1HdtI+TZEwZpZN/4JknERjI3AGg7vI0JGekGAAAtVvcIs+dCLhi6HHgv3HJAVqu0aOsBn0bCcwpLtHCLb3UAAFrfC0xGuhuJkW4AAIKv1mro5qU73GZAb6wrR8Jt13P2IJhTWKJp6/PrtcFZHe60tgdNAGiolvQC09uYkKC7kQi6AQBoHmwBr+S4tZhJ7rca84ZJl5O2fTj7Vm0/YHH6IDjv7j5atPWgw3FXdUhyGVS3pAdNAPCHpnqBGSgE3X5G0A0AQPPhKmAdNyRRf3rvK5/rfyA1Ua/t/cbpg6C3D1JPpP/IZTI3SS3qQdNXjOgDuJJt5pI3LzCby+8Lgm4/I+gGAKB5cRbISfLb9POmYAvau3Rsr3MXa1yWaW4Pmr4EzYzoA3D2O2TvsbMav2aPx+++NmWohl3TNQCt9IxEagAAoE0JDTE5fRDLGpWsaevz641KN8X0c1/Zru8q4LaVKSmr1N5jZ5vkQdPXUWZfgmZXU0ctZZWatj6/1Y3oA6jP2e+QuCizBiR28er7Jyucj4Q3ZyHBbgAAAIA/jewbr+wJgxQX5ZjpPC7KrJceGKj4KLPchZzh7ZvH41JTPGjmFJbo5qU7NH7NHs3aWKDxa/bo5qU7lFNY4vX3p63Przf90xY0u6un1mpo4ZYDTl902I4t3HJAtdZgvwoB4Itaq6G8I2f0ZkGx8o6ccfh/2t3vkJxCi1f1+7JrRbAw0g0AAFq9kX3jdXtynNMR3pAQk8uRcEma+tNrvF4X7s/RdF8fNH0dZfYUNNu2X7s9Oc7pyPneY2ddrtW01VF3RJ9130Dz5O7/TXczYW5PjnP5O8QbtqU2tqVDLQlBNwAAaBNcTT+3jYQ7m+5oe1DcuO8bl+vCbQ+C8+5OrrfXd1wTJXMLbx+qwVdFe1XW1dp2XwJmqWFBs219Zt02nCz3bqT+ZEUl676BIGpsUC05TwhpKavU1PX5uu36/3L7O6QuVy9Bs0Ylt8iXbyRSayQSqQEA0Lp4etB0tS2Z9EN28cYkczNJiurYXmXfr+t29WA2ZmAPLb+3v6SGbzvmbeD/2pShTgPm0BCTXsz9Ss9v/9JjHQ8Nu0rvHCh1aEPXTh3UPtQkS3mVx+/37tpRx85crHc8GHueM9qOtqYxQbU3CSEb4uHhSdpWaGkRL93IXu5nBN0AALQtTZFATHIdtEuqV390x/Yqu1Qj25LI1KRoHT97SZZy7x+IG2LyTVcp5wvHgDk2MkzJ8ZHaWXTKh5qbhreZ3JtipNybOgjKL2stfw6BuA9P1whmG9ztkd2UQbUn7l7+NTcE3X5G0A0AQNvj762ynNX/3sFSTf9bvr5zkWAs0A/EvggxSVbD9dr3TmGhulBV67Eedw/l7gIHybuRcm/qkOq/JGloYN8agtXWshQgEC9ZPF0jEH+Wrq4x7+4+WrT1oNfTvxurc1g7Xaj6zu1Snea0PaInBN1+RtANAAAaqrEP7e8UWvTr9fsD0EL3fjkwQW98ekJS4xPGPZH+I23cd9xpYHG+6jv9dvO/Pdbhavqpp8DBm4f6Wquhm5fucFuHbTmAr4F9cwlWG9svm+IFR3MQiJcsnq7x6E96a/UHx/z6Z+mqDYH0RPqP9MJ7l5epuFuq01IQdPsZQTcAAAiUvCNnNH7Nniapy5cM669NGaqyS9VOg4+7+sbplY++9ljHn8cN0P/ql+A0yGvK+3TH3Ui5r22oG9hLztffNyRY9XV01dP3GzvCK8njy4mWMGoZiJcsnq7hiTd9qu61nJ33tQ2+qnsP2w9Yms0LJ195GxOSvRwAAKCZa4o9uiXno8xxDQiYT1ZU6hcDejjdfm3vsbNe1dE9wuwyk3xq7xjFR5ldJp1rKm9+WqzMvxfUe+j/1S1X68OvfFu7bsvivnLHYacj+rbReG8yyXsTnDQ207RtOrOnbeQk5yO844YkNmgLuObKm6z8rpZtXPn3Zavvyr+LvcfO+BTseupT3kxPNwz5NeB2lxDyyszj7rZwbK0Y6W4kRroBAECg+Hv0de+xs17V/9qUoS4DKNtImqet1bxJguYs6Vxr0JBZBSlXddEn/znntA7J85RnyXWmaUla9cBAj1PxXY3wNoS7mQ11+ZpgrLHn//L+ES3edsiHO7zM1bKJ+4ckakvBCR05fcHnazjjaXp63XK+/D16E1Q3Va6DloTp5X5G0A0AAALFm4DWmwdiVw+9/g6YG7pe09WInbcj8m1BpLmdKirrJ6SyBVeR5nYqr/zO5fdDQ6Raqz9beNl9KT21+6vTboMwXxOMNeZ8XGSYBvaK1rsHLAH5c/A3k0lqqqjO1R7Z3gbVrSFBoLcIuv2MoBsAAARSY7cda8ptzXwJmBs60uXswd3bEXlbuxu7dn3aT6/Wy+8flVzU0aUJRoDbsiv7rC8Jxhp7PtBs66pdCfk+aPZnO83tQ1RZ4/wNg+3F2ry7k7VoK0G1twi6/YygGwAABJq/tzXyZ8DcFA/l3o7IuwocGpLsLaxdiMep21LjA3tXTJIiwtup/JLrUermprH3Hd4+RIbkMhD0pm7bNnQuv+/FCPDIvrF6p7BUkv9esjx+23X6c+5XTq8h/fBywFUbmsLDw5P06vf9392LNYJq7xF0+xlBNwAACAZ/PxA39wdub0fkfRkpt61db0ySsnFDEvWn977y6l5cTeN9PP06r+vwRUynDvr2QrVPQZ3LtcwpiXoh1//30BTcZeVvqpcsnl7kuJsm35A+5Y6n+2yNa679jaDbzwi6AQAAgqOxI/JNtXa9bn2uttJq7Gh81qhk3Z4c57YOX9Vtw/QNroNJdyO8npLzvf3vE5q1scAPrW96fx43QL8Y0MOvL1m8eZEjNa5PSe6np1/Zr5v7i7WWpEUF3atWrdLy5ctlsVjUv39/rVixQqmpqU7LrlmzRn/9619VWFgoSRo8eLCeeeYZh/Imk/NOs2zZMv3ud7/T119/rUWLFmnHjh2yWCxKSEjQhAkT9NRTT6lDhw5etZmgGwAAIHgaGzg01dr1priGpyDP3eiqp4DY28R67l5gSK5HeOvW4Uyg9lxvCu6y8tfly0sWX/cr99Sn3E1Pl5qmX6O+FhN0b9q0SRMnTtTLL7+stLQ0vfDCC9q8ebOKiorUvXv3euUzMjI0fPhw3XTTTTKbzVq6dKlef/11ffHFF+rRo4ckyWKxOHxn27ZteuSRR3T48GFdffXVysnJ0aZNmzR+/Hhde+21Kiws1JQpU/Tggw/q2Wef9ardBN0AAAAtU1OtXff3NXwNiCXvEuv5ste3K97MKoiNDJNkUml540ZwfT0fqIC4qQJeX7O4o+m1mKA7LS1NQ4YM0cqVKyVJVqtViYmJmjlzpubMmePx+7W1tYqOjtbKlSs1ceJEp2VGjx6tiooK5ebmuqxn+fLlys7O1tGjR71qN0E3AABAyxWIKbZNcQ1fA2J/t8EdbzPu+zKC6+v5QAXETcXX/crRtLyNCdsFsE31VFdXa//+/Zo7d679WEhIiNLT05WXl+dVHRcvXlRNTY1iYmKcni8tLdXWrVu1bt06t/WUlZW5rEOSqqqqVFVVZf9cXl7uVfsAAADQ/ISGmLyaUhzsa7irY2TfeN2eHOc2yPJ3G9wZ2Tde2RMG1d8j+4pg1FOZgb2i/Xq+KXjzd9EUPP1dBKJfo+GCGnSfPn1atbW1io2NdTgeGxurQ4cOeVXH7NmzlZCQoPT0dKfn161bp4iICI0ZM8ZlHYcPH9aKFSvcTi1fvHixFi5c6FWbAAAAgEBo7kGWN8GopzL+Pt9UmvvfBYInqEG3r5YsWaKNGzdq165dMpvNTsusXbtWGRkZLs8XFxdr5MiRuvfeezVlyhSX15o7d64yMzPtn8vLy5WYmOjbDQAAAACtnDfBqK8juIwAozkLatDdrVs3hYaGqrS01OF4aWmp4uLi3H732Wef1ZIlS/Tee++pX79+Tsvs3r1bRUVF2rRpk9PzJ06c0M9//nPddNNNWr16tdvrhYWFKSwszG0ZAAAAAADqCgnmxTt06KDBgwc7JDizWq3Kzc3VsGHDXH5v2bJlWrRokXJycpSSkuKy3CuvvKLBgwerf//+9c4VFxfrZz/7mQYPHqxXX31VISFB/aMAAAAAALRCQZ9enpmZqUmTJiklJUWpqal64YUXdOHCBU2ePFmSNHHiRPXo0UOLFy+WJC1dulTz58/Xhg0blJSUZN8erHPnzurcubO93vLycm3evFnPPfdcvWvaAu6rrrpKzz77rE6dOmU/52mEHQAAAAAAbwU96L7//vt16tQpzZ8/XxaLRQMGDFBOTo49udrx48cdRqGzs7NVXV2te+65x6GerKwsLViwwP5548aNMgxD48ePr3fN7du36/Dhwzp8+LB69uzpcC7IO6gBAAAAAFqRoO/T3VKxTzcAAAAAtF3exoQsZAYAAAAAwE8IugEAAAAA8BOCbgAAAAAA/ISgGwAAAAAAPyHoBgAAAADATwi6AQAAAADwk6Dv091S2XZaKy8vD3JLAAAAAACBZosFPe3CTdDdSBUVFZKkxMTEILcEAAAAABAsFRUVioqKcnneZHgKy+GU1WrViRMnFBERIZPJFJQ2lJeXKzExUd98843bzdiBQKFPojmiX6K5oU+iOaJforlpCX3SMAxVVFQoISFBISGuV24z0t1IISEh6tmzZ7CbIUmKjIxsth0RbRN9Es0R/RLNDX0SzRH9Es1Nc++T7ka4bUikBgAAAACAnxB0AwAAAADgJwTdLVhYWJiysrIUFhYW7KYAkuiTaJ7ol2hu6JNojuiXaG5aU58kkRoAAAAAAH7CSDcAAAAAAH5C0A0AAAAAgJ8QdAMAAAAA4CcE3S3UqlWrlJSUJLPZrLS0NO3duzfYTUIbsXjxYg0ZMkQRERHq3r27Ro8eraKiIocylZWVmj59urp27arOnTtr7NixKi0tDVKL0RYtWbJEJpNJjz/+uP0Y/RKBVlxcrAkTJqhr164KDw/XjTfeqE8++cR+3jAMzZ8/X/Hx8QoPD1d6erq++uqrILYYrV1tba3mzZun3r17Kzw8XNdcc40WLVqkuime6Jfwpw8++ECjRo1SQkKCTCaT3njjDYfz3vS/s2fPKiMjQ5GRkerSpYseeeQRnT9/PoB30XAE3S3Qpk2blJmZqaysLOXn56t///4aMWKETp48GeymoQ14//33NX36dO3Zs0fbt29XTU2N7rjjDl24cMFe5oknntCWLVu0efNmvf/++zpx4oTGjBkTxFajLdm3b5/+8pe/qF+/fg7H6ZcIpG+//VbDhw9X+/bttW3bNh04cEDPPfecoqOj7WWWLVumF198US+//LI+/vhjderUSSNGjFBlZWUQW47WbOnSpcrOztbKlSt18OBBLV26VMuWLdOKFSvsZeiX8KcLFy6of//+WrVqldPz3vS/jIwMffHFF9q+fbvefvttffDBB3r00UcDdQuNY6DFSU1NNaZPn27/XFtbayQkJBiLFy8OYqvQVp08edKQZLz//vuGYRjGuXPnjPbt2xubN2+2lzl48KAhycjLywtWM9FGVFRUGNddd52xfft246c//akxa9YswzDolwi82bNnGzfffLPL81ar1YiLizOWL19uP3bu3DkjLCzMeO211wLRRLRBd999t/Hwww87HBszZoyRkZFhGAb9EoElyXj99dftn73pfwcOHDAkGfv27bOX2bZtm2EymYzi4uKAtb2hGOluYaqrq7V//36lp6fbj4WEhCg9PV15eXlBbBnaqrKyMklSTEyMJGn//v2qqalx6KPXX3+9evXqRR+F302fPl133323Q/+T6JcIvLfeekspKSm699571b17dw0cOFBr1qyxnz927JgsFotDn4yKilJaWhp9En5z0003KTc3V19++aUk6bPPPtOHH36oO++8UxL9EsHlTf/Ly8tTly5dlJKSYi+Tnp6ukJAQffzxxwFvs7faBbsBaJjTp0+rtrZWsbGxDsdjY2N16NChILUKbZXVatXjjz+u4cOHq2/fvpIki8WiDh06qEuXLg5lY2NjZbFYgtBKtBUbN25Ufn6+9u3bV+8c/RKBdvToUWVnZyszM1NPPvmk9u3bp9/85jfq0KGDJk2aZO93zv49p0/CX+bMmaPy8nJdf/31Cg0NVW1trZ5++mllZGRIEv0SQeVN/7NYLOrevbvD+Xbt2ikmJqZZ91GCbgCNNn36dBUWFurDDz8MdlPQxn3zzTeaNWuWtm/fLrPZHOzmALJarUpJSdEzzzwjSRo4cKAKCwv18ssva9KkSUFuHdqqv//97/rb3/6mDRs26IYbblBBQYEef/xxJSQk0C8BP2J6eQvTrVs3hYaG1su4W1paqri4uCC1Cm3RjBkz9Pbbb2vnzp3q2bOn/XhcXJyqq6t17tw5h/L0UfjT/v37dfLkSQ0aNEjt2rVTu3bt9P777+vFF19Uu3btFBsbS79EQMXHxys5OdnhWJ8+fXT8+HFJsvc7/j1HIP3ud7/TnDlzNG7cON1444168MEH9cQTT2jx4sWS6JcILm/6X1xcXL3k0d99953Onj3brPsoQXcL06FDBw0ePFi5ubn2Y1arVbm5uRo2bFgQW4a2wjAMzZgxQ6+//rp27Nih3r17O5wfPHiw2rdv79BHi4qKdPz4cfoo/Oa2227T559/roKCAvtPSkqKMjIy7P9Nv0QgDR8+vN52il9++aWuuuoqSVLv3r0VFxfn0CfLy8v18ccf0yfhNxcvXlRIiOPjf2hoqKxWqyT6JYLLm/43bNgwnTt3Tvv377eX2bFjh6xWq9LS0gLeZm8xvbwFyszM1KRJk5SSkqLU1FS98MILunDhgiZPnhzspqENmD59ujZs2KA333xTERER9vUzUVFRCg8PV1RUlB555BFlZmYqJiZGkZGRmjlzpoYNG6ahQ4cGufVorSIiIux5BWw6deqkrl272o/TLxFITzzxhG666SY988wzuu+++7R3716tXr1aq1evliT7PvJ//OMfdd1116l3796aN2+eEhISNHr06OA2Hq3WqFGj9PTTT6tXr1664YYb9Omnn+r555/Xww8/LIl+Cf87f/68Dh8+bP987NgxFRQUKCYmRr169fLY//r06aORI0dqypQpevnll1VTU6MZM2Zo3LhxSkhICNJdeSHY6dPROCtWrDB69epldOjQwUhNTTX27NkT7CahjZDk9OfVV1+1l7l06ZLx2GOPGdHR0UbHjh2NX/7yl0ZJSUnwGo02qe6WYYZBv0Tgbdmyxejbt68RFhZmXH/99cbq1asdzlutVmPevHlGbGysERYWZtx2221GUVFRkFqLtqC8vNyYNWuW0atXL8NsNhtXX3218dRTTxlVVVX2MvRL+NPOnTudPkdOmjTJMAzv+t+ZM2eM8ePHG507dzYiIyONyZMnGxUVFUG4G++ZDMMwghTvAwAAAADQqrGmGwAAAAAAPyHoBgAAAADATwi6AQAAAADwE4JuAAAAAAD8hKAbAAAAAAA/IegGAAAAAMBPCLoBAAAAAPATgm4AAAAAAPyEoBsAAASUyWTSG2+8EexmAAAQEATdAAC0IQ899JBMJlO9n5EjRwa7aQAAtErtgt0AAAAQWCNHjtSrr77qcCwsLCxIrQEAoHVjpBsAgDYmLCxMcXFxDj/R0dGSLk/9zs7O1p133qnw8HBdffXV+sc//uHw/c8//1y33nqrwsPD1bVrVz366KM6f/68Q5m1a9fqhhtuUFhYmOLj4zVjxgyH86dPn9Yvf/lLdezYUdddd53eeust/940AABBQtANAAAczJs3T2PHjtVnn32mjIwMjRs3TgcPHpQkXbhwQSNGjFB0dLT27dunzZs367333nMIqrOzszV9+nQ9+uij+vzzz/XWW2/p2muvdbjGwoULdd999+nf//637rrrLmVkZOjs2bMBvU8AAALBZBiGEexGAACAwHjooYe0fv16mc1mh+NPPvmknnzySZlMJk2dOlXZ2dn2c0OHDtWgQYP00ksvac2aNZo9e7a++eYbderUSZL0r3/9S6NGjdKJEycUGxurHj16aPLkyfrjH//otA0mk0l/+MMftGjRIkmXA/nOnTtr27ZtrC0HALQ6rOkGAKCN+fnPf+4QVEtSTEyM/b+HDRvmcG7YsGEqKCiQJB08eFD9+/e3B9ySNHz4cFmtVhUVFclkMunEiRO67bbb3LahX79+9v/u1KmTIiMjdfLkycbeEgAAzRZBNwAAbUynTp3qTfduKuHh4V6Va9++vcNnk8kkq9XqjyYBABBUrOkGAAAO9uzZU+9znz59JEl9+vTRZ599pgsXLtjPf/TRRwoJCdGPf/xjRUREKCkpSbm5uQFtMwAAzRUj3QAAtDFVVVWyWCwOx9q1a6du3bpJkjZv3qyUlBTdfPPN+tvf/qa9e/fqlVdekSRlZGQoKytLkyZN0oIFC3Tq1CnNnDlTDz74oGJjYyVJCxYs0NSpU9W9e3fdeeedqqio0EcffaSZM2cG9kYBAGgGCLoBAGhjcnJyFB8f73Dsxz/+sQ4dOiTpcmbxjRs36rHHHlN8fLxee+01JScnS5I6duyod955R7NmzdKQIUPUsWNHjR07Vs8//7y9rkmTJqmyslJ/+tOf9Nvf/lbdunXTPffcE7gbBACgGSF7OQAAsDOZTHr99dc1evToYDcFAIBWgTXdAAAAAAD4CUE3AAAAAAB+wppuAABgx6ozAACaFiPdAAAAAAD4CUE3AAAAAAB+QtANAAAAAICfEHQDAAAAAOAnBN0AAAAAAPgJQTcAAAAAAH5C0A0AAAAAgJ8QdAMAAAAA4CcE3QAAAAAA+Mn/BzcXfbowwND7AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('MLP_Best.csv')\n",
        "loss = df['eval_loss'].tolist()\n",
        "\n",
        "loss_2 = trainer.history\n",
        "with open('MLP_Worst.csv', 'w') as f:\n",
        "    pd.DataFrame(loss_2).to_csv(f, index=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(\n",
        "    history1, \n",
        "    history2, \n",
        "    label1='Train Loss 1', \n",
        "    label2='Train Loss 2',\n",
        "    figsize=(8, 6),\n",
        "    fmt1='-',\n",
        "    fmt2='-',\n",
        "    title='Training Loss Curves',\n",
        "    xlabel='Epoch',\n",
        "    ylabel='Loss',\n",
        "    plot_kwargs1=None,\n",
        "    plot_kwargs2=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots two training loss curves on the same figure with adjustable format and size.\n",
        "\n",
        "    Parameters:\n",
        "    - history1: dict with key 'train_loss' containing loss values per epoch\n",
        "    - history2: dict with key 'train_loss' containing loss values per epoch\n",
        "    - label1: label for the first loss curve\n",
        "    - label2: label for the second loss curve\n",
        "    - figsize: tuple specifying figure size (width, height) in inches\n",
        "    - fmt1: format string for the first curve (e.g. '-', '--', 'o-')\n",
        "    - fmt2: format string for the second curve\n",
        "    - title: title of the plot\n",
        "    - xlabel: label for the x-axis\n",
        "    - ylabel: label for the y-axis\n",
        "    - plot_kwargs1: dict of additional keyword arguments for the first plt.plot call\n",
        "    - plot_kwargs2: dict of additional keyword arguments for the second plt.plot call\n",
        "    \"\"\"\n",
        "    plot_kwargs1 = plot_kwargs1 or {}\n",
        "    plot_kwargs2 = plot_kwargs2 or {}\n",
        "\n",
        "    epochs1 = range(1, len(history1) + 1)\n",
        "    epochs2 = range(1, len(history2) + 1)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(epochs1, history1, fmt1, label=label1, **plot_kwargs1)\n",
        "    plt.plot(epochs2, history2, fmt2, label=label2, **plot_kwargs2)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_loss_curves(\n",
        "    loss, \n",
        "    loss_2, \n",
        "    label1='Without Parameter Tuning', \n",
        "    label2='After Parameter Tuning',\n",
        "    figsize=(10, 5),\n",
        "    fmt1='-o',\n",
        "    fmt2='-s',\n",
        "    title='MLP Training Loss',\n",
        "    plot_kwargs1={'linewidth':2},\n",
        "    plot_kwargs2={'linewidth':2, 'markerfacecolor':'none'}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "6c690761",
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "from MLP import MLPModel\n",
        "from ModelTrainer import ModelTrainer\n",
        "from losses import fluctuation_loss\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [128, 256, 512])\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
        "    alpha = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n",
        "\n",
        "    # Build hidden layers\n",
        "    hidden_layers = [hidden_dim] * n_layers\n",
        "\n",
        "    # Build model\n",
        "    model = MLPModel(input_shape=len(x_train_mlp[1]), output_shape=len(y_train_mlp[1]), hidden_layers=hidden_layers).get_model().to(device)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = ModelTrainer(\n",
        "        model=model,\n",
        "        features_training_data=x_train_mlp,\n",
        "        target_training_data=y_train_mlp,\n",
        "        features_eval_data=x_val_mlp,\n",
        "        target_eval_data=y_val_mlp,\n",
        "        device=device,\n",
        "        loss_fn=lambda pred, target: fluctuation_loss(pred, target, alpha=alpha)\n",
        "    )\n",
        "\n",
        "    # Train for a few epochs\n",
        "    trainer.train(epochs=50, batch_size=32, patience=10, learning_rate=lr)\n",
        "\n",
        "    # Return final eval loss (or early stopping best)\n",
        "    return trainer.history['eval_loss'][-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "43d4194c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:27:28,155] A new study created in memory with name: no-name-17c2a3e8-cce5-4992-ba32-383d6574a8a2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_4054947/1319189539.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-3)\n",
            "/ephnvme/weiliang/cache/tmpdir/ipykernel_4054947/1319189539.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  alpha = trial.suggest_uniform(\"alpha\", 0.1, 0.5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 0.7915, Eval Loss = 0.2956\n",
            "Epoch 2: Train Loss = 0.6538, Eval Loss = 0.2941\n",
            "Epoch 3: Train Loss = 0.6367, Eval Loss = 0.2920\n",
            "Epoch 4: Train Loss = 0.6199, Eval Loss = 0.2931\n",
            "Epoch 5: Train Loss = 0.6098, Eval Loss = 0.2907\n",
            "Epoch 6: Train Loss = 0.5982, Eval Loss = 0.2894\n",
            "Epoch 7: Train Loss = 0.5809, Eval Loss = 0.2879\n",
            "Epoch 8: Train Loss = 0.5561, Eval Loss = 0.2867\n",
            "Epoch 9: Train Loss = 0.5317, Eval Loss = 0.2849\n",
            "Epoch 10: Train Loss = 0.5053, Eval Loss = 0.2852\n",
            "Epoch 11: Train Loss = 0.4822, Eval Loss = 0.2840\n",
            "Epoch 12: Train Loss = 0.4616, Eval Loss = 0.2846\n",
            "Epoch 13: Train Loss = 0.4406, Eval Loss = 0.2844\n",
            "Epoch 14: Train Loss = 0.4235, Eval Loss = 0.2836\n",
            "Epoch 15: Train Loss = 0.4103, Eval Loss = 0.2834\n",
            "Epoch 16: Train Loss = 0.3875, Eval Loss = 0.2830\n",
            "Epoch 17: Train Loss = 0.3834, Eval Loss = 0.2833\n",
            "Epoch 18: Train Loss = 0.3749, Eval Loss = 0.2846\n",
            "Epoch 19: Train Loss = 0.3706, Eval Loss = 0.2851\n",
            "Epoch 20: Train Loss = 0.3681, Eval Loss = 0.2850\n",
            "Epoch 21: Train Loss = 0.3627, Eval Loss = 0.2854\n",
            "Epoch 22: Train Loss = 0.3604, Eval Loss = 0.2862\n",
            "Epoch 23: Train Loss = 0.3498, Eval Loss = 0.2870\n",
            "Epoch 24: Train Loss = 0.3471, Eval Loss = 0.2884\n",
            "Epoch 25: Train Loss = 0.3427, Eval Loss = 0.2884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:28:27,356] Trial 0 finished with value: 0.2882169187068939 and parameters: {'hidden_dim': 128, 'n_layers': 4, 'lr': 0.00016287499695007422, 'alpha': 0.4054719478439285}. Best is trial 0 with value: 0.2882169187068939.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss = 0.3412, Eval Loss = 0.2882\n",
            "Early stopping triggered at epoch 26\n",
            "Epoch 1: Train Loss = 1.0502, Eval Loss = 0.2890\n",
            "Epoch 2: Train Loss = 0.8330, Eval Loss = 0.2866\n",
            "Epoch 3: Train Loss = 0.7250, Eval Loss = 0.2856\n",
            "Epoch 4: Train Loss = 0.6771, Eval Loss = 0.2859\n",
            "Epoch 5: Train Loss = 0.6681, Eval Loss = 0.2853\n",
            "Epoch 6: Train Loss = 0.6259, Eval Loss = 0.2855\n",
            "Epoch 7: Train Loss = 0.6093, Eval Loss = 0.2855\n",
            "Epoch 8: Train Loss = 0.5981, Eval Loss = 0.2848\n",
            "Epoch 9: Train Loss = 0.5869, Eval Loss = 0.2849\n",
            "Epoch 10: Train Loss = 0.5763, Eval Loss = 0.2849\n",
            "Epoch 11: Train Loss = 0.5674, Eval Loss = 0.2845\n",
            "Epoch 12: Train Loss = 0.5582, Eval Loss = 0.2837\n",
            "Epoch 13: Train Loss = 0.5501, Eval Loss = 0.2835\n",
            "Epoch 14: Train Loss = 0.5422, Eval Loss = 0.2832\n",
            "Epoch 15: Train Loss = 0.5329, Eval Loss = 0.2829\n",
            "Epoch 16: Train Loss = 0.5267, Eval Loss = 0.2826\n",
            "Epoch 17: Train Loss = 0.5194, Eval Loss = 0.2823\n",
            "Epoch 18: Train Loss = 0.5113, Eval Loss = 0.2823\n",
            "Epoch 19: Train Loss = 0.5113, Eval Loss = 0.2819\n",
            "Epoch 20: Train Loss = 0.4966, Eval Loss = 0.2816\n",
            "Epoch 21: Train Loss = 0.4968, Eval Loss = 0.2820\n",
            "Epoch 22: Train Loss = 0.4843, Eval Loss = 0.2818\n",
            "Epoch 23: Train Loss = 0.4768, Eval Loss = 0.2815\n",
            "Epoch 24: Train Loss = 0.4718, Eval Loss = 0.2815\n",
            "Epoch 25: Train Loss = 0.4651, Eval Loss = 0.2812\n",
            "Epoch 26: Train Loss = 0.4607, Eval Loss = 0.2816\n",
            "Epoch 27: Train Loss = 0.4542, Eval Loss = 0.2814\n",
            "Epoch 28: Train Loss = 0.4483, Eval Loss = 0.2814\n",
            "Epoch 29: Train Loss = 0.4432, Eval Loss = 0.2816\n",
            "Epoch 30: Train Loss = 0.4385, Eval Loss = 0.2818\n",
            "Epoch 31: Train Loss = 0.4325, Eval Loss = 0.2819\n",
            "Epoch 32: Train Loss = 0.4284, Eval Loss = 0.2817\n",
            "Epoch 33: Train Loss = 0.4237, Eval Loss = 0.2817\n",
            "Epoch 34: Train Loss = 0.4193, Eval Loss = 0.2821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:29:54,127] Trial 1 finished with value: 0.282134085893631 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 1.210530981218894e-05, 'alpha': 0.38457813283897857}. Best is trial 1 with value: 0.282134085893631.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: Train Loss = 0.4144, Eval Loss = 0.2821\n",
            "Early stopping triggered at epoch 35\n",
            "Epoch 1: Train Loss = 0.8146, Eval Loss = 0.3039\n",
            "Epoch 2: Train Loss = 0.7186, Eval Loss = 0.3010\n",
            "Epoch 3: Train Loss = 0.7052, Eval Loss = 0.3002\n",
            "Epoch 4: Train Loss = 0.6701, Eval Loss = 0.2999\n",
            "Epoch 5: Train Loss = 0.6761, Eval Loss = 0.3017\n",
            "Epoch 6: Train Loss = 0.6525, Eval Loss = 0.3028\n",
            "Epoch 7: Train Loss = 0.6107, Eval Loss = 0.3083\n",
            "Epoch 8: Train Loss = 0.6041, Eval Loss = 0.3087\n",
            "Epoch 9: Train Loss = 0.5698, Eval Loss = 0.3071\n",
            "Epoch 10: Train Loss = 0.5655, Eval Loss = 0.3089\n",
            "Epoch 11: Train Loss = 0.5486, Eval Loss = 0.3073\n",
            "Epoch 12: Train Loss = 0.5111, Eval Loss = 0.3099\n",
            "Epoch 13: Train Loss = 0.5046, Eval Loss = 0.3097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:30:25,846] Trial 2 finished with value: 0.3071444630622864 and parameters: {'hidden_dim': 128, 'n_layers': 4, 'lr': 0.0005800169261252493, 'alpha': 0.4989992300998197}. Best is trial 1 with value: 0.282134085893631.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.4948, Eval Loss = 0.3071\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.6423, Eval Loss = 0.2430\n",
            "Epoch 2: Train Loss = 0.5103, Eval Loss = 0.2396\n",
            "Epoch 3: Train Loss = 0.4713, Eval Loss = 0.2341\n",
            "Epoch 4: Train Loss = 0.4271, Eval Loss = 0.2347\n",
            "Epoch 5: Train Loss = 0.3735, Eval Loss = 0.2331\n",
            "Epoch 6: Train Loss = 0.3368, Eval Loss = 0.2324\n",
            "Epoch 7: Train Loss = 0.2983, Eval Loss = 0.2318\n",
            "Epoch 8: Train Loss = 0.2751, Eval Loss = 0.2314\n",
            "Epoch 9: Train Loss = 0.2654, Eval Loss = 0.2316\n",
            "Epoch 10: Train Loss = 0.2560, Eval Loss = 0.2307\n",
            "Epoch 11: Train Loss = 0.2535, Eval Loss = 0.2303\n",
            "Epoch 12: Train Loss = 0.2391, Eval Loss = 0.2331\n",
            "Epoch 13: Train Loss = 0.2284, Eval Loss = 0.2331\n",
            "Epoch 14: Train Loss = 0.2263, Eval Loss = 0.2339\n",
            "Epoch 15: Train Loss = 0.2299, Eval Loss = 0.2339\n",
            "Epoch 16: Train Loss = 0.2210, Eval Loss = 0.2353\n",
            "Epoch 17: Train Loss = 0.2100, Eval Loss = 0.2368\n",
            "Epoch 18: Train Loss = 0.2080, Eval Loss = 0.2381\n",
            "Epoch 19: Train Loss = 0.2120, Eval Loss = 0.2382\n",
            "Epoch 20: Train Loss = 0.2050, Eval Loss = 0.2397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:31:35,965] Trial 3 finished with value: 0.24059619009494781 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 9.623680283957342e-05, 'alpha': 0.1066092381769956}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss = 0.1948, Eval Loss = 0.2406\n",
            "Early stopping triggered at epoch 21\n",
            "Epoch 1: Train Loss = 0.9345, Eval Loss = 0.2553\n",
            "Epoch 2: Train Loss = 0.6636, Eval Loss = 0.2538\n",
            "Epoch 3: Train Loss = 0.5786, Eval Loss = 0.2536\n",
            "Epoch 4: Train Loss = 0.5463, Eval Loss = 0.2547\n",
            "Epoch 5: Train Loss = 0.5272, Eval Loss = 0.2548\n",
            "Epoch 6: Train Loss = 0.5143, Eval Loss = 0.2536\n",
            "Epoch 7: Train Loss = 0.5027, Eval Loss = 0.2535\n",
            "Epoch 8: Train Loss = 0.4913, Eval Loss = 0.2532\n",
            "Epoch 9: Train Loss = 0.4810, Eval Loss = 0.2523\n",
            "Epoch 10: Train Loss = 0.4711, Eval Loss = 0.2519\n",
            "Epoch 11: Train Loss = 0.4603, Eval Loss = 0.2512\n",
            "Epoch 12: Train Loss = 0.4481, Eval Loss = 0.2504\n",
            "Epoch 13: Train Loss = 0.4380, Eval Loss = 0.2488\n",
            "Epoch 14: Train Loss = 0.4265, Eval Loss = 0.2494\n",
            "Epoch 15: Train Loss = 0.4164, Eval Loss = 0.2484\n",
            "Epoch 16: Train Loss = 0.4081, Eval Loss = 0.2485\n",
            "Epoch 17: Train Loss = 0.3978, Eval Loss = 0.2474\n",
            "Epoch 18: Train Loss = 0.3897, Eval Loss = 0.2474\n",
            "Epoch 19: Train Loss = 0.3812, Eval Loss = 0.2471\n",
            "Epoch 20: Train Loss = 0.3807, Eval Loss = 0.2470\n",
            "Epoch 21: Train Loss = 0.3673, Eval Loss = 0.2472\n",
            "Epoch 22: Train Loss = 0.3589, Eval Loss = 0.2472\n",
            "Epoch 23: Train Loss = 0.3518, Eval Loss = 0.2471\n",
            "Epoch 24: Train Loss = 0.3470, Eval Loss = 0.2466\n",
            "Epoch 25: Train Loss = 0.3436, Eval Loss = 0.2469\n",
            "Epoch 26: Train Loss = 0.3348, Eval Loss = 0.2468\n",
            "Epoch 27: Train Loss = 0.3280, Eval Loss = 0.2466\n",
            "Epoch 28: Train Loss = 0.3231, Eval Loss = 0.2465\n",
            "Epoch 29: Train Loss = 0.3186, Eval Loss = 0.2467\n",
            "Epoch 30: Train Loss = 0.3130, Eval Loss = 0.2468\n",
            "Epoch 31: Train Loss = 0.3070, Eval Loss = 0.2466\n",
            "Epoch 32: Train Loss = 0.3036, Eval Loss = 0.2470\n",
            "Epoch 33: Train Loss = 0.2989, Eval Loss = 0.2468\n",
            "Epoch 34: Train Loss = 0.2950, Eval Loss = 0.2467\n",
            "Epoch 35: Train Loss = 0.2915, Eval Loss = 0.2468\n",
            "Epoch 36: Train Loss = 0.2860, Eval Loss = 0.2466\n",
            "Epoch 37: Train Loss = 0.2842, Eval Loss = 0.2467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:34:05,657] Trial 4 finished with value: 0.24665459990501404 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 1.2385076070749562e-05, 'alpha': 0.168840537424991}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: Train Loss = 0.2799, Eval Loss = 0.2467\n",
            "Early stopping triggered at epoch 38\n",
            "Epoch 1: Train Loss = 0.9461, Eval Loss = 0.2800\n",
            "Epoch 2: Train Loss = 0.6612, Eval Loss = 0.2797\n",
            "Epoch 3: Train Loss = 0.6086, Eval Loss = 0.2793\n",
            "Epoch 4: Train Loss = 0.5887, Eval Loss = 0.2784\n",
            "Epoch 5: Train Loss = 0.5756, Eval Loss = 0.2782\n",
            "Epoch 6: Train Loss = 0.5601, Eval Loss = 0.2772\n",
            "Epoch 7: Train Loss = 0.5463, Eval Loss = 0.2756\n",
            "Epoch 8: Train Loss = 0.5305, Eval Loss = 0.2743\n",
            "Epoch 9: Train Loss = 0.5104, Eval Loss = 0.2733\n",
            "Epoch 10: Train Loss = 0.4941, Eval Loss = 0.2728\n",
            "Epoch 11: Train Loss = 0.4750, Eval Loss = 0.2718\n",
            "Epoch 12: Train Loss = 0.4618, Eval Loss = 0.2716\n",
            "Epoch 13: Train Loss = 0.4460, Eval Loss = 0.2711\n",
            "Epoch 14: Train Loss = 0.4340, Eval Loss = 0.2708\n",
            "Epoch 15: Train Loss = 0.4363, Eval Loss = 0.2707\n",
            "Epoch 16: Train Loss = 0.4097, Eval Loss = 0.2706\n",
            "Epoch 17: Train Loss = 0.3977, Eval Loss = 0.2706\n",
            "Epoch 18: Train Loss = 0.3869, Eval Loss = 0.2703\n",
            "Epoch 19: Train Loss = 0.3790, Eval Loss = 0.2706\n",
            "Epoch 20: Train Loss = 0.3694, Eval Loss = 0.2703\n",
            "Epoch 21: Train Loss = 0.3621, Eval Loss = 0.2705\n",
            "Epoch 22: Train Loss = 0.3551, Eval Loss = 0.2707\n",
            "Epoch 23: Train Loss = 0.3489, Eval Loss = 0.2704\n",
            "Epoch 24: Train Loss = 0.3449, Eval Loss = 0.2703\n",
            "Epoch 25: Train Loss = 0.3385, Eval Loss = 0.2700\n",
            "Epoch 26: Train Loss = 0.3332, Eval Loss = 0.2703\n",
            "Epoch 27: Train Loss = 0.3273, Eval Loss = 0.2703\n",
            "Epoch 28: Train Loss = 0.3258, Eval Loss = 0.2702\n",
            "Epoch 29: Train Loss = 0.3215, Eval Loss = 0.2702\n",
            "Epoch 30: Train Loss = 0.3191, Eval Loss = 0.2701\n",
            "Epoch 31: Train Loss = 0.3129, Eval Loss = 0.2701\n",
            "Epoch 32: Train Loss = 0.3131, Eval Loss = 0.2701\n",
            "Epoch 33: Train Loss = 0.3081, Eval Loss = 0.2701\n",
            "Epoch 34: Train Loss = 0.3056, Eval Loss = 0.2697\n",
            "Epoch 35: Train Loss = 0.3032, Eval Loss = 0.2699\n",
            "Epoch 36: Train Loss = 0.3023, Eval Loss = 0.2699\n",
            "Epoch 37: Train Loss = 0.2971, Eval Loss = 0.2701\n",
            "Epoch 38: Train Loss = 0.2934, Eval Loss = 0.2702\n",
            "Epoch 39: Train Loss = 0.2895, Eval Loss = 0.2704\n",
            "Epoch 40: Train Loss = 0.2893, Eval Loss = 0.2706\n",
            "Epoch 41: Train Loss = 0.2855, Eval Loss = 0.2707\n",
            "Epoch 42: Train Loss = 0.2851, Eval Loss = 0.2708\n",
            "Epoch 43: Train Loss = 0.2787, Eval Loss = 0.2711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:36:05,739] Trial 5 finished with value: 0.2710748612880707 and parameters: {'hidden_dim': 256, 'n_layers': 3, 'lr': 4.269476391407439e-05, 'alpha': 0.31903545171002334}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: Train Loss = 0.2781, Eval Loss = 0.2711\n",
            "Early stopping triggered at epoch 44\n",
            "Epoch 1: Train Loss = 0.9645, Eval Loss = 0.2929\n",
            "Epoch 2: Train Loss = 0.7012, Eval Loss = 0.2949\n",
            "Epoch 3: Train Loss = 0.6438, Eval Loss = 0.2941\n",
            "Epoch 4: Train Loss = 0.6249, Eval Loss = 0.2936\n",
            "Epoch 5: Train Loss = 0.6051, Eval Loss = 0.2921\n",
            "Epoch 6: Train Loss = 0.5915, Eval Loss = 0.2906\n",
            "Epoch 7: Train Loss = 0.5731, Eval Loss = 0.2893\n",
            "Epoch 8: Train Loss = 0.5567, Eval Loss = 0.2892\n",
            "Epoch 9: Train Loss = 0.5389, Eval Loss = 0.2880\n",
            "Epoch 10: Train Loss = 0.5183, Eval Loss = 0.2873\n",
            "Epoch 11: Train Loss = 0.5061, Eval Loss = 0.2862\n",
            "Epoch 12: Train Loss = 0.4910, Eval Loss = 0.2855\n",
            "Epoch 13: Train Loss = 0.4778, Eval Loss = 0.2858\n",
            "Epoch 14: Train Loss = 0.4623, Eval Loss = 0.2849\n",
            "Epoch 15: Train Loss = 0.4531, Eval Loss = 0.2845\n",
            "Epoch 16: Train Loss = 0.4417, Eval Loss = 0.2844\n",
            "Epoch 17: Train Loss = 0.4310, Eval Loss = 0.2847\n",
            "Epoch 18: Train Loss = 0.4187, Eval Loss = 0.2849\n",
            "Epoch 19: Train Loss = 0.4126, Eval Loss = 0.2845\n",
            "Epoch 20: Train Loss = 0.4006, Eval Loss = 0.2845\n",
            "Epoch 21: Train Loss = 0.3946, Eval Loss = 0.2841\n",
            "Epoch 22: Train Loss = 0.3855, Eval Loss = 0.2843\n",
            "Epoch 23: Train Loss = 0.3792, Eval Loss = 0.2839\n",
            "Epoch 24: Train Loss = 0.3724, Eval Loss = 0.2838\n",
            "Epoch 25: Train Loss = 0.3662, Eval Loss = 0.2837\n",
            "Epoch 26: Train Loss = 0.3612, Eval Loss = 0.2834\n",
            "Epoch 27: Train Loss = 0.3550, Eval Loss = 0.2835\n",
            "Epoch 28: Train Loss = 0.3537, Eval Loss = 0.2834\n",
            "Epoch 29: Train Loss = 0.3449, Eval Loss = 0.2833\n",
            "Epoch 30: Train Loss = 0.3403, Eval Loss = 0.2830\n",
            "Epoch 31: Train Loss = 0.3374, Eval Loss = 0.2829\n",
            "Epoch 32: Train Loss = 0.3323, Eval Loss = 0.2827\n",
            "Epoch 33: Train Loss = 0.3285, Eval Loss = 0.2827\n",
            "Epoch 34: Train Loss = 0.3242, Eval Loss = 0.2826\n",
            "Epoch 35: Train Loss = 0.3217, Eval Loss = 0.2826\n",
            "Epoch 36: Train Loss = 0.3155, Eval Loss = 0.2826\n",
            "Epoch 37: Train Loss = 0.3122, Eval Loss = 0.2825\n",
            "Epoch 38: Train Loss = 0.3097, Eval Loss = 0.2824\n",
            "Epoch 39: Train Loss = 0.3047, Eval Loss = 0.2825\n",
            "Epoch 40: Train Loss = 0.3032, Eval Loss = 0.2825\n",
            "Epoch 41: Train Loss = 0.2971, Eval Loss = 0.2826\n",
            "Epoch 42: Train Loss = 0.2958, Eval Loss = 0.2825\n",
            "Epoch 43: Train Loss = 0.2909, Eval Loss = 0.2825\n",
            "Epoch 44: Train Loss = 0.2871, Eval Loss = 0.2826\n",
            "Epoch 45: Train Loss = 0.2818, Eval Loss = 0.2825\n",
            "Epoch 46: Train Loss = 0.2821, Eval Loss = 0.2824\n",
            "Epoch 47: Train Loss = 0.2759, Eval Loss = 0.2827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:39:15,488] Trial 6 finished with value: 0.28289419412612915 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 2.318354166719222e-05, 'alpha': 0.4018182652144753}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: Train Loss = 0.2710, Eval Loss = 0.2829\n",
            "Early stopping triggered at epoch 48\n",
            "Epoch 1: Train Loss = 0.7664, Eval Loss = 0.2754\n",
            "Epoch 2: Train Loss = 0.6072, Eval Loss = 0.2730\n",
            "Epoch 3: Train Loss = 0.5703, Eval Loss = 0.2711\n",
            "Epoch 4: Train Loss = 0.5411, Eval Loss = 0.2671\n",
            "Epoch 5: Train Loss = 0.5013, Eval Loss = 0.2667\n",
            "Epoch 6: Train Loss = 0.4635, Eval Loss = 0.2654\n",
            "Epoch 7: Train Loss = 0.4291, Eval Loss = 0.2643\n",
            "Epoch 8: Train Loss = 0.4037, Eval Loss = 0.2651\n",
            "Epoch 9: Train Loss = 0.3783, Eval Loss = 0.2645\n",
            "Epoch 10: Train Loss = 0.3598, Eval Loss = 0.2640\n",
            "Epoch 11: Train Loss = 0.3427, Eval Loss = 0.2639\n",
            "Epoch 12: Train Loss = 0.3315, Eval Loss = 0.2639\n",
            "Epoch 13: Train Loss = 0.3219, Eval Loss = 0.2643\n",
            "Epoch 14: Train Loss = 0.3136, Eval Loss = 0.2635\n",
            "Epoch 15: Train Loss = 0.3063, Eval Loss = 0.2633\n",
            "Epoch 16: Train Loss = 0.2999, Eval Loss = 0.2629\n",
            "Epoch 17: Train Loss = 0.2977, Eval Loss = 0.2635\n",
            "Epoch 18: Train Loss = 0.2895, Eval Loss = 0.2638\n",
            "Epoch 19: Train Loss = 0.2825, Eval Loss = 0.2647\n",
            "Epoch 20: Train Loss = 0.2769, Eval Loss = 0.2648\n",
            "Epoch 21: Train Loss = 0.2714, Eval Loss = 0.2648\n",
            "Epoch 22: Train Loss = 0.2699, Eval Loss = 0.2658\n",
            "Epoch 23: Train Loss = 0.2604, Eval Loss = 0.2675\n",
            "Epoch 24: Train Loss = 0.2513, Eval Loss = 0.2666\n",
            "Epoch 25: Train Loss = 0.2494, Eval Loss = 0.2675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:41:01,699] Trial 7 finished with value: 0.26867035031318665 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 6.04214410565616e-05, 'alpha': 0.29814249995711684}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss = 0.2470, Eval Loss = 0.2687\n",
            "Early stopping triggered at epoch 26\n",
            "Epoch 1: Train Loss = 0.8451, Eval Loss = 0.2784\n",
            "Epoch 2: Train Loss = 0.6254, Eval Loss = 0.2776\n",
            "Epoch 3: Train Loss = 0.5890, Eval Loss = 0.2760\n",
            "Epoch 4: Train Loss = 0.5697, Eval Loss = 0.2744\n",
            "Epoch 5: Train Loss = 0.5362, Eval Loss = 0.2716\n",
            "Epoch 6: Train Loss = 0.5087, Eval Loss = 0.2697\n",
            "Epoch 7: Train Loss = 0.4789, Eval Loss = 0.2695\n",
            "Epoch 8: Train Loss = 0.4572, Eval Loss = 0.2684\n",
            "Epoch 9: Train Loss = 0.4337, Eval Loss = 0.2680\n",
            "Epoch 10: Train Loss = 0.4134, Eval Loss = 0.2677\n",
            "Epoch 11: Train Loss = 0.3979, Eval Loss = 0.2679\n",
            "Epoch 12: Train Loss = 0.3828, Eval Loss = 0.2674\n",
            "Epoch 13: Train Loss = 0.3691, Eval Loss = 0.2673\n",
            "Epoch 14: Train Loss = 0.3548, Eval Loss = 0.2670\n",
            "Epoch 15: Train Loss = 0.3435, Eval Loss = 0.2673\n",
            "Epoch 16: Train Loss = 0.3348, Eval Loss = 0.2674\n",
            "Epoch 17: Train Loss = 0.3264, Eval Loss = 0.2674\n",
            "Epoch 18: Train Loss = 0.3204, Eval Loss = 0.2669\n",
            "Epoch 19: Train Loss = 0.3136, Eval Loss = 0.2671\n",
            "Epoch 20: Train Loss = 0.3065, Eval Loss = 0.2668\n",
            "Epoch 21: Train Loss = 0.3032, Eval Loss = 0.2669\n",
            "Epoch 22: Train Loss = 0.2950, Eval Loss = 0.2671\n",
            "Epoch 23: Train Loss = 0.2917, Eval Loss = 0.2668\n",
            "Epoch 24: Train Loss = 0.2857, Eval Loss = 0.2666\n",
            "Epoch 25: Train Loss = 0.2803, Eval Loss = 0.2666\n",
            "Epoch 26: Train Loss = 0.2768, Eval Loss = 0.2666\n",
            "Epoch 27: Train Loss = 0.2712, Eval Loss = 0.2672\n",
            "Epoch 28: Train Loss = 0.2666, Eval Loss = 0.2671\n",
            "Epoch 29: Train Loss = 0.2669, Eval Loss = 0.2676\n",
            "Epoch 30: Train Loss = 0.2650, Eval Loss = 0.2681\n",
            "Epoch 31: Train Loss = 0.2512, Eval Loss = 0.2681\n",
            "Epoch 32: Train Loss = 0.2438, Eval Loss = 0.2683\n",
            "Epoch 33: Train Loss = 0.2439, Eval Loss = 0.2684\n",
            "Epoch 34: Train Loss = 0.2339, Eval Loss = 0.2690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:43:23,744] Trial 8 finished with value: 0.2693879306316376 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 4.1666369394759935e-05, 'alpha': 0.31745822915817806}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: Train Loss = 0.2292, Eval Loss = 0.2694\n",
            "Early stopping triggered at epoch 35\n",
            "Epoch 1: Train Loss = 1.0391, Eval Loss = 0.2647\n",
            "Epoch 2: Train Loss = 0.8297, Eval Loss = 0.2614\n",
            "Epoch 3: Train Loss = 0.6971, Eval Loss = 0.2613\n",
            "Epoch 4: Train Loss = 0.6333, Eval Loss = 0.2613\n",
            "Epoch 5: Train Loss = 0.6001, Eval Loss = 0.2608\n",
            "Epoch 6: Train Loss = 0.5780, Eval Loss = 0.2614\n",
            "Epoch 7: Train Loss = 0.5627, Eval Loss = 0.2612\n",
            "Epoch 8: Train Loss = 0.5505, Eval Loss = 0.2604\n",
            "Epoch 9: Train Loss = 0.5391, Eval Loss = 0.2606\n",
            "Epoch 10: Train Loss = 0.5310, Eval Loss = 0.2599\n",
            "Epoch 11: Train Loss = 0.5237, Eval Loss = 0.2592\n",
            "Epoch 12: Train Loss = 0.5261, Eval Loss = 0.2589\n",
            "Epoch 13: Train Loss = 0.5096, Eval Loss = 0.2587\n",
            "Epoch 14: Train Loss = 0.5022, Eval Loss = 0.2585\n",
            "Epoch 15: Train Loss = 0.4951, Eval Loss = 0.2583\n",
            "Epoch 16: Train Loss = 0.4901, Eval Loss = 0.2579\n",
            "Epoch 17: Train Loss = 0.4821, Eval Loss = 0.2574\n",
            "Epoch 18: Train Loss = 0.4762, Eval Loss = 0.2570\n",
            "Epoch 19: Train Loss = 0.4695, Eval Loss = 0.2569\n",
            "Epoch 20: Train Loss = 0.4627, Eval Loss = 0.2567\n",
            "Epoch 21: Train Loss = 0.4568, Eval Loss = 0.2564\n",
            "Epoch 22: Train Loss = 0.4508, Eval Loss = 0.2560\n",
            "Epoch 23: Train Loss = 0.4454, Eval Loss = 0.2558\n",
            "Epoch 24: Train Loss = 0.4391, Eval Loss = 0.2558\n",
            "Epoch 25: Train Loss = 0.4331, Eval Loss = 0.2553\n",
            "Epoch 26: Train Loss = 0.4278, Eval Loss = 0.2554\n",
            "Epoch 27: Train Loss = 0.4223, Eval Loss = 0.2552\n",
            "Epoch 28: Train Loss = 0.4174, Eval Loss = 0.2552\n",
            "Epoch 29: Train Loss = 0.4121, Eval Loss = 0.2550\n",
            "Epoch 30: Train Loss = 0.4073, Eval Loss = 0.2550\n",
            "Epoch 31: Train Loss = 0.4027, Eval Loss = 0.2549\n",
            "Epoch 32: Train Loss = 0.3990, Eval Loss = 0.2551\n",
            "Epoch 33: Train Loss = 0.3938, Eval Loss = 0.2550\n",
            "Epoch 34: Train Loss = 0.3899, Eval Loss = 0.2551\n",
            "Epoch 35: Train Loss = 0.3856, Eval Loss = 0.2551\n",
            "Epoch 36: Train Loss = 0.3805, Eval Loss = 0.2552\n",
            "Epoch 37: Train Loss = 0.3770, Eval Loss = 0.2553\n",
            "Epoch 38: Train Loss = 0.3734, Eval Loss = 0.2552\n",
            "Epoch 39: Train Loss = 0.3694, Eval Loss = 0.2552\n",
            "Epoch 40: Train Loss = 0.3655, Eval Loss = 0.2554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:44:27,092] Trial 9 finished with value: 0.2556040287017822 and parameters: {'hidden_dim': 128, 'n_layers': 2, 'lr': 2.6593255918279533e-05, 'alpha': 0.2146111996975223}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: Train Loss = 0.3618, Eval Loss = 0.2556\n",
            "Early stopping triggered at epoch 41\n",
            "Epoch 1: Train Loss = 0.6302, Eval Loss = 0.2438\n",
            "Epoch 2: Train Loss = 0.5120, Eval Loss = 0.2387\n",
            "Epoch 3: Train Loss = 0.4701, Eval Loss = 0.2356\n",
            "Epoch 4: Train Loss = 0.4182, Eval Loss = 0.2347\n",
            "Epoch 5: Train Loss = 0.3744, Eval Loss = 0.2345\n",
            "Epoch 6: Train Loss = 0.3364, Eval Loss = 0.2341\n",
            "Epoch 7: Train Loss = 0.3048, Eval Loss = 0.2341\n",
            "Epoch 8: Train Loss = 0.2793, Eval Loss = 0.2338\n",
            "Epoch 9: Train Loss = 0.2678, Eval Loss = 0.2356\n",
            "Epoch 10: Train Loss = 0.2595, Eval Loss = 0.2359\n",
            "Epoch 11: Train Loss = 0.2432, Eval Loss = 0.2357\n",
            "Epoch 12: Train Loss = 0.2353, Eval Loss = 0.2371\n",
            "Epoch 13: Train Loss = 0.2304, Eval Loss = 0.2371\n",
            "Epoch 14: Train Loss = 0.2273, Eval Loss = 0.2385\n",
            "Epoch 15: Train Loss = 0.2273, Eval Loss = 0.2387\n",
            "Epoch 16: Train Loss = 0.2150, Eval Loss = 0.2395\n",
            "Epoch 17: Train Loss = 0.2090, Eval Loss = 0.2403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:45:01,982] Trial 10 finished with value: 0.24077589809894562 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0001904842503461363, 'alpha': 0.10178606215320835}. Best is trial 3 with value: 0.24059619009494781.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss = 0.2086, Eval Loss = 0.2408\n",
            "Early stopping triggered at epoch 18\n",
            "Epoch 1: Train Loss = 0.6363, Eval Loss = 0.2409\n",
            "Epoch 2: Train Loss = 0.5019, Eval Loss = 0.2387\n",
            "Epoch 3: Train Loss = 0.4605, Eval Loss = 0.2359\n",
            "Epoch 4: Train Loss = 0.4183, Eval Loss = 0.2347\n",
            "Epoch 5: Train Loss = 0.3851, Eval Loss = 0.2338\n",
            "Epoch 6: Train Loss = 0.3330, Eval Loss = 0.2342\n",
            "Epoch 7: Train Loss = 0.3041, Eval Loss = 0.2335\n",
            "Epoch 8: Train Loss = 0.2779, Eval Loss = 0.2341\n",
            "Epoch 9: Train Loss = 0.2650, Eval Loss = 0.2334\n",
            "Epoch 10: Train Loss = 0.2504, Eval Loss = 0.2342\n",
            "Epoch 11: Train Loss = 0.2538, Eval Loss = 0.2338\n",
            "Epoch 12: Train Loss = 0.2382, Eval Loss = 0.2342\n",
            "Epoch 13: Train Loss = 0.2279, Eval Loss = 0.2349\n",
            "Epoch 14: Train Loss = 0.2282, Eval Loss = 0.2365\n",
            "Epoch 15: Train Loss = 0.2233, Eval Loss = 0.2363\n",
            "Epoch 16: Train Loss = 0.2129, Eval Loss = 0.2367\n",
            "Epoch 17: Train Loss = 0.2124, Eval Loss = 0.2373\n",
            "Epoch 18: Train Loss = 0.2029, Eval Loss = 0.2385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:45:39,396] Trial 11 finished with value: 0.23932461440563202 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00019053191108844402, 'alpha': 0.10118860885829964}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss = 0.1982, Eval Loss = 0.2393\n",
            "Early stopping triggered at epoch 19\n",
            "Epoch 1: Train Loss = 0.6028, Eval Loss = 0.2404\n",
            "Epoch 2: Train Loss = 0.5120, Eval Loss = 0.2373\n",
            "Epoch 3: Train Loss = 0.4682, Eval Loss = 0.2346\n",
            "Epoch 4: Train Loss = 0.4063, Eval Loss = 0.2346\n",
            "Epoch 5: Train Loss = 0.3488, Eval Loss = 0.2346\n",
            "Epoch 6: Train Loss = 0.3201, Eval Loss = 0.2340\n",
            "Epoch 7: Train Loss = 0.2871, Eval Loss = 0.2348\n",
            "Epoch 8: Train Loss = 0.2680, Eval Loss = 0.2350\n",
            "Epoch 9: Train Loss = 0.2532, Eval Loss = 0.2357\n",
            "Epoch 10: Train Loss = 0.2557, Eval Loss = 0.2375\n",
            "Epoch 11: Train Loss = 0.2373, Eval Loss = 0.2390\n",
            "Epoch 12: Train Loss = 0.2414, Eval Loss = 0.2408\n",
            "Epoch 13: Train Loss = 0.2440, Eval Loss = 0.2410\n",
            "Epoch 14: Train Loss = 0.2206, Eval Loss = 0.2408\n",
            "Epoch 15: Train Loss = 0.2196, Eval Loss = 0.2411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:46:10,259] Trial 12 finished with value: 0.24254155158996582 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00039297723844301027, 'alpha': 0.10563362594467132}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.2065, Eval Loss = 0.2425\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 0.6788, Eval Loss = 0.2572\n",
            "Epoch 2: Train Loss = 0.5630, Eval Loss = 0.2552\n",
            "Epoch 3: Train Loss = 0.5332, Eval Loss = 0.2546\n",
            "Epoch 4: Train Loss = 0.5171, Eval Loss = 0.2510\n",
            "Epoch 5: Train Loss = 0.4967, Eval Loss = 0.2498\n",
            "Epoch 6: Train Loss = 0.4705, Eval Loss = 0.2487\n",
            "Epoch 7: Train Loss = 0.4384, Eval Loss = 0.2484\n",
            "Epoch 8: Train Loss = 0.3991, Eval Loss = 0.2483\n",
            "Epoch 9: Train Loss = 0.3657, Eval Loss = 0.2472\n",
            "Epoch 10: Train Loss = 0.3400, Eval Loss = 0.2473\n",
            "Epoch 11: Train Loss = 0.3162, Eval Loss = 0.2478\n",
            "Epoch 12: Train Loss = 0.3041, Eval Loss = 0.2474\n",
            "Epoch 13: Train Loss = 0.2938, Eval Loss = 0.2494\n",
            "Epoch 14: Train Loss = 0.2886, Eval Loss = 0.2499\n",
            "Epoch 15: Train Loss = 0.2846, Eval Loss = 0.2505\n",
            "Epoch 16: Train Loss = 0.2766, Eval Loss = 0.2515\n",
            "Epoch 17: Train Loss = 0.2700, Eval Loss = 0.2532\n",
            "Epoch 18: Train Loss = 0.2635, Eval Loss = 0.2546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:47:13,972] Trial 13 finished with value: 0.256275475025177 and parameters: {'hidden_dim': 256, 'n_layers': 4, 'lr': 0.00011764929934405094, 'alpha': 0.18551688306552772}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss = 0.2663, Eval Loss = 0.2563\n",
            "Early stopping triggered at epoch 19\n",
            "Epoch 1: Train Loss = 0.6995, Eval Loss = 0.2623\n",
            "Epoch 2: Train Loss = 0.5791, Eval Loss = 0.2599\n",
            "Epoch 3: Train Loss = 0.5410, Eval Loss = 0.2576\n",
            "Epoch 4: Train Loss = 0.4897, Eval Loss = 0.2550\n",
            "Epoch 5: Train Loss = 0.4475, Eval Loss = 0.2562\n",
            "Epoch 6: Train Loss = 0.3878, Eval Loss = 0.2557\n",
            "Epoch 7: Train Loss = 0.3574, Eval Loss = 0.2566\n",
            "Epoch 8: Train Loss = 0.3327, Eval Loss = 0.2570\n",
            "Epoch 9: Train Loss = 0.3285, Eval Loss = 0.2571\n",
            "Epoch 10: Train Loss = 0.3098, Eval Loss = 0.2592\n",
            "Epoch 11: Train Loss = 0.2962, Eval Loss = 0.2598\n",
            "Epoch 12: Train Loss = 0.2917, Eval Loss = 0.2599\n",
            "Epoch 13: Train Loss = 0.2887, Eval Loss = 0.2621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:47:42,208] Trial 14 finished with value: 0.2611980736255646 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0002886066473416056, 'alpha': 0.24341091947463792}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.2753, Eval Loss = 0.2612\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.7110, Eval Loss = 0.2443\n",
            "Epoch 2: Train Loss = 0.6843, Eval Loss = 0.2475\n",
            "Epoch 3: Train Loss = 0.5618, Eval Loss = 0.2438\n",
            "Epoch 4: Train Loss = 0.5289, Eval Loss = 0.2468\n",
            "Epoch 5: Train Loss = 0.4884, Eval Loss = 0.2471\n",
            "Epoch 6: Train Loss = 0.4880, Eval Loss = 0.2470\n",
            "Epoch 7: Train Loss = 0.4313, Eval Loss = 0.2458\n",
            "Epoch 8: Train Loss = 0.4085, Eval Loss = 0.2468\n",
            "Epoch 9: Train Loss = 0.3799, Eval Loss = 0.2483\n",
            "Epoch 10: Train Loss = 0.3339, Eval Loss = 0.2487\n",
            "Epoch 11: Train Loss = 0.3275, Eval Loss = 0.2478\n",
            "Epoch 12: Train Loss = 0.2932, Eval Loss = 0.2480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:48:14,443] Trial 15 finished with value: 0.2500613331794739 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 0.0008734618084313882, 'alpha': 0.14677944693206488}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.2771, Eval Loss = 0.2501\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.7961, Eval Loss = 0.2703\n",
            "Epoch 2: Train Loss = 0.5858, Eval Loss = 0.2682\n",
            "Epoch 3: Train Loss = 0.5690, Eval Loss = 0.2672\n",
            "Epoch 4: Train Loss = 0.5504, Eval Loss = 0.2662\n",
            "Epoch 5: Train Loss = 0.5444, Eval Loss = 0.2664\n",
            "Epoch 6: Train Loss = 0.5251, Eval Loss = 0.2644\n",
            "Epoch 7: Train Loss = 0.4988, Eval Loss = 0.2615\n",
            "Epoch 8: Train Loss = 0.4669, Eval Loss = 0.2610\n",
            "Epoch 9: Train Loss = 0.4341, Eval Loss = 0.2585\n",
            "Epoch 10: Train Loss = 0.4023, Eval Loss = 0.2579\n",
            "Epoch 11: Train Loss = 0.3806, Eval Loss = 0.2575\n",
            "Epoch 12: Train Loss = 0.3656, Eval Loss = 0.2583\n",
            "Epoch 13: Train Loss = 0.3474, Eval Loss = 0.2583\n",
            "Epoch 14: Train Loss = 0.3343, Eval Loss = 0.2582\n",
            "Epoch 15: Train Loss = 0.3220, Eval Loss = 0.2575\n",
            "Epoch 16: Train Loss = 0.3203, Eval Loss = 0.2578\n",
            "Epoch 17: Train Loss = 0.3085, Eval Loss = 0.2577\n",
            "Epoch 18: Train Loss = 0.3044, Eval Loss = 0.2589\n",
            "Epoch 19: Train Loss = 0.3020, Eval Loss = 0.2592\n",
            "Epoch 20: Train Loss = 0.2972, Eval Loss = 0.2592\n",
            "Epoch 21: Train Loss = 0.2944, Eval Loss = 0.2589\n",
            "Epoch 22: Train Loss = 0.2880, Eval Loss = 0.2606\n",
            "Epoch 23: Train Loss = 0.2832, Eval Loss = 0.2619\n",
            "Epoch 24: Train Loss = 0.2840, Eval Loss = 0.2614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:49:40,076] Trial 16 finished with value: 0.2610337734222412 and parameters: {'hidden_dim': 256, 'n_layers': 4, 'lr': 8.201978690992264e-05, 'alpha': 0.25116297346216043}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: Train Loss = 0.2802, Eval Loss = 0.2610\n",
            "Early stopping triggered at epoch 25\n",
            "Epoch 1: Train Loss = 0.6384, Eval Loss = 0.2428\n",
            "Epoch 2: Train Loss = 0.5529, Eval Loss = 0.2422\n",
            "Epoch 3: Train Loss = 0.5120, Eval Loss = 0.2388\n",
            "Epoch 4: Train Loss = 0.4731, Eval Loss = 0.2401\n",
            "Epoch 5: Train Loss = 0.4121, Eval Loss = 0.2407\n",
            "Epoch 6: Train Loss = 0.3919, Eval Loss = 0.2420\n",
            "Epoch 7: Train Loss = 0.3382, Eval Loss = 0.2423\n",
            "Epoch 8: Train Loss = 0.3640, Eval Loss = 0.2450\n",
            "Epoch 9: Train Loss = 0.3092, Eval Loss = 0.2461\n",
            "Epoch 10: Train Loss = 0.2967, Eval Loss = 0.2452\n",
            "Epoch 11: Train Loss = 0.2728, Eval Loss = 0.2448\n",
            "Epoch 12: Train Loss = 0.2864, Eval Loss = 0.2482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:50:25,080] Trial 17 finished with value: 0.24769815802574158 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.00025614170690773817, 'alpha': 0.13738980884207208}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.2657, Eval Loss = 0.2477\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.7308, Eval Loss = 0.2599\n",
            "Epoch 2: Train Loss = 0.5639, Eval Loss = 0.2575\n",
            "Epoch 3: Train Loss = 0.5327, Eval Loss = 0.2556\n",
            "Epoch 4: Train Loss = 0.5119, Eval Loss = 0.2521\n",
            "Epoch 5: Train Loss = 0.4678, Eval Loss = 0.2506\n",
            "Epoch 6: Train Loss = 0.4361, Eval Loss = 0.2502\n",
            "Epoch 7: Train Loss = 0.3956, Eval Loss = 0.2500\n",
            "Epoch 8: Train Loss = 0.3753, Eval Loss = 0.2484\n",
            "Epoch 9: Train Loss = 0.3529, Eval Loss = 0.2488\n",
            "Epoch 10: Train Loss = 0.3304, Eval Loss = 0.2487\n",
            "Epoch 11: Train Loss = 0.3106, Eval Loss = 0.2489\n",
            "Epoch 12: Train Loss = 0.3066, Eval Loss = 0.2476\n",
            "Epoch 13: Train Loss = 0.2946, Eval Loss = 0.2482\n",
            "Epoch 14: Train Loss = 0.2834, Eval Loss = 0.2485\n",
            "Epoch 15: Train Loss = 0.2777, Eval Loss = 0.2491\n",
            "Epoch 16: Train Loss = 0.2723, Eval Loss = 0.2498\n",
            "Epoch 17: Train Loss = 0.2656, Eval Loss = 0.2497\n",
            "Epoch 18: Train Loss = 0.2674, Eval Loss = 0.2494\n",
            "Epoch 19: Train Loss = 0.2629, Eval Loss = 0.2510\n",
            "Epoch 20: Train Loss = 0.2570, Eval Loss = 0.2525\n",
            "Epoch 21: Train Loss = 0.2503, Eval Loss = 0.2533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:51:22,481] Trial 18 finished with value: 0.2526605725288391 and parameters: {'hidden_dim': 256, 'n_layers': 3, 'lr': 0.00011396698329289136, 'alpha': 0.1979622404159901}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: Train Loss = 0.2492, Eval Loss = 0.2527\n",
            "Early stopping triggered at epoch 22\n",
            "Epoch 1: Train Loss = 0.7936, Eval Loss = 0.2498\n",
            "Epoch 2: Train Loss = 0.5735, Eval Loss = 0.2484\n",
            "Epoch 3: Train Loss = 0.5313, Eval Loss = 0.2486\n",
            "Epoch 4: Train Loss = 0.5114, Eval Loss = 0.2476\n",
            "Epoch 5: Train Loss = 0.4921, Eval Loss = 0.2461\n",
            "Epoch 6: Train Loss = 0.4765, Eval Loss = 0.2451\n",
            "Epoch 7: Train Loss = 0.4582, Eval Loss = 0.2445\n",
            "Epoch 8: Train Loss = 0.4402, Eval Loss = 0.2436\n",
            "Epoch 9: Train Loss = 0.4232, Eval Loss = 0.2429\n",
            "Epoch 10: Train Loss = 0.4085, Eval Loss = 0.2424\n",
            "Epoch 11: Train Loss = 0.3915, Eval Loss = 0.2415\n",
            "Epoch 12: Train Loss = 0.3781, Eval Loss = 0.2420\n",
            "Epoch 13: Train Loss = 0.3633, Eval Loss = 0.2421\n",
            "Epoch 14: Train Loss = 0.3520, Eval Loss = 0.2419\n",
            "Epoch 15: Train Loss = 0.3399, Eval Loss = 0.2421\n",
            "Epoch 16: Train Loss = 0.3303, Eval Loss = 0.2425\n",
            "Epoch 17: Train Loss = 0.3216, Eval Loss = 0.2421\n",
            "Epoch 18: Train Loss = 0.3113, Eval Loss = 0.2427\n",
            "Epoch 19: Train Loss = 0.3032, Eval Loss = 0.2428\n",
            "Epoch 20: Train Loss = 0.2940, Eval Loss = 0.2427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:51:54,306] Trial 19 finished with value: 0.2425321787595749 and parameters: {'hidden_dim': 128, 'n_layers': 2, 'lr': 7.376244360103121e-05, 'alpha': 0.1383248056458412}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss = 0.2934, Eval Loss = 0.2425\n",
            "Early stopping triggered at epoch 21\n",
            "Epoch 1: Train Loss = 0.7721, Eval Loss = 0.2649\n",
            "Epoch 2: Train Loss = 0.6287, Eval Loss = 0.2623\n",
            "Epoch 3: Train Loss = 0.5894, Eval Loss = 0.2619\n",
            "Epoch 4: Train Loss = 0.6154, Eval Loss = 0.2641\n",
            "Epoch 5: Train Loss = 0.5281, Eval Loss = 0.2637\n",
            "Epoch 6: Train Loss = 0.5494, Eval Loss = 0.2678\n",
            "Epoch 7: Train Loss = 0.4861, Eval Loss = 0.2646\n",
            "Epoch 8: Train Loss = 0.4658, Eval Loss = 0.2683\n",
            "Epoch 9: Train Loss = 0.4259, Eval Loss = 0.2659\n",
            "Epoch 10: Train Loss = 0.4533, Eval Loss = 0.2658\n",
            "Epoch 11: Train Loss = 0.3711, Eval Loss = 0.2625\n",
            "Epoch 12: Train Loss = 0.3373, Eval Loss = 0.2661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:52:39,165] Trial 20 finished with value: 0.26608991622924805 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.0004742797493097238, 'alpha': 0.26047476343115045}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.3459, Eval Loss = 0.2661\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.6332, Eval Loss = 0.2418\n",
            "Epoch 2: Train Loss = 0.5150, Eval Loss = 0.2391\n",
            "Epoch 3: Train Loss = 0.4666, Eval Loss = 0.2364\n",
            "Epoch 4: Train Loss = 0.4188, Eval Loss = 0.2348\n",
            "Epoch 5: Train Loss = 0.3651, Eval Loss = 0.2347\n",
            "Epoch 6: Train Loss = 0.3408, Eval Loss = 0.2344\n",
            "Epoch 7: Train Loss = 0.3021, Eval Loss = 0.2345\n",
            "Epoch 8: Train Loss = 0.2847, Eval Loss = 0.2342\n",
            "Epoch 9: Train Loss = 0.2681, Eval Loss = 0.2357\n",
            "Epoch 10: Train Loss = 0.2539, Eval Loss = 0.2351\n",
            "Epoch 11: Train Loss = 0.2537, Eval Loss = 0.2362\n",
            "Epoch 12: Train Loss = 0.2519, Eval Loss = 0.2363\n",
            "Epoch 13: Train Loss = 0.2346, Eval Loss = 0.2379\n",
            "Epoch 14: Train Loss = 0.2299, Eval Loss = 0.2381\n",
            "Epoch 15: Train Loss = 0.2259, Eval Loss = 0.2380\n",
            "Epoch 16: Train Loss = 0.2174, Eval Loss = 0.2395\n",
            "Epoch 17: Train Loss = 0.2127, Eval Loss = 0.2396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:53:13,973] Trial 21 finished with value: 0.23996113240718842 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00019833429502005785, 'alpha': 0.1084746896255454}. Best is trial 11 with value: 0.23932461440563202.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss = 0.2123, Eval Loss = 0.2400\n",
            "Early stopping triggered at epoch 18\n",
            "Epoch 1: Train Loss = 0.6507, Eval Loss = 0.2441\n",
            "Epoch 2: Train Loss = 0.5273, Eval Loss = 0.2398\n",
            "Epoch 3: Train Loss = 0.4700, Eval Loss = 0.2376\n",
            "Epoch 4: Train Loss = 0.4161, Eval Loss = 0.2365\n",
            "Epoch 5: Train Loss = 0.3784, Eval Loss = 0.2365\n",
            "Epoch 6: Train Loss = 0.3415, Eval Loss = 0.2339\n",
            "Epoch 7: Train Loss = 0.3084, Eval Loss = 0.2348\n",
            "Epoch 8: Train Loss = 0.2883, Eval Loss = 0.2349\n",
            "Epoch 9: Train Loss = 0.2706, Eval Loss = 0.2349\n",
            "Epoch 10: Train Loss = 0.2569, Eval Loss = 0.2352\n",
            "Epoch 11: Train Loss = 0.2661, Eval Loss = 0.2348\n",
            "Epoch 12: Train Loss = 0.2381, Eval Loss = 0.2354\n",
            "Epoch 13: Train Loss = 0.2312, Eval Loss = 0.2363\n",
            "Epoch 14: Train Loss = 0.2326, Eval Loss = 0.2378\n",
            "Epoch 15: Train Loss = 0.2300, Eval Loss = 0.2375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:53:42,996] Trial 22 finished with value: 0.23827916383743286 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0001711630829256663, 'alpha': 0.10491783304004444}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.2177, Eval Loss = 0.2383\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 0.6653, Eval Loss = 0.2517\n",
            "Epoch 2: Train Loss = 0.5349, Eval Loss = 0.2476\n",
            "Epoch 3: Train Loss = 0.4941, Eval Loss = 0.2457\n",
            "Epoch 4: Train Loss = 0.4410, Eval Loss = 0.2443\n",
            "Epoch 5: Train Loss = 0.3948, Eval Loss = 0.2431\n",
            "Epoch 6: Train Loss = 0.3651, Eval Loss = 0.2431\n",
            "Epoch 7: Train Loss = 0.3307, Eval Loss = 0.2430\n",
            "Epoch 8: Train Loss = 0.3033, Eval Loss = 0.2425\n",
            "Epoch 9: Train Loss = 0.2919, Eval Loss = 0.2422\n",
            "Epoch 10: Train Loss = 0.2737, Eval Loss = 0.2419\n",
            "Epoch 11: Train Loss = 0.2672, Eval Loss = 0.2430\n",
            "Epoch 12: Train Loss = 0.2631, Eval Loss = 0.2432\n",
            "Epoch 13: Train Loss = 0.2575, Eval Loss = 0.2431\n",
            "Epoch 14: Train Loss = 0.2469, Eval Loss = 0.2435\n",
            "Epoch 15: Train Loss = 0.2403, Eval Loss = 0.2445\n",
            "Epoch 16: Train Loss = 0.2351, Eval Loss = 0.2454\n",
            "Epoch 17: Train Loss = 0.2317, Eval Loss = 0.2458\n",
            "Epoch 18: Train Loss = 0.2257, Eval Loss = 0.2465\n",
            "Epoch 19: Train Loss = 0.2212, Eval Loss = 0.2462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:54:19,650] Trial 23 finished with value: 0.24714794754981995 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0001920220969781183, 'alpha': 0.15869093629167383}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss = 0.2168, Eval Loss = 0.2471\n",
            "Early stopping triggered at epoch 20\n",
            "Epoch 1: Train Loss = 0.6460, Eval Loss = 0.2442\n",
            "Epoch 2: Train Loss = 0.5253, Eval Loss = 0.2435\n",
            "Epoch 3: Train Loss = 0.4799, Eval Loss = 0.2402\n",
            "Epoch 4: Train Loss = 0.4259, Eval Loss = 0.2404\n",
            "Epoch 5: Train Loss = 0.3778, Eval Loss = 0.2405\n",
            "Epoch 6: Train Loss = 0.3319, Eval Loss = 0.2399\n",
            "Epoch 7: Train Loss = 0.3057, Eval Loss = 0.2409\n",
            "Epoch 8: Train Loss = 0.2797, Eval Loss = 0.2408\n",
            "Epoch 9: Train Loss = 0.2667, Eval Loss = 0.2432\n",
            "Epoch 10: Train Loss = 0.2665, Eval Loss = 0.2415\n",
            "Epoch 11: Train Loss = 0.2573, Eval Loss = 0.2437\n",
            "Epoch 12: Train Loss = 0.2570, Eval Loss = 0.2431\n",
            "Epoch 13: Train Loss = 0.2346, Eval Loss = 0.2452\n",
            "Epoch 14: Train Loss = 0.2334, Eval Loss = 0.2460\n",
            "Epoch 15: Train Loss = 0.2362, Eval Loss = 0.2462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:54:49,255] Trial 24 finished with value: 0.24810928106307983 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0002966881731184431, 'alpha': 0.13418792165876636}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.2246, Eval Loss = 0.2481\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 0.6963, Eval Loss = 0.2618\n",
            "Epoch 2: Train Loss = 0.5548, Eval Loss = 0.2596\n",
            "Epoch 3: Train Loss = 0.5212, Eval Loss = 0.2571\n",
            "Epoch 4: Train Loss = 0.4697, Eval Loss = 0.2558\n",
            "Epoch 5: Train Loss = 0.4343, Eval Loss = 0.2539\n",
            "Epoch 6: Train Loss = 0.3972, Eval Loss = 0.2550\n",
            "Epoch 7: Train Loss = 0.3676, Eval Loss = 0.2549\n",
            "Epoch 8: Train Loss = 0.3364, Eval Loss = 0.2544\n",
            "Epoch 9: Train Loss = 0.3221, Eval Loss = 0.2550\n",
            "Epoch 10: Train Loss = 0.3102, Eval Loss = 0.2545\n",
            "Epoch 11: Train Loss = 0.3084, Eval Loss = 0.2542\n",
            "Epoch 12: Train Loss = 0.2894, Eval Loss = 0.2539\n",
            "Epoch 13: Train Loss = 0.2872, Eval Loss = 0.2541\n",
            "Epoch 14: Train Loss = 0.2750, Eval Loss = 0.2547\n",
            "Epoch 15: Train Loss = 0.2682, Eval Loss = 0.2546\n",
            "Epoch 16: Train Loss = 0.2647, Eval Loss = 0.2550\n",
            "Epoch 17: Train Loss = 0.2589, Eval Loss = 0.2556\n",
            "Epoch 18: Train Loss = 0.2558, Eval Loss = 0.2561\n",
            "Epoch 19: Train Loss = 0.2503, Eval Loss = 0.2562\n",
            "Epoch 20: Train Loss = 0.2417, Eval Loss = 0.2569\n",
            "Epoch 21: Train Loss = 0.2369, Eval Loss = 0.2576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:55:29,724] Trial 25 finished with value: 0.2574329078197479 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00014809321678604627, 'alpha': 0.21205916395893165}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: Train Loss = 0.2354, Eval Loss = 0.2574\n",
            "Early stopping triggered at epoch 22\n",
            "Epoch 1: Train Loss = 0.6292, Eval Loss = 0.2378\n",
            "Epoch 2: Train Loss = 0.5323, Eval Loss = 0.2376\n",
            "Epoch 3: Train Loss = 0.5095, Eval Loss = 0.2359\n",
            "Epoch 4: Train Loss = 0.4540, Eval Loss = 0.2373\n",
            "Epoch 5: Train Loss = 0.4405, Eval Loss = 0.2402\n",
            "Epoch 6: Train Loss = 0.3741, Eval Loss = 0.2414\n",
            "Epoch 7: Train Loss = 0.3261, Eval Loss = 0.2419\n",
            "Epoch 8: Train Loss = 0.3035, Eval Loss = 0.2416\n",
            "Epoch 9: Train Loss = 0.2731, Eval Loss = 0.2412\n",
            "Epoch 10: Train Loss = 0.2694, Eval Loss = 0.2416\n",
            "Epoch 11: Train Loss = 0.2636, Eval Loss = 0.2429\n",
            "Epoch 12: Train Loss = 0.2455, Eval Loss = 0.2431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:55:53,540] Trial 26 finished with value: 0.24311022460460663 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.0008033022971886674, 'alpha': 0.1011313502587996}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.2324, Eval Loss = 0.2431\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.6500, Eval Loss = 0.2516\n",
            "Epoch 2: Train Loss = 0.5366, Eval Loss = 0.2477\n",
            "Epoch 3: Train Loss = 0.4983, Eval Loss = 0.2449\n",
            "Epoch 4: Train Loss = 0.4450, Eval Loss = 0.2447\n",
            "Epoch 5: Train Loss = 0.3988, Eval Loss = 0.2432\n",
            "Epoch 6: Train Loss = 0.3592, Eval Loss = 0.2421\n",
            "Epoch 7: Train Loss = 0.3255, Eval Loss = 0.2429\n",
            "Epoch 8: Train Loss = 0.3038, Eval Loss = 0.2429\n",
            "Epoch 9: Train Loss = 0.2882, Eval Loss = 0.2426\n",
            "Epoch 10: Train Loss = 0.2807, Eval Loss = 0.2424\n",
            "Epoch 11: Train Loss = 0.2712, Eval Loss = 0.2427\n",
            "Epoch 12: Train Loss = 0.2666, Eval Loss = 0.2434\n",
            "Epoch 13: Train Loss = 0.2652, Eval Loss = 0.2430\n",
            "Epoch 14: Train Loss = 0.2572, Eval Loss = 0.2434\n",
            "Epoch 15: Train Loss = 0.2459, Eval Loss = 0.2436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:56:23,073] Trial 27 finished with value: 0.244315966963768 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00021087973122686546, 'alpha': 0.16803727016185088}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss = 0.2442, Eval Loss = 0.2443\n",
            "Early stopping triggered at epoch 16\n",
            "Epoch 1: Train Loss = 0.6530, Eval Loss = 0.2425\n",
            "Epoch 2: Train Loss = 0.5173, Eval Loss = 0.2400\n",
            "Epoch 3: Train Loss = 0.4705, Eval Loss = 0.2367\n",
            "Epoch 4: Train Loss = 0.4187, Eval Loss = 0.2354\n",
            "Epoch 5: Train Loss = 0.3764, Eval Loss = 0.2370\n",
            "Epoch 6: Train Loss = 0.3363, Eval Loss = 0.2360\n",
            "Epoch 7: Train Loss = 0.2938, Eval Loss = 0.2377\n",
            "Epoch 8: Train Loss = 0.2872, Eval Loss = 0.2389\n",
            "Epoch 9: Train Loss = 0.2753, Eval Loss = 0.2386\n",
            "Epoch 10: Train Loss = 0.2581, Eval Loss = 0.2399\n",
            "Epoch 11: Train Loss = 0.2716, Eval Loss = 0.2411\n",
            "Epoch 12: Train Loss = 0.2443, Eval Loss = 0.2415\n",
            "Epoch 13: Train Loss = 0.2431, Eval Loss = 0.2423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:56:48,825] Trial 28 finished with value: 0.2425297349691391 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00037241825577504173, 'alpha': 0.1251822668202063}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.2349, Eval Loss = 0.2425\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.7357, Eval Loss = 0.2570\n",
            "Epoch 2: Train Loss = 0.5667, Eval Loss = 0.2568\n",
            "Epoch 3: Train Loss = 0.5367, Eval Loss = 0.2545\n",
            "Epoch 4: Train Loss = 0.5115, Eval Loss = 0.2532\n",
            "Epoch 5: Train Loss = 0.4854, Eval Loss = 0.2529\n",
            "Epoch 6: Train Loss = 0.4586, Eval Loss = 0.2508\n",
            "Epoch 7: Train Loss = 0.4311, Eval Loss = 0.2500\n",
            "Epoch 8: Train Loss = 0.4068, Eval Loss = 0.2503\n",
            "Epoch 9: Train Loss = 0.3842, Eval Loss = 0.2501\n",
            "Epoch 10: Train Loss = 0.3619, Eval Loss = 0.2499\n",
            "Epoch 11: Train Loss = 0.3541, Eval Loss = 0.2497\n",
            "Epoch 12: Train Loss = 0.3284, Eval Loss = 0.2494\n",
            "Epoch 13: Train Loss = 0.3162, Eval Loss = 0.2490\n",
            "Epoch 14: Train Loss = 0.3086, Eval Loss = 0.2493\n",
            "Epoch 15: Train Loss = 0.2991, Eval Loss = 0.2498\n",
            "Epoch 16: Train Loss = 0.2905, Eval Loss = 0.2499\n",
            "Epoch 17: Train Loss = 0.2845, Eval Loss = 0.2501\n",
            "Epoch 18: Train Loss = 0.2823, Eval Loss = 0.2498\n",
            "Epoch 19: Train Loss = 0.2732, Eval Loss = 0.2500\n",
            "Epoch 20: Train Loss = 0.2698, Eval Loss = 0.2504\n",
            "Epoch 21: Train Loss = 0.2636, Eval Loss = 0.2504\n",
            "Epoch 22: Train Loss = 0.2597, Eval Loss = 0.2502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:57:22,742] Trial 29 finished with value: 0.25052717328071594 and parameters: {'hidden_dim': 128, 'n_layers': 2, 'lr': 0.00014032397534307088, 'alpha': 0.18534531199196652}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Train Loss = 0.2571, Eval Loss = 0.2505\n",
            "Early stopping triggered at epoch 23\n",
            "Epoch 1: Train Loss = 0.7282, Eval Loss = 0.2828\n",
            "Epoch 2: Train Loss = 0.6408, Eval Loss = 0.2791\n",
            "Epoch 3: Train Loss = 0.5903, Eval Loss = 0.2772\n",
            "Epoch 4: Train Loss = 0.5459, Eval Loss = 0.2757\n",
            "Epoch 5: Train Loss = 0.4957, Eval Loss = 0.2744\n",
            "Epoch 6: Train Loss = 0.4460, Eval Loss = 0.2767\n",
            "Epoch 7: Train Loss = 0.4137, Eval Loss = 0.2782\n",
            "Epoch 8: Train Loss = 0.4100, Eval Loss = 0.2801\n",
            "Epoch 9: Train Loss = 0.3846, Eval Loss = 0.2824\n",
            "Epoch 10: Train Loss = 0.3800, Eval Loss = 0.2824\n",
            "Epoch 11: Train Loss = 0.3682, Eval Loss = 0.2832\n",
            "Epoch 12: Train Loss = 0.3497, Eval Loss = 0.2849\n",
            "Epoch 13: Train Loss = 0.3336, Eval Loss = 0.2848\n",
            "Epoch 14: Train Loss = 0.3299, Eval Loss = 0.2873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:57:50,402] Trial 30 finished with value: 0.2903870940208435 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.000573035540806766, 'alpha': 0.3631897674920237}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss = 0.3258, Eval Loss = 0.2904\n",
            "Early stopping triggered at epoch 15\n",
            "Epoch 1: Train Loss = 0.6854, Eval Loss = 0.2489\n",
            "Epoch 2: Train Loss = 0.5308, Eval Loss = 0.2480\n",
            "Epoch 3: Train Loss = 0.5098, Eval Loss = 0.2475\n",
            "Epoch 4: Train Loss = 0.4936, Eval Loss = 0.2446\n",
            "Epoch 5: Train Loss = 0.4750, Eval Loss = 0.2429\n",
            "Epoch 6: Train Loss = 0.4540, Eval Loss = 0.2416\n",
            "Epoch 7: Train Loss = 0.4245, Eval Loss = 0.2413\n",
            "Epoch 8: Train Loss = 0.3943, Eval Loss = 0.2396\n",
            "Epoch 9: Train Loss = 0.3640, Eval Loss = 0.2400\n",
            "Epoch 10: Train Loss = 0.3399, Eval Loss = 0.2382\n",
            "Epoch 11: Train Loss = 0.3163, Eval Loss = 0.2384\n",
            "Epoch 12: Train Loss = 0.2968, Eval Loss = 0.2382\n",
            "Epoch 13: Train Loss = 0.2813, Eval Loss = 0.2382\n",
            "Epoch 14: Train Loss = 0.2690, Eval Loss = 0.2381\n",
            "Epoch 15: Train Loss = 0.2620, Eval Loss = 0.2384\n",
            "Epoch 16: Train Loss = 0.2576, Eval Loss = 0.2378\n",
            "Epoch 17: Train Loss = 0.2563, Eval Loss = 0.2387\n",
            "Epoch 18: Train Loss = 0.2492, Eval Loss = 0.2383\n",
            "Epoch 19: Train Loss = 0.2436, Eval Loss = 0.2379\n",
            "Epoch 20: Train Loss = 0.2420, Eval Loss = 0.2386\n",
            "Epoch 21: Train Loss = 0.2368, Eval Loss = 0.2394\n",
            "Epoch 22: Train Loss = 0.2289, Eval Loss = 0.2399\n",
            "Epoch 23: Train Loss = 0.2287, Eval Loss = 0.2409\n",
            "Epoch 24: Train Loss = 0.2322, Eval Loss = 0.2421\n",
            "Epoch 25: Train Loss = 0.2255, Eval Loss = 0.2418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:59:12,471] Trial 31 finished with value: 0.24235545098781586 and parameters: {'hidden_dim': 256, 'n_layers': 4, 'lr': 8.696404766354976e-05, 'alpha': 0.12235384005818346}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss = 0.2179, Eval Loss = 0.2424\n",
            "Early stopping triggered at epoch 26\n",
            "Epoch 1: Train Loss = 0.8127, Eval Loss = 0.3000\n",
            "Epoch 2: Train Loss = 0.6736, Eval Loss = 0.2972\n",
            "Epoch 3: Train Loss = 0.6331, Eval Loss = 0.2943\n",
            "Epoch 4: Train Loss = 0.5942, Eval Loss = 0.2935\n",
            "Epoch 5: Train Loss = 0.5600, Eval Loss = 0.2902\n",
            "Epoch 6: Train Loss = 0.5187, Eval Loss = 0.2900\n",
            "Epoch 7: Train Loss = 0.4868, Eval Loss = 0.2894\n",
            "Epoch 8: Train Loss = 0.4541, Eval Loss = 0.2897\n",
            "Epoch 9: Train Loss = 0.4301, Eval Loss = 0.2902\n",
            "Epoch 10: Train Loss = 0.4131, Eval Loss = 0.2896\n",
            "Epoch 11: Train Loss = 0.3993, Eval Loss = 0.2903\n",
            "Epoch 12: Train Loss = 0.3927, Eval Loss = 0.2899\n",
            "Epoch 13: Train Loss = 0.3746, Eval Loss = 0.2899\n",
            "Epoch 14: Train Loss = 0.3695, Eval Loss = 0.2907\n",
            "Epoch 15: Train Loss = 0.3631, Eval Loss = 0.2903\n",
            "Epoch 16: Train Loss = 0.3507, Eval Loss = 0.2911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 03:59:43,899] Trial 32 finished with value: 0.2906968891620636 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 0.00015037889851878992, 'alpha': 0.4480636058569929}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss = 0.3472, Eval Loss = 0.2907\n",
            "Early stopping triggered at epoch 17\n",
            "Epoch 1: Train Loss = 0.6468, Eval Loss = 0.2408\n",
            "Epoch 2: Train Loss = 0.5390, Eval Loss = 0.2398\n",
            "Epoch 3: Train Loss = 0.4523, Eval Loss = 0.2372\n",
            "Epoch 4: Train Loss = 0.3967, Eval Loss = 0.2355\n",
            "Epoch 5: Train Loss = 0.3335, Eval Loss = 0.2372\n",
            "Epoch 6: Train Loss = 0.3133, Eval Loss = 0.2364\n",
            "Epoch 7: Train Loss = 0.2867, Eval Loss = 0.2391\n",
            "Epoch 8: Train Loss = 0.2662, Eval Loss = 0.2389\n",
            "Epoch 9: Train Loss = 0.2547, Eval Loss = 0.2411\n",
            "Epoch 10: Train Loss = 0.2647, Eval Loss = 0.2418\n",
            "Epoch 11: Train Loss = 0.2468, Eval Loss = 0.2424\n",
            "Epoch 12: Train Loss = 0.2381, Eval Loss = 0.2446\n",
            "Epoch 13: Train Loss = 0.2257, Eval Loss = 0.2453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:00:16,395] Trial 33 finished with value: 0.24739211797714233 and parameters: {'hidden_dim': 512, 'n_layers': 2, 'lr': 0.0002459556807965155, 'alpha': 0.11907705159016535}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss = 0.2202, Eval Loss = 0.2474\n",
            "Early stopping triggered at epoch 14\n",
            "Epoch 1: Train Loss = 0.8494, Eval Loss = 0.2561\n",
            "Epoch 2: Train Loss = 0.5911, Eval Loss = 0.2559\n",
            "Epoch 3: Train Loss = 0.5517, Eval Loss = 0.2559\n",
            "Epoch 4: Train Loss = 0.5346, Eval Loss = 0.2546\n",
            "Epoch 5: Train Loss = 0.5197, Eval Loss = 0.2539\n",
            "Epoch 6: Train Loss = 0.5072, Eval Loss = 0.2534\n",
            "Epoch 7: Train Loss = 0.4952, Eval Loss = 0.2522\n",
            "Epoch 8: Train Loss = 0.4835, Eval Loss = 0.2517\n",
            "Epoch 9: Train Loss = 0.4670, Eval Loss = 0.2510\n",
            "Epoch 10: Train Loss = 0.4531, Eval Loss = 0.2497\n",
            "Epoch 11: Train Loss = 0.4390, Eval Loss = 0.2491\n",
            "Epoch 12: Train Loss = 0.4263, Eval Loss = 0.2478\n",
            "Epoch 13: Train Loss = 0.4066, Eval Loss = 0.2471\n",
            "Epoch 14: Train Loss = 0.3905, Eval Loss = 0.2469\n",
            "Epoch 15: Train Loss = 0.3763, Eval Loss = 0.2463\n",
            "Epoch 16: Train Loss = 0.3639, Eval Loss = 0.2459\n",
            "Epoch 17: Train Loss = 0.3545, Eval Loss = 0.2462\n",
            "Epoch 18: Train Loss = 0.3443, Eval Loss = 0.2460\n",
            "Epoch 19: Train Loss = 0.3333, Eval Loss = 0.2461\n",
            "Epoch 20: Train Loss = 0.3267, Eval Loss = 0.2458\n",
            "Epoch 21: Train Loss = 0.3175, Eval Loss = 0.2455\n",
            "Epoch 22: Train Loss = 0.3108, Eval Loss = 0.2456\n",
            "Epoch 23: Train Loss = 0.3050, Eval Loss = 0.2455\n",
            "Epoch 24: Train Loss = 0.2999, Eval Loss = 0.2453\n",
            "Epoch 25: Train Loss = 0.2932, Eval Loss = 0.2455\n",
            "Epoch 26: Train Loss = 0.2890, Eval Loss = 0.2456\n",
            "Epoch 27: Train Loss = 0.2836, Eval Loss = 0.2454\n",
            "Epoch 28: Train Loss = 0.2797, Eval Loss = 0.2454\n",
            "Epoch 29: Train Loss = 0.2774, Eval Loss = 0.2454\n",
            "Epoch 30: Train Loss = 0.2725, Eval Loss = 0.2451\n",
            "Epoch 31: Train Loss = 0.2709, Eval Loss = 0.2451\n",
            "Epoch 32: Train Loss = 0.2668, Eval Loss = 0.2453\n",
            "Epoch 33: Train Loss = 0.2637, Eval Loss = 0.2451\n",
            "Epoch 34: Train Loss = 0.2605, Eval Loss = 0.2450\n",
            "Epoch 35: Train Loss = 0.2597, Eval Loss = 0.2451\n",
            "Epoch 36: Train Loss = 0.2558, Eval Loss = 0.2452\n",
            "Epoch 37: Train Loss = 0.2544, Eval Loss = 0.2454\n",
            "Epoch 38: Train Loss = 0.2520, Eval Loss = 0.2453\n",
            "Epoch 39: Train Loss = 0.2498, Eval Loss = 0.2457\n",
            "Epoch 40: Train Loss = 0.2481, Eval Loss = 0.2459\n",
            "Epoch 41: Train Loss = 0.2470, Eval Loss = 0.2457\n",
            "Epoch 42: Train Loss = 0.2451, Eval Loss = 0.2456\n",
            "Epoch 43: Train Loss = 0.2431, Eval Loss = 0.2458\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:01:36,188] Trial 34 finished with value: 0.24577412009239197 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 5.781202919276994e-05, 'alpha': 0.17063386122033597}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: Train Loss = 0.2403, Eval Loss = 0.2458\n",
            "Early stopping triggered at epoch 44\n",
            "Epoch 1: Train Loss = 0.6572, Eval Loss = 0.2511\n",
            "Epoch 2: Train Loss = 0.5349, Eval Loss = 0.2469\n",
            "Epoch 3: Train Loss = 0.4974, Eval Loss = 0.2442\n",
            "Epoch 4: Train Loss = 0.4484, Eval Loss = 0.2436\n",
            "Epoch 5: Train Loss = 0.3964, Eval Loss = 0.2416\n",
            "Epoch 6: Train Loss = 0.3607, Eval Loss = 0.2405\n",
            "Epoch 7: Train Loss = 0.3258, Eval Loss = 0.2406\n",
            "Epoch 8: Train Loss = 0.3031, Eval Loss = 0.2406\n",
            "Epoch 9: Train Loss = 0.2880, Eval Loss = 0.2413\n",
            "Epoch 10: Train Loss = 0.2721, Eval Loss = 0.2407\n",
            "Epoch 11: Train Loss = 0.2741, Eval Loss = 0.2398\n",
            "Epoch 12: Train Loss = 0.2629, Eval Loss = 0.2415\n",
            "Epoch 13: Train Loss = 0.2543, Eval Loss = 0.2426\n",
            "Epoch 14: Train Loss = 0.2548, Eval Loss = 0.2450\n",
            "Epoch 15: Train Loss = 0.2407, Eval Loss = 0.2447\n",
            "Epoch 16: Train Loss = 0.2385, Eval Loss = 0.2466\n",
            "Epoch 17: Train Loss = 0.2384, Eval Loss = 0.2468\n",
            "Epoch 18: Train Loss = 0.2284, Eval Loss = 0.2476\n",
            "Epoch 19: Train Loss = 0.2258, Eval Loss = 0.2498\n",
            "Epoch 20: Train Loss = 0.2196, Eval Loss = 0.2504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:02:42,037] Trial 35 finished with value: 0.25149083137512207 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.00010565029345561229, 'alpha': 0.1553057255020687}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss = 0.2179, Eval Loss = 0.2515\n",
            "Early stopping triggered at epoch 21\n",
            "Epoch 1: Train Loss = 0.6809, Eval Loss = 0.2479\n",
            "Epoch 2: Train Loss = 0.5383, Eval Loss = 0.2430\n",
            "Epoch 3: Train Loss = 0.5103, Eval Loss = 0.2422\n",
            "Epoch 4: Train Loss = 0.4962, Eval Loss = 0.2395\n",
            "Epoch 5: Train Loss = 0.4733, Eval Loss = 0.2382\n",
            "Epoch 6: Train Loss = 0.4509, Eval Loss = 0.2373\n",
            "Epoch 7: Train Loss = 0.4106, Eval Loss = 0.2375\n",
            "Epoch 8: Train Loss = 0.3709, Eval Loss = 0.2369\n",
            "Epoch 9: Train Loss = 0.3397, Eval Loss = 0.2388\n",
            "Epoch 10: Train Loss = 0.3175, Eval Loss = 0.2398\n",
            "Epoch 11: Train Loss = 0.3007, Eval Loss = 0.2409\n",
            "Epoch 12: Train Loss = 0.2719, Eval Loss = 0.2401\n",
            "Epoch 13: Train Loss = 0.2807, Eval Loss = 0.2441\n",
            "Epoch 14: Train Loss = 0.2907, Eval Loss = 0.2434\n",
            "Epoch 15: Train Loss = 0.2550, Eval Loss = 0.2452\n",
            "Epoch 16: Train Loss = 0.2495, Eval Loss = 0.2466\n",
            "Epoch 17: Train Loss = 0.2440, Eval Loss = 0.2476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:03:37,178] Trial 36 finished with value: 0.247280552983284 and parameters: {'hidden_dim': 256, 'n_layers': 4, 'lr': 0.00017381809536977564, 'alpha': 0.11948362764484902}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss = 0.2576, Eval Loss = 0.2473\n",
            "Early stopping triggered at epoch 18\n",
            "Epoch 1: Train Loss = 0.7014, Eval Loss = 0.2616\n",
            "Epoch 2: Train Loss = 0.6141, Eval Loss = 0.2588\n",
            "Epoch 3: Train Loss = 0.5672, Eval Loss = 0.2572\n",
            "Epoch 4: Train Loss = 0.6182, Eval Loss = 0.2581\n",
            "Epoch 5: Train Loss = 0.5467, Eval Loss = 0.2606\n",
            "Epoch 6: Train Loss = 0.4905, Eval Loss = 0.2596\n",
            "Epoch 7: Train Loss = 0.5036, Eval Loss = 0.2605\n",
            "Epoch 8: Train Loss = 0.4300, Eval Loss = 0.2632\n",
            "Epoch 9: Train Loss = 0.3976, Eval Loss = 0.2623\n",
            "Epoch 10: Train Loss = 0.3717, Eval Loss = 0.2609\n",
            "Epoch 11: Train Loss = 0.3669, Eval Loss = 0.2607\n",
            "Epoch 12: Train Loss = 0.3196, Eval Loss = 0.2619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:04:16,972] Trial 37 finished with value: 0.26143115758895874 and parameters: {'hidden_dim': 512, 'n_layers': 3, 'lr': 0.0003662297246026884, 'alpha': 0.2308673963349186}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss = 0.3223, Eval Loss = 0.2614\n",
            "Early stopping triggered at epoch 13\n",
            "Epoch 1: Train Loss = 0.8941, Eval Loss = 0.2704\n",
            "Epoch 2: Train Loss = 0.6507, Eval Loss = 0.2694\n",
            "Epoch 3: Train Loss = 0.5959, Eval Loss = 0.2695\n",
            "Epoch 4: Train Loss = 0.5700, Eval Loss = 0.2690\n",
            "Epoch 5: Train Loss = 0.5499, Eval Loss = 0.2680\n",
            "Epoch 6: Train Loss = 0.5352, Eval Loss = 0.2671\n",
            "Epoch 7: Train Loss = 0.5174, Eval Loss = 0.2660\n",
            "Epoch 8: Train Loss = 0.5024, Eval Loss = 0.2655\n",
            "Epoch 9: Train Loss = 0.4854, Eval Loss = 0.2652\n",
            "Epoch 10: Train Loss = 0.4690, Eval Loss = 0.2638\n",
            "Epoch 11: Train Loss = 0.4541, Eval Loss = 0.2637\n",
            "Epoch 12: Train Loss = 0.4403, Eval Loss = 0.2636\n",
            "Epoch 13: Train Loss = 0.4262, Eval Loss = 0.2638\n",
            "Epoch 14: Train Loss = 0.4153, Eval Loss = 0.2635\n",
            "Epoch 15: Train Loss = 0.4036, Eval Loss = 0.2635\n",
            "Epoch 16: Train Loss = 0.3927, Eval Loss = 0.2634\n",
            "Epoch 17: Train Loss = 0.3839, Eval Loss = 0.2634\n",
            "Epoch 18: Train Loss = 0.3730, Eval Loss = 0.2631\n",
            "Epoch 19: Train Loss = 0.3673, Eval Loss = 0.2635\n",
            "Epoch 20: Train Loss = 0.3585, Eval Loss = 0.2640\n",
            "Epoch 21: Train Loss = 0.3510, Eval Loss = 0.2637\n",
            "Epoch 22: Train Loss = 0.3417, Eval Loss = 0.2636\n",
            "Epoch 23: Train Loss = 0.3369, Eval Loss = 0.2635\n",
            "Epoch 24: Train Loss = 0.3285, Eval Loss = 0.2638\n",
            "Epoch 25: Train Loss = 0.3234, Eval Loss = 0.2639\n",
            "Epoch 26: Train Loss = 0.3189, Eval Loss = 0.2641\n",
            "Epoch 27: Train Loss = 0.3113, Eval Loss = 0.2639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:05:07,706] Trial 38 finished with value: 0.26402798295021057 and parameters: {'hidden_dim': 256, 'n_layers': 2, 'lr': 4.3905631822140736e-05, 'alpha': 0.27474007204937934}. Best is trial 22 with value: 0.23827916383743286.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: Train Loss = 0.3081, Eval Loss = 0.2640\n",
            "Early stopping triggered at epoch 28\n",
            "Epoch 1: Train Loss = 0.7446, Eval Loss = 0.2462\n",
            "Epoch 2: Train Loss = 0.5329, Eval Loss = 0.2439\n",
            "Epoch 3: Train Loss = 0.5048, Eval Loss = 0.2420\n",
            "Epoch 4: Train Loss = 0.4859, Eval Loss = 0.2403\n",
            "Epoch 5: Train Loss = 0.4641, Eval Loss = 0.2392\n",
            "Epoch 6: Train Loss = 0.4404, Eval Loss = 0.2374\n",
            "Epoch 7: Train Loss = 0.4172, Eval Loss = 0.2359\n",
            "Epoch 8: Train Loss = 0.3884, Eval Loss = 0.2351\n",
            "Epoch 9: Train Loss = 0.3624, Eval Loss = 0.2348\n",
            "Epoch 10: Train Loss = 0.3422, Eval Loss = 0.2352\n",
            "Epoch 11: Train Loss = 0.3209, Eval Loss = 0.2351\n",
            "Epoch 12: Train Loss = 0.3044, Eval Loss = 0.2350\n",
            "Epoch 13: Train Loss = 0.2928, Eval Loss = 0.2346\n",
            "Epoch 14: Train Loss = 0.2796, Eval Loss = 0.2345\n",
            "Epoch 15: Train Loss = 0.2713, Eval Loss = 0.2347\n",
            "Epoch 16: Train Loss = 0.2612, Eval Loss = 0.2343\n",
            "Epoch 17: Train Loss = 0.2540, Eval Loss = 0.2346\n",
            "Epoch 18: Train Loss = 0.2479, Eval Loss = 0.2351\n",
            "Epoch 19: Train Loss = 0.2461, Eval Loss = 0.2348\n",
            "Epoch 20: Train Loss = 0.2397, Eval Loss = 0.2350\n",
            "Epoch 21: Train Loss = 0.2399, Eval Loss = 0.2356\n",
            "Epoch 22: Train Loss = 0.2309, Eval Loss = 0.2354\n",
            "Epoch 23: Train Loss = 0.2304, Eval Loss = 0.2357\n",
            "Epoch 24: Train Loss = 0.2269, Eval Loss = 0.2365\n",
            "Epoch 25: Train Loss = 0.2266, Eval Loss = 0.2369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:05:54,170] Trial 39 finished with value: 0.23753900825977325 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 0.00012046832873842345, 'alpha': 0.10120507355972641}. Best is trial 39 with value: 0.23753900825977325.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss = 0.2197, Eval Loss = 0.2375\n",
            "Early stopping triggered at epoch 26\n",
            "Epoch 1: Train Loss = 0.9181, Eval Loss = 0.3088\n",
            "Epoch 2: Train Loss = 0.6910, Eval Loss = 0.3072\n",
            "Epoch 3: Train Loss = 0.6655, Eval Loss = 0.3053\n",
            "Epoch 4: Train Loss = 0.6483, Eval Loss = 0.3033\n",
            "Epoch 5: Train Loss = 0.6341, Eval Loss = 0.3026\n",
            "Epoch 6: Train Loss = 0.6110, Eval Loss = 0.2999\n",
            "Epoch 7: Train Loss = 0.5917, Eval Loss = 0.2983\n",
            "Epoch 8: Train Loss = 0.5644, Eval Loss = 0.2974\n",
            "Epoch 9: Train Loss = 0.5396, Eval Loss = 0.2961\n",
            "Epoch 10: Train Loss = 0.5206, Eval Loss = 0.2963\n",
            "Epoch 11: Train Loss = 0.4960, Eval Loss = 0.2960\n",
            "Epoch 12: Train Loss = 0.4808, Eval Loss = 0.2959\n",
            "Epoch 13: Train Loss = 0.4606, Eval Loss = 0.2957\n",
            "Epoch 14: Train Loss = 0.4468, Eval Loss = 0.2965\n",
            "Epoch 15: Train Loss = 0.4336, Eval Loss = 0.2962\n",
            "Epoch 16: Train Loss = 0.4244, Eval Loss = 0.2959\n",
            "Epoch 17: Train Loss = 0.4157, Eval Loss = 0.2964\n",
            "Epoch 18: Train Loss = 0.4106, Eval Loss = 0.2959\n",
            "Epoch 19: Train Loss = 0.4023, Eval Loss = 0.2964\n",
            "Epoch 20: Train Loss = 0.3995, Eval Loss = 0.2962\n",
            "Epoch 21: Train Loss = 0.3918, Eval Loss = 0.2958\n",
            "Epoch 22: Train Loss = 0.3872, Eval Loss = 0.2964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:06:35,373] Trial 40 finished with value: 0.29614996910095215 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 0.00012771506462785708, 'alpha': 0.4837970114087849}. Best is trial 39 with value: 0.23753900825977325.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Train Loss = 0.3838, Eval Loss = 0.2961\n",
            "Early stopping triggered at epoch 23\n",
            "Epoch 1: Train Loss = 0.7516, Eval Loss = 0.2463\n",
            "Epoch 2: Train Loss = 0.5448, Eval Loss = 0.2472\n",
            "Epoch 3: Train Loss = 0.5124, Eval Loss = 0.2464\n",
            "Epoch 4: Train Loss = 0.4965, Eval Loss = 0.2446\n",
            "Epoch 5: Train Loss = 0.4802, Eval Loss = 0.2437\n",
            "Epoch 6: Train Loss = 0.4638, Eval Loss = 0.2414\n",
            "Epoch 7: Train Loss = 0.4426, Eval Loss = 0.2406\n",
            "Epoch 8: Train Loss = 0.4197, Eval Loss = 0.2389\n",
            "Epoch 9: Train Loss = 0.4034, Eval Loss = 0.2381\n",
            "Epoch 10: Train Loss = 0.3790, Eval Loss = 0.2366\n",
            "Epoch 11: Train Loss = 0.3572, Eval Loss = 0.2369\n",
            "Epoch 12: Train Loss = 0.3375, Eval Loss = 0.2358\n",
            "Epoch 13: Train Loss = 0.3223, Eval Loss = 0.2358\n",
            "Epoch 14: Train Loss = 0.3087, Eval Loss = 0.2356\n",
            "Epoch 15: Train Loss = 0.2940, Eval Loss = 0.2356\n",
            "Epoch 16: Train Loss = 0.2864, Eval Loss = 0.2356\n",
            "Epoch 17: Train Loss = 0.2779, Eval Loss = 0.2362\n",
            "Epoch 18: Train Loss = 0.2705, Eval Loss = 0.2352\n",
            "Epoch 19: Train Loss = 0.2654, Eval Loss = 0.2350\n",
            "Epoch 20: Train Loss = 0.2591, Eval Loss = 0.2354\n",
            "Epoch 21: Train Loss = 0.2537, Eval Loss = 0.2352\n",
            "Epoch 22: Train Loss = 0.2523, Eval Loss = 0.2351\n",
            "Epoch 23: Train Loss = 0.2464, Eval Loss = 0.2347\n",
            "Epoch 24: Train Loss = 0.2459, Eval Loss = 0.2347\n",
            "Epoch 25: Train Loss = 0.2413, Eval Loss = 0.2347\n",
            "Epoch 26: Train Loss = 0.2411, Eval Loss = 0.2351\n",
            "Epoch 27: Train Loss = 0.2343, Eval Loss = 0.2346\n",
            "Epoch 28: Train Loss = 0.2329, Eval Loss = 0.2348\n",
            "Epoch 29: Train Loss = 0.2306, Eval Loss = 0.2348\n",
            "Epoch 30: Train Loss = 0.2279, Eval Loss = 0.2347\n",
            "Epoch 31: Train Loss = 0.2253, Eval Loss = 0.2354\n",
            "Epoch 32: Train Loss = 0.2256, Eval Loss = 0.2356\n",
            "Epoch 33: Train Loss = 0.2228, Eval Loss = 0.2353\n",
            "Epoch 34: Train Loss = 0.2200, Eval Loss = 0.2354\n",
            "Epoch 35: Train Loss = 0.2153, Eval Loss = 0.2354\n",
            "Epoch 36: Train Loss = 0.2147, Eval Loss = 0.2356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:07:40,683] Trial 41 finished with value: 0.23610512912273407 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 9.468893411646537e-05, 'alpha': 0.11361185642306224}. Best is trial 41 with value: 0.23610512912273407.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: Train Loss = 0.2127, Eval Loss = 0.2361\n",
            "Early stopping triggered at epoch 37\n",
            "Epoch 1: Train Loss = 0.6983, Eval Loss = 0.2441\n",
            "Epoch 2: Train Loss = 0.5199, Eval Loss = 0.2404\n",
            "Epoch 3: Train Loss = 0.4910, Eval Loss = 0.2384\n",
            "Epoch 4: Train Loss = 0.4678, Eval Loss = 0.2356\n",
            "Epoch 5: Train Loss = 0.4336, Eval Loss = 0.2349\n",
            "Epoch 6: Train Loss = 0.3977, Eval Loss = 0.2338\n",
            "Epoch 7: Train Loss = 0.3653, Eval Loss = 0.2350\n",
            "Epoch 8: Train Loss = 0.3459, Eval Loss = 0.2335\n",
            "Epoch 9: Train Loss = 0.2981, Eval Loss = 0.2326\n",
            "Epoch 10: Train Loss = 0.2862, Eval Loss = 0.2324\n",
            "Epoch 11: Train Loss = 0.2671, Eval Loss = 0.2337\n",
            "Epoch 12: Train Loss = 0.2590, Eval Loss = 0.2326\n",
            "Epoch 13: Train Loss = 0.2511, Eval Loss = 0.2337\n",
            "Epoch 14: Train Loss = 0.2486, Eval Loss = 0.2328\n",
            "Epoch 15: Train Loss = 0.2445, Eval Loss = 0.2337\n",
            "Epoch 16: Train Loss = 0.2397, Eval Loss = 0.2345\n",
            "Epoch 17: Train Loss = 0.2346, Eval Loss = 0.2350\n",
            "Epoch 18: Train Loss = 0.2364, Eval Loss = 0.2360\n",
            "Epoch 19: Train Loss = 0.2247, Eval Loss = 0.2364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:08:16,426] Trial 42 finished with value: 0.23749381303787231 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 0.00021699557873931138, 'alpha': 0.10146224588209556}. Best is trial 41 with value: 0.23610512912273407.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss = 0.2236, Eval Loss = 0.2375\n",
            "Early stopping triggered at epoch 20\n",
            "Epoch 1: Train Loss = 0.8749, Eval Loss = 0.2522\n",
            "Epoch 2: Train Loss = 0.5764, Eval Loss = 0.2525\n",
            "Epoch 3: Train Loss = 0.5332, Eval Loss = 0.2514\n",
            "Epoch 4: Train Loss = 0.5148, Eval Loss = 0.2498\n",
            "Epoch 5: Train Loss = 0.5036, Eval Loss = 0.2488\n",
            "Epoch 6: Train Loss = 0.4915, Eval Loss = 0.2483\n",
            "Epoch 7: Train Loss = 0.4815, Eval Loss = 0.2479\n",
            "Epoch 8: Train Loss = 0.4691, Eval Loss = 0.2465\n",
            "Epoch 9: Train Loss = 0.4556, Eval Loss = 0.2445\n",
            "Epoch 10: Train Loss = 0.4421, Eval Loss = 0.2442\n",
            "Epoch 11: Train Loss = 0.4265, Eval Loss = 0.2431\n",
            "Epoch 12: Train Loss = 0.4104, Eval Loss = 0.2423\n",
            "Epoch 13: Train Loss = 0.3960, Eval Loss = 0.2413\n",
            "Epoch 14: Train Loss = 0.3799, Eval Loss = 0.2408\n",
            "Epoch 15: Train Loss = 0.3630, Eval Loss = 0.2402\n",
            "Epoch 16: Train Loss = 0.3495, Eval Loss = 0.2400\n",
            "Epoch 17: Train Loss = 0.3356, Eval Loss = 0.2398\n",
            "Epoch 18: Train Loss = 0.3243, Eval Loss = 0.2390\n",
            "Epoch 19: Train Loss = 0.3141, Eval Loss = 0.2395\n",
            "Epoch 20: Train Loss = 0.3037, Eval Loss = 0.2395\n",
            "Epoch 21: Train Loss = 0.2957, Eval Loss = 0.2394\n",
            "Epoch 22: Train Loss = 0.2903, Eval Loss = 0.2394\n",
            "Epoch 23: Train Loss = 0.2836, Eval Loss = 0.2394\n",
            "Epoch 24: Train Loss = 0.2793, Eval Loss = 0.2391\n",
            "Epoch 25: Train Loss = 0.2743, Eval Loss = 0.2392\n",
            "Epoch 26: Train Loss = 0.2689, Eval Loss = 0.2396\n",
            "Epoch 27: Train Loss = 0.2664, Eval Loss = 0.2395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:09:06,595] Trial 43 finished with value: 0.23955538868904114 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 6.511377368834283e-05, 'alpha': 0.13916400913533475}. Best is trial 41 with value: 0.23610512912273407.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: Train Loss = 0.2624, Eval Loss = 0.2396\n",
            "Early stopping triggered at epoch 28\n",
            "Epoch 1: Train Loss = 0.7632, Eval Loss = 0.2861\n",
            "Epoch 2: Train Loss = 0.6352, Eval Loss = 0.2842\n",
            "Epoch 3: Train Loss = 0.6055, Eval Loss = 0.2820\n",
            "Epoch 4: Train Loss = 0.5836, Eval Loss = 0.2811\n",
            "Epoch 5: Train Loss = 0.5555, Eval Loss = 0.2786\n",
            "Epoch 6: Train Loss = 0.5173, Eval Loss = 0.2789\n",
            "Epoch 7: Train Loss = 0.4769, Eval Loss = 0.2771\n",
            "Epoch 8: Train Loss = 0.4457, Eval Loss = 0.2761\n",
            "Epoch 9: Train Loss = 0.4205, Eval Loss = 0.2771\n",
            "Epoch 10: Train Loss = 0.3876, Eval Loss = 0.2756\n",
            "Epoch 11: Train Loss = 0.3759, Eval Loss = 0.2777\n",
            "Epoch 12: Train Loss = 0.3682, Eval Loss = 0.2772\n",
            "Epoch 13: Train Loss = 0.3526, Eval Loss = 0.2788\n",
            "Epoch 14: Train Loss = 0.3475, Eval Loss = 0.2787\n",
            "Epoch 15: Train Loss = 0.3449, Eval Loss = 0.2790\n",
            "Epoch 16: Train Loss = 0.3348, Eval Loss = 0.2794\n",
            "Epoch 17: Train Loss = 0.3325, Eval Loss = 0.2821\n",
            "Epoch 18: Train Loss = 0.3334, Eval Loss = 0.2816\n",
            "Epoch 19: Train Loss = 0.3213, Eval Loss = 0.2828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:09:42,529] Trial 44 finished with value: 0.2824055850505829 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 0.00023217057151850529, 'alpha': 0.36127236316889105}. Best is trial 41 with value: 0.23610512912273407.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss = 0.3188, Eval Loss = 0.2824\n",
            "Early stopping triggered at epoch 20\n",
            "Epoch 1: Train Loss = 0.7614, Eval Loss = 0.2461\n",
            "Epoch 2: Train Loss = 0.5382, Eval Loss = 0.2464\n",
            "Epoch 3: Train Loss = 0.5140, Eval Loss = 0.2457\n",
            "Epoch 4: Train Loss = 0.4973, Eval Loss = 0.2436\n",
            "Epoch 5: Train Loss = 0.4786, Eval Loss = 0.2428\n",
            "Epoch 6: Train Loss = 0.4602, Eval Loss = 0.2406\n",
            "Epoch 7: Train Loss = 0.4443, Eval Loss = 0.2397\n",
            "Epoch 8: Train Loss = 0.4272, Eval Loss = 0.2390\n",
            "Epoch 9: Train Loss = 0.4064, Eval Loss = 0.2381\n",
            "Epoch 10: Train Loss = 0.3837, Eval Loss = 0.2367\n",
            "Epoch 11: Train Loss = 0.3643, Eval Loss = 0.2369\n",
            "Epoch 12: Train Loss = 0.3429, Eval Loss = 0.2361\n",
            "Epoch 13: Train Loss = 0.3289, Eval Loss = 0.2362\n",
            "Epoch 14: Train Loss = 0.3127, Eval Loss = 0.2364\n",
            "Epoch 15: Train Loss = 0.2999, Eval Loss = 0.2360\n",
            "Epoch 16: Train Loss = 0.2907, Eval Loss = 0.2362\n",
            "Epoch 17: Train Loss = 0.2801, Eval Loss = 0.2361\n",
            "Epoch 18: Train Loss = 0.2729, Eval Loss = 0.2361\n",
            "Epoch 19: Train Loss = 0.2661, Eval Loss = 0.2351\n",
            "Epoch 20: Train Loss = 0.2601, Eval Loss = 0.2357\n",
            "Epoch 21: Train Loss = 0.2544, Eval Loss = 0.2359\n",
            "Epoch 22: Train Loss = 0.2508, Eval Loss = 0.2359\n",
            "Epoch 23: Train Loss = 0.2480, Eval Loss = 0.2353\n",
            "Epoch 24: Train Loss = 0.2448, Eval Loss = 0.2357\n",
            "Epoch 25: Train Loss = 0.2406, Eval Loss = 0.2356\n",
            "Epoch 26: Train Loss = 0.2364, Eval Loss = 0.2356\n",
            "Epoch 27: Train Loss = 0.2334, Eval Loss = 0.2352\n",
            "Epoch 28: Train Loss = 0.2325, Eval Loss = 0.2356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:10:34,197] Trial 45 finished with value: 0.23558296263217926 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 9.230673692265863e-05, 'alpha': 0.10402652415237752}. Best is trial 45 with value: 0.23558296263217926.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: Train Loss = 0.2291, Eval Loss = 0.2356\n",
            "Early stopping triggered at epoch 29\n",
            "Epoch 1: Train Loss = 0.9125, Eval Loss = 0.2589\n",
            "Epoch 2: Train Loss = 0.6171, Eval Loss = 0.2583\n",
            "Epoch 3: Train Loss = 0.5573, Eval Loss = 0.2588\n",
            "Epoch 4: Train Loss = 0.5394, Eval Loss = 0.2589\n",
            "Epoch 5: Train Loss = 0.5287, Eval Loss = 0.2580\n",
            "Epoch 6: Train Loss = 0.5200, Eval Loss = 0.2572\n",
            "Epoch 7: Train Loss = 0.5101, Eval Loss = 0.2565\n",
            "Epoch 8: Train Loss = 0.5016, Eval Loss = 0.2558\n",
            "Epoch 9: Train Loss = 0.4913, Eval Loss = 0.2549\n",
            "Epoch 10: Train Loss = 0.4825, Eval Loss = 0.2539\n",
            "Epoch 11: Train Loss = 0.4707, Eval Loss = 0.2534\n",
            "Epoch 12: Train Loss = 0.4596, Eval Loss = 0.2525\n",
            "Epoch 13: Train Loss = 0.4494, Eval Loss = 0.2514\n",
            "Epoch 14: Train Loss = 0.4352, Eval Loss = 0.2506\n",
            "Epoch 15: Train Loss = 0.4222, Eval Loss = 0.2501\n",
            "Epoch 16: Train Loss = 0.4108, Eval Loss = 0.2493\n",
            "Epoch 17: Train Loss = 0.3979, Eval Loss = 0.2487\n",
            "Epoch 18: Train Loss = 0.3887, Eval Loss = 0.2485\n",
            "Epoch 19: Train Loss = 0.3757, Eval Loss = 0.2482\n",
            "Epoch 20: Train Loss = 0.3679, Eval Loss = 0.2482\n",
            "Epoch 21: Train Loss = 0.3585, Eval Loss = 0.2482\n",
            "Epoch 22: Train Loss = 0.3482, Eval Loss = 0.2479\n",
            "Epoch 23: Train Loss = 0.3407, Eval Loss = 0.2481\n",
            "Epoch 24: Train Loss = 0.3343, Eval Loss = 0.2478\n",
            "Epoch 25: Train Loss = 0.3257, Eval Loss = 0.2478\n",
            "Epoch 26: Train Loss = 0.3217, Eval Loss = 0.2479\n",
            "Epoch 27: Train Loss = 0.3152, Eval Loss = 0.2480\n",
            "Epoch 28: Train Loss = 0.3103, Eval Loss = 0.2478\n",
            "Epoch 29: Train Loss = 0.3043, Eval Loss = 0.2477\n",
            "Epoch 30: Train Loss = 0.2994, Eval Loss = 0.2481\n",
            "Epoch 31: Train Loss = 0.2954, Eval Loss = 0.2477\n",
            "Epoch 32: Train Loss = 0.2914, Eval Loss = 0.2481\n",
            "Epoch 33: Train Loss = 0.2872, Eval Loss = 0.2481\n",
            "Epoch 34: Train Loss = 0.2850, Eval Loss = 0.2483\n",
            "Epoch 35: Train Loss = 0.2811, Eval Loss = 0.2485\n",
            "Epoch 36: Train Loss = 0.2786, Eval Loss = 0.2483\n",
            "Epoch 37: Train Loss = 0.2753, Eval Loss = 0.2486\n",
            "Epoch 38: Train Loss = 0.2729, Eval Loss = 0.2485\n",
            "Epoch 39: Train Loss = 0.2700, Eval Loss = 0.2487\n",
            "Epoch 40: Train Loss = 0.2683, Eval Loss = 0.2488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:11:47,210] Trial 46 finished with value: 0.24866200983524323 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 4.834293732915945e-05, 'alpha': 0.18077591399775667}. Best is trial 45 with value: 0.23558296263217926.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: Train Loss = 0.2659, Eval Loss = 0.2487\n",
            "Early stopping triggered at epoch 41\n",
            "Epoch 1: Train Loss = 0.9829, Eval Loss = 0.2524\n",
            "Epoch 2: Train Loss = 0.6950, Eval Loss = 0.2515\n",
            "Epoch 3: Train Loss = 0.5860, Eval Loss = 0.2520\n",
            "Epoch 4: Train Loss = 0.5458, Eval Loss = 0.2518\n",
            "Epoch 5: Train Loss = 0.5301, Eval Loss = 0.2520\n",
            "Epoch 6: Train Loss = 0.5178, Eval Loss = 0.2509\n",
            "Epoch 7: Train Loss = 0.5112, Eval Loss = 0.2510\n",
            "Epoch 8: Train Loss = 0.5028, Eval Loss = 0.2507\n",
            "Epoch 9: Train Loss = 0.4971, Eval Loss = 0.2505\n",
            "Epoch 10: Train Loss = 0.4905, Eval Loss = 0.2497\n",
            "Epoch 11: Train Loss = 0.4857, Eval Loss = 0.2494\n",
            "Epoch 12: Train Loss = 0.4763, Eval Loss = 0.2491\n",
            "Epoch 13: Train Loss = 0.4687, Eval Loss = 0.2489\n",
            "Epoch 14: Train Loss = 0.4613, Eval Loss = 0.2481\n",
            "Epoch 15: Train Loss = 0.4531, Eval Loss = 0.2476\n",
            "Epoch 16: Train Loss = 0.4448, Eval Loss = 0.2473\n",
            "Epoch 17: Train Loss = 0.4361, Eval Loss = 0.2471\n",
            "Epoch 18: Train Loss = 0.4275, Eval Loss = 0.2465\n",
            "Epoch 19: Train Loss = 0.4171, Eval Loss = 0.2461\n",
            "Epoch 20: Train Loss = 0.4068, Eval Loss = 0.2457\n",
            "Epoch 21: Train Loss = 0.4011, Eval Loss = 0.2455\n",
            "Epoch 22: Train Loss = 0.3926, Eval Loss = 0.2450\n",
            "Epoch 23: Train Loss = 0.3846, Eval Loss = 0.2449\n",
            "Epoch 24: Train Loss = 0.3762, Eval Loss = 0.2444\n",
            "Epoch 25: Train Loss = 0.3696, Eval Loss = 0.2441\n",
            "Epoch 26: Train Loss = 0.3609, Eval Loss = 0.2437\n",
            "Epoch 27: Train Loss = 0.3547, Eval Loss = 0.2440\n",
            "Epoch 28: Train Loss = 0.3470, Eval Loss = 0.2437\n",
            "Epoch 29: Train Loss = 0.3411, Eval Loss = 0.2435\n",
            "Epoch 30: Train Loss = 0.3344, Eval Loss = 0.2432\n",
            "Epoch 31: Train Loss = 0.3277, Eval Loss = 0.2431\n",
            "Epoch 32: Train Loss = 0.3225, Eval Loss = 0.2432\n",
            "Epoch 33: Train Loss = 0.3181, Eval Loss = 0.2431\n",
            "Epoch 34: Train Loss = 0.3129, Eval Loss = 0.2430\n",
            "Epoch 35: Train Loss = 0.3074, Eval Loss = 0.2431\n",
            "Epoch 36: Train Loss = 0.3038, Eval Loss = 0.2431\n",
            "Epoch 37: Train Loss = 0.2984, Eval Loss = 0.2433\n",
            "Epoch 38: Train Loss = 0.2954, Eval Loss = 0.2431\n",
            "Epoch 39: Train Loss = 0.2959, Eval Loss = 0.2429\n",
            "Epoch 40: Train Loss = 0.2887, Eval Loss = 0.2431\n",
            "Epoch 41: Train Loss = 0.2847, Eval Loss = 0.2430\n",
            "Epoch 42: Train Loss = 0.2821, Eval Loss = 0.2430\n",
            "Epoch 43: Train Loss = 0.2796, Eval Loss = 0.2432\n",
            "Epoch 44: Train Loss = 0.2769, Eval Loss = 0.2429\n",
            "Epoch 45: Train Loss = 0.2732, Eval Loss = 0.2430\n",
            "Epoch 46: Train Loss = 0.2725, Eval Loss = 0.2431\n",
            "Epoch 47: Train Loss = 0.2694, Eval Loss = 0.2429\n",
            "Epoch 48: Train Loss = 0.2679, Eval Loss = 0.2428\n",
            "Epoch 49: Train Loss = 0.2666, Eval Loss = 0.2428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:13:16,616] Trial 47 finished with value: 0.2429732084274292 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 3.470086088933624e-05, 'alpha': 0.14845529471241584}. Best is trial 45 with value: 0.23558296263217926.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss = 0.2639, Eval Loss = 0.2430\n",
            "Epoch 1: Train Loss = 0.7719, Eval Loss = 0.2501\n",
            "Epoch 2: Train Loss = 0.5427, Eval Loss = 0.2492\n",
            "Epoch 3: Train Loss = 0.5121, Eval Loss = 0.2485\n",
            "Epoch 4: Train Loss = 0.4972, Eval Loss = 0.2464\n",
            "Epoch 5: Train Loss = 0.4828, Eval Loss = 0.2467\n",
            "Epoch 6: Train Loss = 0.4691, Eval Loss = 0.2439\n",
            "Epoch 7: Train Loss = 0.4425, Eval Loss = 0.2416\n",
            "Epoch 8: Train Loss = 0.4215, Eval Loss = 0.2400\n",
            "Epoch 9: Train Loss = 0.4005, Eval Loss = 0.2399\n",
            "Epoch 10: Train Loss = 0.3774, Eval Loss = 0.2389\n",
            "Epoch 11: Train Loss = 0.3551, Eval Loss = 0.2383\n",
            "Epoch 12: Train Loss = 0.3449, Eval Loss = 0.2382\n",
            "Epoch 13: Train Loss = 0.3257, Eval Loss = 0.2382\n",
            "Epoch 14: Train Loss = 0.3118, Eval Loss = 0.2383\n",
            "Epoch 15: Train Loss = 0.3005, Eval Loss = 0.2380\n",
            "Epoch 16: Train Loss = 0.2910, Eval Loss = 0.2386\n",
            "Epoch 17: Train Loss = 0.2828, Eval Loss = 0.2381\n",
            "Epoch 18: Train Loss = 0.2747, Eval Loss = 0.2383\n",
            "Epoch 19: Train Loss = 0.2668, Eval Loss = 0.2386\n",
            "Epoch 20: Train Loss = 0.2631, Eval Loss = 0.2384\n",
            "Epoch 21: Train Loss = 0.2576, Eval Loss = 0.2385\n",
            "Epoch 22: Train Loss = 0.2554, Eval Loss = 0.2381\n",
            "Epoch 23: Train Loss = 0.2503, Eval Loss = 0.2385\n",
            "Epoch 24: Train Loss = 0.2477, Eval Loss = 0.2383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:14:01,479] Trial 48 finished with value: 0.23866428434848785 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 9.667972707321172e-05, 'alpha': 0.11913976502636305}. Best is trial 45 with value: 0.23558296263217926.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: Train Loss = 0.2423, Eval Loss = 0.2387\n",
            "Early stopping triggered at epoch 25\n",
            "Epoch 1: Train Loss = 0.8131, Eval Loss = 0.2550\n",
            "Epoch 2: Train Loss = 0.5766, Eval Loss = 0.2545\n",
            "Epoch 3: Train Loss = 0.5396, Eval Loss = 0.2541\n",
            "Epoch 4: Train Loss = 0.5236, Eval Loss = 0.2541\n",
            "Epoch 5: Train Loss = 0.5134, Eval Loss = 0.2524\n",
            "Epoch 6: Train Loss = 0.5001, Eval Loss = 0.2520\n",
            "Epoch 7: Train Loss = 0.4877, Eval Loss = 0.2505\n",
            "Epoch 8: Train Loss = 0.4722, Eval Loss = 0.2496\n",
            "Epoch 9: Train Loss = 0.4545, Eval Loss = 0.2482\n",
            "Epoch 10: Train Loss = 0.4362, Eval Loss = 0.2467\n",
            "Epoch 11: Train Loss = 0.4177, Eval Loss = 0.2459\n",
            "Epoch 12: Train Loss = 0.4008, Eval Loss = 0.2454\n",
            "Epoch 13: Train Loss = 0.3851, Eval Loss = 0.2447\n",
            "Epoch 14: Train Loss = 0.3728, Eval Loss = 0.2449\n",
            "Epoch 15: Train Loss = 0.3550, Eval Loss = 0.2444\n",
            "Epoch 16: Train Loss = 0.3421, Eval Loss = 0.2444\n",
            "Epoch 17: Train Loss = 0.3311, Eval Loss = 0.2444\n",
            "Epoch 18: Train Loss = 0.3210, Eval Loss = 0.2444\n",
            "Epoch 19: Train Loss = 0.3148, Eval Loss = 0.2445\n",
            "Epoch 20: Train Loss = 0.3060, Eval Loss = 0.2439\n",
            "Epoch 21: Train Loss = 0.2987, Eval Loss = 0.2438\n",
            "Epoch 22: Train Loss = 0.2951, Eval Loss = 0.2439\n",
            "Epoch 23: Train Loss = 0.2879, Eval Loss = 0.2436\n",
            "Epoch 24: Train Loss = 0.2836, Eval Loss = 0.2435\n",
            "Epoch 25: Train Loss = 0.2797, Eval Loss = 0.2435\n",
            "Epoch 26: Train Loss = 0.2752, Eval Loss = 0.2433\n",
            "Epoch 27: Train Loss = 0.2725, Eval Loss = 0.2434\n",
            "Epoch 28: Train Loss = 0.2688, Eval Loss = 0.2433\n",
            "Epoch 29: Train Loss = 0.2656, Eval Loss = 0.2434\n",
            "Epoch 30: Train Loss = 0.2627, Eval Loss = 0.2435\n",
            "Epoch 31: Train Loss = 0.2603, Eval Loss = 0.2437\n",
            "Epoch 32: Train Loss = 0.2573, Eval Loss = 0.2438\n",
            "Epoch 33: Train Loss = 0.2539, Eval Loss = 0.2435\n",
            "Epoch 34: Train Loss = 0.2525, Eval Loss = 0.2438\n",
            "Epoch 35: Train Loss = 0.2511, Eval Loss = 0.2437\n",
            "Epoch 36: Train Loss = 0.2478, Eval Loss = 0.2437\n",
            "Epoch 37: Train Loss = 0.2457, Eval Loss = 0.2440\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-11 04:15:09,296] Trial 49 finished with value: 0.24386152625083923 and parameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 7.138527211758871e-05, 'alpha': 0.1586207971055263}. Best is trial 45 with value: 0.23558296263217926.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: Train Loss = 0.2436, Eval Loss = 0.2439\n",
            "Early stopping triggered at epoch 38\n"
          ]
        }
      ],
      "source": [
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner()\n",
        ")\n",
        "study.optimize(objective, n_trials=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c24e29fd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ce4e3bb9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'hidden_dim': 128, 'n_layers': 3, 'lr': 9.230673692265863e-05, 'alpha': 0.10402652415237752}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best hyperparameters:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "90832a27",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MAE: 0.1370\n",
            "Test RMSE: 0.8542\n"
          ]
        }
      ],
      "source": [
        "# predict\n",
        "\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = mlp_model(torch.tensor(x_test_mlp, dtype=torch.float32).to(device))\n",
        "\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "errors = y_pred - y_test_mlp  # assuming y_test is numpy array\n",
        "mse = np.mean(errors**2)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = np.mean(np.abs(errors))\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HAyut1x8xchV",
      "metadata": {
        "id": "HAyut1x8xchV"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "eng",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
